{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# <font color='green'>Analyse des sentiments</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>Lecture des données</font>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importer les bibliothèques\n",
    "\n",
    "Reportez-vous aux pages Web pour les bibliothèques individuelles\n",
    "* [pandas] (http://pandas.pydata.org/), pour charger et gérer les données\n",
    "* [matplotlib] (http://matplotlib.org/), pour la visualisation\n",
    "* [numpy] (http://www.numpy.org/) pour peindre la représentation et la manipulation\n",
    "* [re] (https://docs.python.org/3/library/re.html) pour l'expression régulière\n",
    "* [nltk] (http://www.nltk.org/) pour le prétraitement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lecture de l'ensemble de données\n",
    "Certaines des données \"uploaded_cleansed_B\" sont produites à partir de \"uploaded_cleansed_A\". La différence est:\n",
    "- \"uploaded_cleansed_A\" a trois colonnes que nous n'utiliserons pas.\n",
    "- \"uploaded_cleansed_A\" a des tweets répété."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9665, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>264183816548130816</td>\n",
       "      <td>15140428</td>\n",
       "      <td>positive</td>\n",
       "      <td>Gas by my house hit $3.39!!!! I'm going to Cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>263405084770172928</td>\n",
       "      <td>591166521</td>\n",
       "      <td>negative</td>\n",
       "      <td>Not Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>262163168678248449</td>\n",
       "      <td>35266263</td>\n",
       "      <td>negative</td>\n",
       "      <td>Not Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>264249301910310912</td>\n",
       "      <td>18516728</td>\n",
       "      <td>negative</td>\n",
       "      <td>Iranian general says Israel's Iron Dome can't ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>262682041215234048</td>\n",
       "      <td>254373818</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Not Available</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0          1         2  \\\n",
       "0  264183816548130816   15140428  positive   \n",
       "1  263405084770172928  591166521  negative   \n",
       "2  262163168678248449   35266263  negative   \n",
       "3  264249301910310912   18516728  negative   \n",
       "4  262682041215234048  254373818   neutral   \n",
       "\n",
       "                                                   3  \n",
       "0  Gas by my house hit $3.39!!!! I'm going to Cha...  \n",
       "1                                      Not Available  \n",
       "2                                      Not Available  \n",
       "3  Iranian general says Israel's Iron Dome can't ...  \n",
       "4                                      Not Available  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/data/train/downloaded_cleansed_B.tsv', sep= '\\t', header=None)\n",
    "print (df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notez que certains tweets sont \"Non disponible\". Nous les rejetterons car cela n'aidera pas dans l'analyse des sentiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Supprimer tous les tweets \"NOT AVAILABLE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>264183816548130816</td>\n",
       "      <td>15140428</td>\n",
       "      <td>positive</td>\n",
       "      <td>Gas by my house hit $3.39!!!! I'm going to Cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>264249301910310912</td>\n",
       "      <td>18516728</td>\n",
       "      <td>negative</td>\n",
       "      <td>Iranian general says Israel's Iron Dome can't ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>264105751826538497</td>\n",
       "      <td>147088367</td>\n",
       "      <td>positive</td>\n",
       "      <td>with J Davlar 11th. Main rivals are team Polan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>264094586689953794</td>\n",
       "      <td>332474633</td>\n",
       "      <td>negative</td>\n",
       "      <td>Talking about ACT's &amp;amp;&amp;amp; SAT's, deciding...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>254941790757601280</td>\n",
       "      <td>557103111</td>\n",
       "      <td>negative</td>\n",
       "      <td>They may have a SuperBowl in Dallas, but Dalla...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0          1         2  \\\n",
       "0  264183816548130816   15140428  positive   \n",
       "3  264249301910310912   18516728  negative   \n",
       "6  264105751826538497  147088367  positive   \n",
       "7  264094586689953794  332474633  negative   \n",
       "9  254941790757601280  557103111  negative   \n",
       "\n",
       "                                                   3  \n",
       "0  Gas by my house hit $3.39!!!! I'm going to Cha...  \n",
       "3  Iranian general says Israel's Iron Dome can't ...  \n",
       "6  with J Davlar 11th. Main rivals are team Polan...  \n",
       "7  Talking about ACT's &amp;&amp; SAT's, deciding...  \n",
       "9  They may have a SuperBowl in Dallas, but Dalla...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df[3] != \"Not Available\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7205, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dessiner les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAncAAAHsCAYAAACwg4t/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npI4Y7iRJkjpiuJMkSerI/wHEC/Un6cIQXAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f38d5380898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# calculate the total number of occurrences of each class\n",
    "y = [len(df[df[2] == i]) for i in ['positive', 'negative', 'neutral']]\n",
    "# X axis\n",
    "objects = ['positive', 'negative', 'neutral']\n",
    "x_pos = range(len(objects))\n",
    "\n",
    "# Draw Diagram\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.bar(x_pos, y, alpha=0.5)\n",
    "plt.xticks(x_pos, objects)\n",
    "plt.ylabel('Occurences').set_size(20)\n",
    "plt.xlabel('Classes').set_size(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interprétation\n",
    "À partir du graphique ci-dessus, nous pouvons clairement noter que la classe «négative» a le moins d'échantillons dans les données par rapport à «positif» et «neutre». Par conséquent, les données semblent déséquilibrées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7205,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_tweets = list(df[3])\n",
    "labels = df[2]\n",
    "mapper = {'positive': 1, 'negative': -1, 'neutral': 0}\n",
    "labels = labels.map(mapper)\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment140 Score\n",
    "\n",
    "Avant de faire un pré-traitement sur les tweets, nous allons d'abord utiliser le score du Sentiment140 corpus. Ce corpus a le score des mots les plus courants (formels, informels) utilisés dans twitter. Le score est un nombre compris entre [-4.999: 4.999].\n",
    "\n",
    "Le score sera divisé en trois parties:\n",
    "- unigram score  --> 'unigram140_score'\n",
    "- bigram score   --> 'bigram140_score'\n",
    "- pair score     --> 'pair140_score'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['#beijing',\n",
       " '#babealert',\n",
       " '#miguelrequests',\n",
       " '#wnbaopeningday',\n",
       " '#bbq',\n",
       " '#captions',\n",
       " '#tfarp',\n",
       " '#tellmrtweet',\n",
       " '#ohhushfornewmoon',\n",
       " '#jobs']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Sentiment140_dictionary(filename):\n",
    "    sentiment140 = {}\n",
    "    with open(filename) as fin:\n",
    "        line = fin.readline()[:-1]\n",
    "        while line:\n",
    "            line = line.split('\\t')\n",
    "            sentiment140[line[0]] = float(line[1])\n",
    "            line = fin.readline()[:-1]\n",
    "    return sentiment140\n",
    "\n",
    "unigram140_d = Sentiment140_dictionary('/data/resources/Sentiment140/unigrams-pmilexicon.txt')\n",
    "hashtag_words = [word for word in unigram140_d.keys() if word[0]=='#']\n",
    "\n",
    "print(len(hashtag_words))\n",
    "hashtag_words[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SemEval2015 English lexicon \n",
    "\n",
    "Ce sont les toutes premières et dernières entrées de 'SemEval2015-English-Twitter-Lexicon.txt':\n",
    "- 0.984\tloves\n",
    "- 0.984\t#inspirational\n",
    "- 0.969\tamazing\n",
    "- 0.969\t#peaceful\n",
    "- 0.953\t#greatness\n",
    "- ...\n",
    "- -0.969\tabuse\n",
    "- -0.969\t#failure\n",
    "- -0.982\tkill\n",
    "- -0.984\tbitches\n",
    "- -0.984\t#disappointment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "886\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['#lahore',\n",
       " '#gadgetshowlive',\n",
       " '#lovely',\n",
       " '#cry',\n",
       " '#peaceful',\n",
       " \"#'s\",\n",
       " '#notsorry',\n",
       " '#python',\n",
       " '#sims3',\n",
       " '#musicmonday']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def loadSemEval(filename):\n",
    "    f = open(filename,'r')\n",
    "    lexicon = {}\n",
    "    line = f.readline()\n",
    "    while line:\n",
    "        l = line[:-1].split('\\t')\n",
    "        lexicon[l[1]] = float(l[0])\n",
    "        line = f.readline()\n",
    "    return lexicon\n",
    "\n",
    "EnglishLexicon = loadSemEval('/data/resources/SemEval2015-English-Twitter-Lexicon.txt')\n",
    "hashtag_words.extend([word for word in EnglishLexicon.keys() if word[0]=='#'])\n",
    "hashtag_words = set(hashtag_words)\n",
    "print(len(hashtag_words))\n",
    "list(hashtag_words)[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# <font color='red'>Tweets pré-processus</font>\n",
    "https://nlp.stanford.edu/IR-book/html/htmledition/determining-the-vocabulary-of-terms-1.html\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Supprimer les slangs des tweets\n",
    "Par (slangs) argot, nous entendons des mots comme:\n",
    "- i've --> I have\n",
    "- 12be --> want to be\n",
    "- *4u  --> kiss for you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadSlangs(filename):\n",
    "    \"\"\"\n",
    "    This function reads the file that contains the slangs, and put them in a dictionary such that\n",
    "    the key is the \"slang\" and the value is the acronym.\n",
    "    slangs['i've'] = 'i have'\n",
    "    slang['12be'] = 'want to be'\n",
    "    ...\n",
    "    CAUTION: the keys and values are lower-case letters\n",
    "    \"\"\"\n",
    "    slangs={}\n",
    "    fi=open(filename,'r')\n",
    "    line=fi.readline()\n",
    "    while line:\n",
    "        l=line.split(r',%,')\n",
    "        if len(l) == 2:\n",
    "            slangs[l[0].lower()]=l[1][:-1].lower()  #HERE\n",
    "        line=fi.readline()\n",
    "    fi.close()\n",
    "    return slangs\n",
    "\n",
    "\n",
    "def replaceSlangs(tweet,slangs):\n",
    "    \"\"\"\n",
    "    This function is used to replace the slang in the original tweets and replace them with the acronym.\n",
    "    And it's also returns the the tweet in lower-case letters\n",
    "    \"\"\"\n",
    "    result=''\n",
    "    tweet = tweet.lower()\n",
    "    words=tweet.split()\n",
    "    for w in words:\n",
    "        if w in slangs.keys():\n",
    "            result=result+slangs[w]+\" \"\n",
    "        else:\n",
    "            result=result+w+\" \"\n",
    "    return result.strip()\n",
    "\n",
    "slangs = loadSlangs('/data/resources/internetSlangs.txt')\n",
    "raw_tweets = [replaceSlangs(tweet, slangs) for tweet in raw_tweets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remplacer les mots apostrophe\n",
    "\n",
    "Par cela, nous entendons changer des mots comme 'can't', 'cant' en 'can not'. Ces mots sont dans un fichier appelé 'apostrophe_words.txt' qui existait dans le répertoire 'resources'.\n",
    "\n",
    "Nous devons faire cela pour gérer le problème de la négation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_apostrophe_words(filename):\n",
    "    \"\"\"\n",
    "    This function reads the file that contains all words that have apostrophe, and put them in a dictionary \n",
    "    such that the key is the \"word containing apostrophe\" and the value is the \"the word without apostrophe\".\n",
    "    slangs['i've'] = 'i have'\n",
    "    slang['I'm] = 'I am'\n",
    "    ...\n",
    "    CAUTION: the keys and values are lower-case letters\n",
    "    \"\"\"\n",
    "    apo={}\n",
    "    fi=open(filename,'r')\n",
    "    line=fi.readline()\n",
    "    while line:\n",
    "        l=line.split(r',%,')\n",
    "        if len(l) == 2:\n",
    "            apo[l[0].lower()]=l[1][:-1].lower()\n",
    "        line=fi.readline()\n",
    "    fi.close()\n",
    "    return apo\n",
    "\n",
    "\n",
    "def replace_apostrophe(tweet,apos):\n",
    "    result=''\n",
    "    words=tweet.split()\n",
    "    for w in words:\n",
    "        if w in apos.keys():\n",
    "            result=result+apos[w]+\" \"\n",
    "        else:\n",
    "            result=result+w+\" \"\n",
    "    return result.strip()\n",
    "\n",
    "apos = load_apostrophe_words('/data/resources/apostrophe_words.txt')\n",
    "raw_tweets = [replace_apostrophe(tweet, apos) for tweet in raw_tweets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appliquer des techniques de prétraitement standard\n",
    "\n",
    "* https://nlp.stanford.edu/IR-book/html/htmledition/tokenization-1.html\n",
    "* https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utiliser NRC emoticon lexicon\n",
    "\n",
    "Nous remplacerons l'émoticône par sa signification associée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TT = TweetTokenizer()\n",
    "\n",
    "def emoticondictionary(filename):\n",
    "    \"\"\"\n",
    "    Reads the emoticon file and represents it as dictionary where the emoticon is the key, \n",
    "    and its indication as a value\n",
    "    \"\"\"\n",
    "    emo_scores = {'Positive': 'positive', 'Extremely-Positive': 'positive', \n",
    "                  'Negative': 'negative','Extremely-Negative': 'negative',\n",
    "                  'Neutral': 'neutral'}\n",
    "    emo_score_list = {}\n",
    "    fi = open(filename,\"r\")\n",
    "    l = fi.readline()\n",
    "    while l:\n",
    "        #replace the \"Non-break space\" with the ordinary space \" \"\n",
    "        l = l.replace(\"\\xa0\",\" \") #HERE\n",
    "        li = l.split(\" \")\n",
    "        l2 = li[:-1] #removes the polarity of the emoticon ('negative', 'positive')\n",
    "        l2.append(li[len(li) - 1].split(\"\\t\")[0]) #gets the last emoticon attached to the polarity by '\\t'\n",
    "        sentiment=li[len(li) - 1].split(\"\\t\")[1][:-1] #gets only the polarity, and removes '\\n'\n",
    "        score=emo_scores[sentiment]\n",
    "        l2.append(score)\n",
    "        for i in range(0,len(l2)-1):\n",
    "            emo_score_list[l2[i]]=l2[len(l2)-1]\n",
    "        l=fi.readline()\n",
    "    return emo_score_list\n",
    "\n",
    "dict = emoticondictionary('/data/resources/emoticon.txt')\n",
    "\n",
    "\n",
    "# substititue emoticon with its associated sentiment\n",
    "def subsEmoticon(tweet,d):\n",
    "    l = TT.tokenize(tweet)\n",
    "    tweet = [d[i] if i in d.keys() else i for i in l]\n",
    "    return tweet\n",
    "\n",
    "\n",
    "raw_tweets = [subsEmoticon(tweet, dict) for tweet in raw_tweets]\n",
    "# print(\":D X3 :|\")\n",
    "# subsEmoticon(\":D X3 :|\", dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gérer la négation\n",
    "\n",
    "Suite au travail de Pang et al (2002), nous définissons un contexte nié comme un segment d'un tweet qui commence par un mot de négation (par exemple, no, never) et se termine par l'un des signes de ponctuation: ',', ' . ',': ','; ','! ','? '.\n",
    "\n",
    "Après avoir manipulé la négation, un tweet comme  'I don't like vegan food' serait 'I do not like_not vegan_not food_not.'.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "negation_words = set(['barely', 'hardly', 'lack', 'never', 'neither', 'no', 'nobody', \\\n",
    "                      'not', 'nothing', 'none', 'nowhere', 'shortage', 'scarcely', 'few', \\\n",
    "                      'low', 'merely', 'nope', 'seldom', 'rarely', 'without', 'zero'])\n",
    "punctuations = [',', '.', ':', ';', '!', '?']\n",
    "\n",
    "def handle_negation(tweet):\n",
    "    output = []\n",
    "    negate = False\n",
    "    for word in tweet:\n",
    "        if word in punctuations and negate:\n",
    "            negate = False\n",
    "        if negate and not word in negation_words:\n",
    "            output.append(word+\"_not\")\n",
    "        else:\n",
    "            output.append(word)\n",
    "        if word in negation_words and not negate:\n",
    "            negate = True\n",
    "        elif word in negation_words and negate:\n",
    "            negate = False\n",
    "    return output\n",
    "\n",
    "raw_tweets = [handle_negation(tweet) for tweet in raw_tweets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### lemmatizer les mots \n",
    "La lemmatisation ressemble à la conversion du mot 'networks' en 'network'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mmer = WordNetLemmatizer()\n",
    "# Lemmatize the tweets\n",
    "def lemma(tweet):\n",
    "    return ' '.join([mmer.lemmatize(word) for word in tweet])\n",
    "\n",
    "lemmatized_tweets = [lemma(tweet) for tweet in raw_tweets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### supprimer les hashtags non importants\n",
    "Nous avons extrait les hashtags importants de deux corpus différents (Sentiment140 and SemEval2015 English lexicon) qui sont les seuls mots qui ont des scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_hashtags(tweet):\n",
    "    output = \"\"\n",
    "    for word in tweet.split():\n",
    "        if word[0] == '#' and word not in hashtag_words:\n",
    "            continue\n",
    "        else:\n",
    "            output += word + ' '\n",
    "    return output.strip()\n",
    "\n",
    "clean_tweets = [remove_hashtags(tweet) for tweet in lemmatized_tweets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On traite ici différents problèmes:\n",
    "- supprime les caractères de ponctuation comme,. :; etc.\n",
    "- supprime les numéros du tweet.\n",
    "- supprime les espaces supplémentaires dans le tweet.\n",
    "- supprime l'occurrence de deux ou plusieurs caractères dans un mot, par exemple. loooong -> loong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def preprocess(tweet):\n",
    "    # delete symbols and URIs and tags\n",
    "    tweet =  ' '.join(re.sub(\"(@[A-Za-z0-9_]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", '', tweet).split()) #here _#\n",
    "    # remove numbers\n",
    "    tweet = re.sub('[0-9]', '', tweet)\n",
    "    # remove additional spaces\n",
    "    tweet = re.sub('[\\s]+', ' ', tweet)\n",
    "    # replace the occurrence of 2 or more characters in a word, eg. loooong -> loong\n",
    "    tweet = re.sub(r'(.)\\1{2,}', r'\\1\\1', tweet)\n",
    "    return tweet\n",
    "\n",
    "\n",
    "preprocessed_tweets = [preprocess(tweet) for tweet in lemmatized_tweets]\n",
    "del lemmatized_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Supprimer stopwords\n",
    "https://nlp.stanford.edu/IR-book/html/htmledition/dropping-common-terms-stop-words-1.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "359\n",
      "\n",
      "Compare tweets before / after\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3</th>\n",
       "      <th>final_tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gas by my house hit $3.39!!!! I'm going to Cha...</td>\n",
       "      <td>gas house hit going chapel hill sat positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Iranian general says Israel's Iron Dome can't ...</td>\n",
       "      <td>iranian general say israels iron dome dealnot ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>with J Davlar 11th. Main rivals are team Polan...</td>\n",
       "      <td>davlar th main rival team poland hopefully mak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Talking about ACT's &amp;amp;&amp;amp; SAT's, deciding...</td>\n",
       "      <td>talking acts sats deciding want go college app...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>They may have a SuperBowl in Dallas, but Dalla...</td>\n",
       "      <td>may superbowl dallas dallas winningnot anot su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Im bringing the monster load of candy tomorrow...</td>\n",
       "      <td>instant message bringing monster load candy to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Apple software, retail chiefs out in overhaul:...</td>\n",
       "      <td>apple software retail chief overhaul san franc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>@oluoch @victor_otti @kunjand I just watched i...</td>\n",
       "      <td>watched sridevis comeback remember sun morning...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>#Livewire Nadal confirmed for Mexican Open in ...</td>\n",
       "      <td>livewire nadal confirmed mexican open february...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>@MsSheLahY I didnt want to just pop up... but ...</td>\n",
       "      <td>didnt want pop yep chapel hill next wednesday ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    3  \\\n",
       "0   Gas by my house hit $3.39!!!! I'm going to Cha...   \n",
       "3   Iranian general says Israel's Iron Dome can't ...   \n",
       "6   with J Davlar 11th. Main rivals are team Polan...   \n",
       "7   Talking about ACT's &amp;&amp; SAT's, deciding...   \n",
       "9   They may have a SuperBowl in Dallas, but Dalla...   \n",
       "10  Im bringing the monster load of candy tomorrow...   \n",
       "11  Apple software, retail chiefs out in overhaul:...   \n",
       "12  @oluoch @victor_otti @kunjand I just watched i...   \n",
       "14  #Livewire Nadal confirmed for Mexican Open in ...   \n",
       "15  @MsSheLahY I didnt want to just pop up... but ...   \n",
       "\n",
       "                                         final_tweets  \n",
       "0        gas house hit going chapel hill sat positive  \n",
       "3   iranian general say israels iron dome dealnot ...  \n",
       "6   davlar th main rival team poland hopefully mak...  \n",
       "7   talking acts sats deciding want go college app...  \n",
       "9   may superbowl dallas dallas winningnot anot su...  \n",
       "10  instant message bringing monster load candy to...  \n",
       "11  apple software retail chief overhaul san franc...  \n",
       "12  watched sridevis comeback remember sun morning...  \n",
       "14  livewire nadal confirmed mexican open february...  \n",
       "15  didnt want pop yep chapel hill next wednesday ...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend([word+'_not' for word in stop_words]) #negation\n",
    "stop_words = set(stop_words)\n",
    "stop_words.update('j', 'im')\n",
    "print (len(stop_words))\n",
    "\n",
    "# remove stopwords\n",
    "def rem_stop(tweet):\n",
    "    words = tweet.split()\n",
    "    tweet = ' '.join([word for word in words if word not in stop_words])\n",
    "    return tweet\n",
    "\n",
    "final_tweets = [rem_stop(tweet) for tweet in preprocessed_tweets]\n",
    "del raw_tweets, preprocessed_tweets\n",
    "\n",
    "print(\"\\nCompare tweets before / after\")\n",
    "df['final_tweets'] = final_tweets\n",
    "df[[3, 'final_tweets']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# <font color='red'>Création de Features</font>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## <font color='red'>Entraîner le modèle</font>\n",
    "***\n",
    "#### Créer le feature vector\n",
    "* See [Bag of Words](https://en.wikipedia.org/wiki/Bag-of-words_model) for more details (Supprimer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7205, 143425)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vectorizer = CountVectorizer(analyzer='word', preprocessor=None, stop_words=None, tokenizer=None, ngram_range=(1,3))\n",
    "count_features = count_vectorizer.fit_transform(final_tweets)\n",
    "count_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(analyzer='word', preprocessor=None, stop_words=None, tokenizer=None, ngram_range=(1,3))\n",
    "tfidf_features = tfidf_vectorizer.fit_transform(final_tweets)\n",
    "del final_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7205, 286850)\n"
     ]
    }
   ],
   "source": [
    "features = scipy.sparse.hstack([count_features, tfidf_features])\n",
    "print (features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# supprimer les objets inutiles\n",
    "del count_features, tfidf_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importer Logistic Regression\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0)\n",
    "classifier.fit(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "def plot_learning_curve(estimator, title, training_curve=False, X, y, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if not training_curve:\n",
    "        plt.ylim((0.4, 0.7))\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve( estimator, X, y, cv=None, n_jobs=1, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "    \n",
    "    if training_curve:\n",
    "        plt.fill_between(train_sizes, train_scores_mean-train_scores_std, \\\n",
    "                         train_scores_mean+train_scores_std, alpha=0.1, color=\"r\")\n",
    "        plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "    \n",
    "    plt.fill_between(train_sizes, test_scores_mean-test_scores_std,test_scores_mean+test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "\n",
    "plot_learning_curve(classifier, \"Logistic Regression Learning Curve\", features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prédiction sur les données d'apprentissage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9986\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "nb_predict_train = classifier.predict(features)\n",
    "#check accuracy\n",
    "print(\"Accuracy: {:0.4f}\".format(metrics.accuracy_score(labels, nb_predict_train)))\n",
    "del features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2685    0    7]\n",
      " [   1 1021    2]\n",
      " [   0    0 3489]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       1.00      1.00      1.00      2692\n",
      "         -1       1.00      1.00      1.00      1024\n",
      "          0       1.00      1.00      1.00      3489\n",
      "\n",
      "avg / total       1.00      1.00      1.00      7205\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print confusion matrix\n",
    "print(\"{}\".format(metrics.confusion_matrix(labels, nb_predict_train, \n",
    "                                           labels=[1,-1, 0])))\n",
    "\n",
    "print(\"{}\".format(metrics.classification_report(labels, nb_predict_train, \n",
    "                                                labels=[1, -1, 0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prédire en utilisant le modèle\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importer test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8902, 4)\n"
     ]
    }
   ],
   "source": [
    "t_df = pd.read_csv('/data/test/actual/test_B_labeled.tsv', sep='\\t', header=None)\n",
    "print(t_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7584, 4)\n",
      "(7584,)\n"
     ]
    }
   ],
   "source": [
    "t_df = t_df[t_df[3] != 'Not Available']\n",
    "actual_labels = t_df[2]\n",
    "actual_labels = actual_labels.map(mapper)\n",
    "print(t_df.shape)\n",
    "print(actual_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnMAAAHoCAYAAAAi+WkTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4JgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f38d0af7080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = [len(t_df[t_df[2] == i]) for i in ['positive', 'negative', 'neutral']]\n",
    "x = ['positive', 'negative', 'neutral']\n",
    "x_pos = range(len(x))\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.bar(x_pos, y, alpha=0.5)\n",
    "plt.xticks(x_pos, x)\n",
    "plt.ylabel('# Occurences').set_size(15)\n",
    "plt.xlabel('Classes').set_size(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pré-traiter les tweets de l'ensemble de données de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_tweets_test = t_df[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_tweets_test = [replaceSlangs(tweet, slangs) for tweet in raw_tweets_test]\n",
    "raw_tweets_test = [replace_apostrophe(tweet, apos) for tweet in raw_tweets_test]\n",
    "raw_tweets_test = [subsEmoticon(tweet, dict) for tweet in raw_tweets_test]\n",
    "raw_tweets_test = [handle_negation(tweet) for tweet in raw_tweets_test] #negation\n",
    "lemmatized_tweets_test = [lemma(tweet) for tweet in raw_tweets_test]\n",
    "clean_tweets_test = [remove_hashtags(tweet) for tweet in lemmatized_tweets_test]\n",
    "preprocessed_tweets_test = [preprocess(tweet) for tweet in clean_tweets_test]\n",
    "final_tweets_test = [rem_stop(tweet) for tweet in preprocessed_tweets_test]\n",
    "t_df[3] = final_tweets_test\n",
    "\n",
    "del raw_tweets_test, lemmatized_tweets_test, preprocessed_tweets_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>282031301962395648</td>\n",
       "      <td>T14111200</td>\n",
       "      <td>neutral</td>\n",
       "      <td>dec st know asnot thenot endnot ofnot thenot w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11975</td>\n",
       "      <td>SM112166</td>\n",
       "      <td>negative</td>\n",
       "      <td>yar quite clever aft many guess lor got ask br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>136592</td>\n",
       "      <td>LJ112295</td>\n",
       "      <td>negative</td>\n",
       "      <td>yeah thin lizzy hate informercial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>253421252956545024</td>\n",
       "      <td>T13114433</td>\n",
       "      <td>neutral</td>\n",
       "      <td>mt deir ezzor ali bashar altheeb wa martyred w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>220880422320603137</td>\n",
       "      <td>T14114138</td>\n",
       "      <td>negative</td>\n",
       "      <td>hate life seenot younot atnot thenot roskilden...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0          1         2  \\\n",
       "2  282031301962395648  T14111200   neutral   \n",
       "3               11975   SM112166  negative   \n",
       "4              136592   LJ112295  negative   \n",
       "5  253421252956545024  T13114433   neutral   \n",
       "6  220880422320603137  T14114138  negative   \n",
       "\n",
       "                                                   3  \n",
       "2  dec st know asnot thenot endnot ofnot thenot w...  \n",
       "3  yar quite clever aft many guess lor got ask br...  \n",
       "4                  yeah thin lizzy hate informercial  \n",
       "5  mt deir ezzor ali bashar altheeb wa martyred w...  \n",
       "6  hate life seenot younot atnot thenot roskilden...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Créer le features vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7584, 143425)\n",
      "(7584, 143425)\n"
     ]
    }
   ],
   "source": [
    "test_count_features = count_vectorizer.transform(final_tweets_test)\n",
    "test_count_features = scipy.sparse.csr_matrix(test_count_features)\n",
    "print (test_count_features.shape)\n",
    "\n",
    "\n",
    "test_tfidf_features = tfidf_vectorizer.transform(final_tweets_test)\n",
    "test_tfidf_features = scipy.sparse.csr_matrix(test_tfidf_features)\n",
    "print (test_tfidf_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7584, 286850)\n"
     ]
    }
   ],
   "source": [
    "test_features = scipy.sparse.hstack([test_count_features, test_tfidf_features])\n",
    "print (test_features.shape)\n",
    "\n",
    "del test_count_features, test_tfidf_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prédire les étiquettes en utilisant le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_labels = classifier.predict(test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Évaluer le modèle\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 64.40%\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {:0.2f}%'.format(metrics.accuracy_score(actual_labels, predicted_labels) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.70      0.20      0.31      1296\n",
      "          0       0.59      0.88      0.71      3448\n",
      "          1       0.76      0.55      0.64      2840\n",
      "\n",
      "avg / total       0.67      0.64      0.62      7584\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Rapport de classification\n",
    "print('{}'.format(metrics.classification_report(actual_labels, predicted_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voir [Confusion Matrix](https://fr.wikipedia.org/wiki/Matrice_de_confusion) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1575   49 1216]\n",
      " [ 172  260  864]\n",
      " [ 337   62 3049]]\n",
      "\n",
      "\u001b[31m\" macro f1 score \"\u001b[0m\n",
      "0.5542108721055563\n",
      "\n",
      "\u001b[31m\" micro f1 score \"\u001b[0m\n",
      "0.6439873417721519\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print('{}\\n'.format(metrics.confusion_matrix(actual_labels, predicted_labels, labels=[1,-1,0])))\n",
    "#-------------------- F1-score --------------------\n",
    "print(\"\\x1b[31m\\\" macro f1 score \\\"\\x1b[0m\")\n",
    "print('{}\\n'.format(metrics.f1_score(actual_labels, predicted_labels, average='macro')))\n",
    "print(\"\\x1b[31m\\\" micro f1 score \\\"\\x1b[0m\")\n",
    "print('{}\\n'.format(metrics.f1_score(actual_labels, predicted_labels, average='micro')))\n",
    "\n",
    "#-------------------- precision-score --------------------\n",
    "print(\"\\x1b[31m\\\" macro precision score \\\"\\x1b[0m\")\n",
    "print('{}\\n'.format(metrics.precision_score(actual_labels, predicted_labels, average='macro')))\n",
    "print(\"\\x1b[31m\\\" micro precision score \\\"\\x1b[0m\")\n",
    "print('{}\\n'.format(metrics.precision_score(actual_labels, predicted_labels, average='micro')))\n",
    "\n",
    "#-------------------- recall-score --------------------\n",
    "print(\"\\x1b[31m\\\" macro recall score \\\"\\x1b[0m\")\n",
    "print('{}\\n'.format(metrics.recall_score(actual_labels, predicted_labels, average='macro')))\n",
    "print(\"\\x1b[31m\\\" micro recall score \\\"\\x1b[0m\")\n",
    "print('{}\\n'.format(metrics.recall_score(actual_labels, predicted_labels, average='micro')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparaison avec les 5 meilleures équipes du subtask B\n",
    "\n",
    "Nous comparons notre score avec les autres équipes de l'atelier. Les résultats sont tirés du document joint:\n",
    "[Final report SemEval 2014 Subtask 9](http://www.aclweb.org/anthology/S14-2009)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Team|Accuracy (Macro Averaged)| Accuracy (Micro Averaged)|\n",
    "|----|-------------------------|--------------------------|\n",
    "|TeamX|65.63%|69.99%|\n",
    "|coooolll|63.23%|70.51%|\n",
    "|RTRGO|63.08%|70.15%|\n",
    "|NRC-Canada|67.62%|71.37%|\n",
    "|TUGAS|63.89%|68.84%|\n",
    "|**_ME_**|_63.67%_|_67.44%_|\n",
    "| | |***classement : 10 / 50***|\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# <font color='red'> Analyse des modèles de classification: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Model|Macro Averaging| Micro Averaging|\n",
    "|-----|---------------|----------------|\n",
    "|NB (without Lexicons)|51.17%|60.28%|\n",
    "|NB (with Lexicons)|46.00%|59.53%|\n",
    "|LR (without Lexicons)|55.42%|64.39%|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
