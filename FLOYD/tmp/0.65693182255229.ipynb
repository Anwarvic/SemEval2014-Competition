{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# <font color='green'>sentiment Analysis</font> ![title](./resources/img/sent_twitter.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Reading Data</font>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import liberies\n",
    "\n",
    "Refer to the web pages for individual libraries\n",
    "* [Pandas](http://pandas.pydata.org/), to load and manage data\n",
    "* [Matplotlib](http://matplotlib.org/), for visualization\n",
    "* [numpy](http://www.numpy.org/) for painting representation and manipulation\n",
    "* [re](https://docs.python.org/3/library/re.html) for regular expression\n",
    "* [nltk](http://www.nltk.org/) for pretreatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "from copy import copy\n",
    "import collections\n",
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import make_scorer, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading the dataset\n",
    "Some of the data \"downloaded_cleansed_B\" is produced out of the \"downloaded_cleansed_A\". The difference is:\n",
    "- \"downloaded_cleansed_A\" has three columns that we won't use.\n",
    "- \"downloaded_cleansed_A\" has repeatted tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9665, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>264183816548130816</td>\n",
       "      <td>15140428</td>\n",
       "      <td>positive</td>\n",
       "      <td>Gas by my house hit $3.39!!!! I'm going to Cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>263405084770172928</td>\n",
       "      <td>591166521</td>\n",
       "      <td>negative</td>\n",
       "      <td>Not Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>262163168678248449</td>\n",
       "      <td>35266263</td>\n",
       "      <td>negative</td>\n",
       "      <td>Not Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>264249301910310912</td>\n",
       "      <td>18516728</td>\n",
       "      <td>negative</td>\n",
       "      <td>Iranian general says Israel's Iron Dome can't ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>262682041215234048</td>\n",
       "      <td>254373818</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Not Available</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0          1         2  \\\n",
       "0  264183816548130816   15140428  positive   \n",
       "1  263405084770172928  591166521  negative   \n",
       "2  262163168678248449   35266263  negative   \n",
       "3  264249301910310912   18516728  negative   \n",
       "4  262682041215234048  254373818   neutral   \n",
       "\n",
       "                                                   3  \n",
       "0  Gas by my house hit $3.39!!!! I'm going to Cha...  \n",
       "1                                      Not Available  \n",
       "2                                      Not Available  \n",
       "3  Iranian general says Israel's Iron Dome can't ...  \n",
       "4                                      Not Available  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/train/downloaded_cleansed_B.tsv', sep= '\\t', header=None)\n",
    "print (df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that some tweets are \"Not Available\". We will reject them because it will not help in the analysis of feelings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Supprimer tous les tweets \"NOT AVAILABLE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>264183816548130816</td>\n",
       "      <td>15140428</td>\n",
       "      <td>positive</td>\n",
       "      <td>Gas by my house hit $3.39!!!! I'm going to Cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>264249301910310912</td>\n",
       "      <td>18516728</td>\n",
       "      <td>negative</td>\n",
       "      <td>Iranian general says Israel's Iron Dome can't ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>264105751826538497</td>\n",
       "      <td>147088367</td>\n",
       "      <td>positive</td>\n",
       "      <td>with J Davlar 11th. Main rivals are team Polan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>264094586689953794</td>\n",
       "      <td>332474633</td>\n",
       "      <td>negative</td>\n",
       "      <td>Talking about ACT's &amp;amp;&amp;amp; SAT's, deciding...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>254941790757601280</td>\n",
       "      <td>557103111</td>\n",
       "      <td>negative</td>\n",
       "      <td>They may have a SuperBowl in Dallas, but Dalla...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0          1         2  \\\n",
       "0  264183816548130816   15140428  positive   \n",
       "3  264249301910310912   18516728  negative   \n",
       "6  264105751826538497  147088367  positive   \n",
       "7  264094586689953794  332474633  negative   \n",
       "9  254941790757601280  557103111  negative   \n",
       "\n",
       "                                                   3  \n",
       "0  Gas by my house hit $3.39!!!! I'm going to Cha...  \n",
       "3  Iranian general says Israel's Iron Dome can't ...  \n",
       "6  with J Davlar 11th. Main rivals are team Polan...  \n",
       "7  Talking about ACT's &amp;&amp; SAT's, deciding...  \n",
       "9  They may have a SuperBowl in Dallas, but Dalla...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df[3] != \"Not Available\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7205, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='blue'>Training tweets are too limited: just 7205 tweets ...</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Draw the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAncAAAHsCAYAAACwg4t/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f06a6b5fa20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# calculate the total number of occurrences of each class\n",
    "y = [len(df[df[2] == i]) for i in ['negative', 'positive', 'neutral']]\n",
    "# X axis\n",
    "objects = ['negative', 'positive', 'neutral']\n",
    "x_pos = range(len(objects))\n",
    "\n",
    "# Draw Diagram\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.bar(x_pos, y, alpha=0.5)\n",
    "plt.xticks(x_pos, objects)\n",
    "plt.ylabel('Occurences').set_size(20)\n",
    "plt.xlabel('Classes').set_size(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretation\n",
    "From the graph above, we can clearly note that the \"negative\" class has the fewest samples in the data compared to \"positive\" and \"neutral\". As a result, the data appears to be unbalanced and underfit the \"negative\" class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raw_tweets = list(df[3])\n",
    "labels = df[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment140 Score\n",
    "\n",
    "Before doing any preprocessing over the tweets, we will use the score of Sentiment140 corpus first. This corpus has the score of the most common words (formal, informal) used in twitter. The score is a number between [-4.999: 4.999].\n",
    "\n",
    "The score will be divided into three parts:\n",
    "- unigram score  --> 'unigram140_score'\n",
    "- bigram score   --> 'bigram140_score'\n",
    "- pair score     --> 'pair140_score'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7205"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Sentiment140_dictionary(filename):\n",
    "    sentiment140 = {}\n",
    "    with open(filename) as fin:\n",
    "        line = fin.readline()[:-1]\n",
    "        while line:\n",
    "            line = line.split('\\t')\n",
    "            sentiment140[line[0]] = float(line[1])\n",
    "            line = fin.readline()[:-1]\n",
    "    return sentiment140\n",
    "\n",
    "\n",
    "def unigram140Polarity(tweet, d):\n",
    "    score=0.0\n",
    "    reps = 0\n",
    "    for w in tweet.split(' '):\n",
    "        if w in d.keys():\n",
    "            reps += 1\n",
    "            score+=d[w]\n",
    "    return score, reps\n",
    "\n",
    "unigram140_d = Sentiment140_dictionary('resources/Sentiment140/unigrams-pmilexicon.txt')\n",
    "unigram140Score, unigram140Reps = [], []\n",
    "for tweet in raw_tweets:\n",
    "    score, reps = unigram140Polarity(tweet.lower(), unigram140_d)\n",
    "    unigram140Score.append(score)\n",
    "    unigram140Reps.append(reps)\n",
    "\n",
    "len(unigram140Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7205"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_bigrams(input_list):\n",
    "    bigram_list = []\n",
    "    for i in range(len(input_list)-1):\n",
    "        bigram_list.append(input_list[i] + \" \" + input_list[i+1])\n",
    "    return bigram_list\n",
    "\n",
    "\n",
    "def bigram140Polarity(tweet, d):\n",
    "    score=0.0\n",
    "    reps = 0\n",
    "    tweet = find_bigrams(tweet.split(' '))\n",
    "    for w in tweet:\n",
    "        if w in d.keys():\n",
    "            reps += 1\n",
    "            score+=d[w]\n",
    "    return score, reps\n",
    "\n",
    "\n",
    "bigram140_d = Sentiment140_dictionary('resources/Sentiment140/bigrams-pmilexicon.txt')\n",
    "bigram140Score, bigram140Reps = [], []\n",
    "for tweet in raw_tweets:\n",
    "    score, reps = bigram140Polarity(tweet.lower(), bigram140_d)\n",
    "    bigram140Score.append(score)\n",
    "    bigram140Reps.append(reps)\n",
    "\n",
    "len(bigram140Score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SemEval2015 English lexicon \n",
    "\n",
    "These are the very first and last entries of 'SemEval2015-English-Twitter-Lexicon.txt':\n",
    "- 0.984\tloves\n",
    "- 0.984\t#inspirational\n",
    "- 0.969\tamazing\n",
    "- 0.969\t#peaceful\n",
    "- 0.953\t#greatness\n",
    "- ...\n",
    "- -0.969\tabuse\n",
    "- -0.969\t#failure\n",
    "- -0.982\tkill\n",
    "- -0.984\tbitches\n",
    "- -0.984\t#disappointment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of EnglishLexicon entries 1516\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7205"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def loadSemEval(filename):\n",
    "    f = open(filename,'r')\n",
    "    lexicon = {}\n",
    "    line = f.readline()\n",
    "    while line:\n",
    "        l = line[:-1].split('\\t')\n",
    "        lexicon[l[1]] = float(l[0])\n",
    "        line = f.readline()\n",
    "    return lexicon\n",
    "\n",
    "\n",
    "def SemEvalLexiconPolarity(tweet, EnglishLexicon):\n",
    "    score=0.0\n",
    "    reps = 0\n",
    "    for w in tweet.split(' '):\n",
    "        if w in EnglishLexicon.keys():\n",
    "            reps += 1\n",
    "            score += EnglishLexicon[w]\n",
    "    return score, reps\n",
    "\n",
    "EnglishLexicon = loadSemEval('./resources/SemEval2015-English-Twitter-Lexicon.txt')\n",
    "SemEvalScore, SemEvalReps = [], []\n",
    "for tweet in raw_tweets:\n",
    "    score, reps = SemEvalLexiconPolarity(tweet.lower(), EnglishLexicon)\n",
    "    SemEvalScore.append(score)\n",
    "    SemEvalReps.append(reps)\n",
    "\n",
    "print (\"Number of EnglishLexicon entries %d\" % len(EnglishLexicon.keys()))\n",
    "len(SemEvalScore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## <font color='red'>Pre-train the tweets</font>\n",
    "https://nlp.stanford.edu/IR-book/html/htmledition/determining-the-vocabulary-of-terms-1.html\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete slangs from tweets\n",
    "By slangs, we mean words like:\n",
    "- i've --> I have\n",
    "- 12be --> want to be\n",
    "- *4u  --> kiss for you\n",
    "- ...\n",
    "\n",
    "And these parallel-terms are read from <font color='red'>'./resources/internetSlangs.txt'</font> file. Here is the first five lines in that file:\n",
    "- *4u,%,kiss for you\n",
    "- *67,%,unknown\n",
    "- *eg*,%,evil grin\n",
    "- 7734,%,hello\n",
    "- 0day,%,software illegally obtained before it was released"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def loadSlangs(filename):\n",
    "    \"\"\"\n",
    "    This function reads the file that contains the slangs, and put them in a dictionary such that\n",
    "    the key is the \"slang\" and the value is the acronym.\n",
    "    slangs['i've'] = 'i have'\n",
    "    slang['12be'] = 'want to be'\n",
    "    ...\n",
    "    CAUTION: the keys and values are lower-case letters\n",
    "    \"\"\"\n",
    "    slangs={}\n",
    "    fi=open(filename,'r')\n",
    "    line=fi.readline()\n",
    "    while line:\n",
    "        l=line.split(r',%,')\n",
    "        if len(l) == 2:\n",
    "            slangs[l[0].lower()]=l[1][:-1].lower()  #HERE\n",
    "        line=fi.readline()\n",
    "    fi.close()\n",
    "    return slangs\n",
    "\n",
    "\n",
    "def replaceSlangs(tweet,slangs):\n",
    "    \"\"\"\n",
    "    This function is used to replace the slang in the original tweets and replace them with the acronym.\n",
    "    And it's also returns the the tweet in lower-case letters\n",
    "    \"\"\"\n",
    "    result=''\n",
    "    tweet = tweet.lower()\n",
    "    words=tweet.split()\n",
    "    for w in words:\n",
    "        if w in slangs.keys():\n",
    "            result=result+slangs[w]+\" \"\n",
    "        else:\n",
    "            result=result+w+\" \"\n",
    "    return result.strip()\n",
    "\n",
    "slangs = loadSlangs('./resources/internetSlangs.txt')\n",
    "raw_tweets = [replaceSlangs(tweet, slangs) for tweet in raw_tweets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replacing apostrophe words\n",
    "\n",
    "By that, we mean to change words like 'can't', 'cant' into 'can not'. These words are in a txt file called 'apostrophe_words.txt' existed in 'resources' directory. \n",
    "We need to do that to handle the negation problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_apostrophe_words(filename):\n",
    "    \"\"\"\n",
    "    This function reads the file that contains all words that have apostrophe, and put them in a dictionary \n",
    "    such that the key is the \"word containing apostrophe\" and the value is the \"the word without apostrophe\".\n",
    "    slangs['i've'] = 'i have'\n",
    "    slang['I'm] = 'I am'\n",
    "    ...\n",
    "    CAUTION: the keys and values are lower-case letters\n",
    "    \"\"\"\n",
    "    apo={}\n",
    "    fi=open(filename,'r')\n",
    "    line=fi.readline()\n",
    "    while line:\n",
    "        l=line.split(r',%,')\n",
    "        if len(l) == 2:\n",
    "            apo[l[0].lower()]=l[1][:-1].lower()\n",
    "        line=fi.readline()\n",
    "    fi.close()\n",
    "    return apo\n",
    "\n",
    "\n",
    "def replace_apostrophe(tweet,apos):\n",
    "    result=''\n",
    "    words=tweet.split()\n",
    "    for w in words:\n",
    "        if w in apos.keys():\n",
    "            result=result+apos[w]+\" \"\n",
    "        else:\n",
    "            result=result+w+\" \"\n",
    "    return result.strip()\n",
    "\n",
    "apos = load_apostrophe_words('./resources/apostrophe_words.txt')\n",
    "raw_tweets = [replace_apostrophe(tweet, apos) for tweet in raw_tweets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply standard preprocessing techniques\n",
    "\n",
    "* https://nlp.stanford.edu/IR-book/html/htmledition/tokenization-1.html\n",
    "* https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use NRC emoticon lexicon\n",
    "\n",
    "We will replace the emoticon with its associated meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TT = TweetTokenizer()\n",
    "\n",
    "def emoticondictionary(filename):\n",
    "    \"\"\"\n",
    "    Reads the emoticon file and represents it as dictionary where the emoticon is the key, \n",
    "    and its indication as a value\n",
    "    \"\"\"\n",
    "    emo_scores = {'Positive': 'positive', 'Extremely-Positive': 'positive', \n",
    "                  'Negative': 'negative','Extremely-Negative': 'negative',\n",
    "                  'Neutral': 'neutral'}\n",
    "    emo_score_list = {}\n",
    "    fi = open(filename,\"r\")\n",
    "    l = fi.readline()\n",
    "    while l:\n",
    "        #replace the \"Non-break space\" with the ordinary space \" \"\n",
    "        l = l.replace(\"\\xa0\",\" \") #HERE\n",
    "        li = l.split(\" \")\n",
    "        l2 = li[:-1] #removes the polarity of the emoticon ('negative', 'positive')\n",
    "        l2.append(li[len(li) - 1].split(\"\\t\")[0]) #gets the last emoticon attached to the polarity by '\\t'\n",
    "        sentiment=li[len(li) - 1].split(\"\\t\")[1][:-1] #gets only the polarity, and removes '\\n'\n",
    "        score=emo_scores[sentiment]\n",
    "        l2.append(score)\n",
    "        for i in range(0,len(l2)-1):\n",
    "            emo_score_list[l2[i]]=l2[len(l2)-1]\n",
    "        l=fi.readline()\n",
    "    return emo_score_list\n",
    "\n",
    "dict = emoticondictionary('./resources/emoticon.txt')\n",
    "\n",
    "\n",
    "# substititue emoticon with its associated sentiment\n",
    "def subsEmoticon(tweet,d):\n",
    "    l = TT.tokenize(tweet)\n",
    "    tweet = [d[i] if i in d.keys() else i for i in l]\n",
    "    return tweet\n",
    "\n",
    "\n",
    "raw_tweets = [subsEmoticon(tweet, dict) for tweet in raw_tweets]\n",
    "# print(\":D X3 :|\")\n",
    "# subsEmoticon(\":D X3 :|\", dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handle Negation\n",
    "\n",
    "Following the work of Pang et al.(2002), we define a negated context as a segment of a tweet that starts with a negation word (e.g., no, never) and ends with one of the punctuation marks: ‘,’, ‘.’, ‘:’, ‘;’, ‘!’, ‘?’.\n",
    "\n",
    "After handling the negtation, a tweet like the that 'I don't like vegan food' would be 'I do not like_not vegan_not food_not.'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "negation_words = set(['barely', 'hardly', 'lack', 'never', 'neither', 'no', 'nobody', \\\n",
    "                      'not', 'nothing', 'none', 'nowhere', 'shortage', 'scarcely', 'few', \\\n",
    "                      'low', 'merely', 'nope', 'seldom', 'rarely', 'without', 'zero'])\n",
    "punctuations = [',', '.', ':', ';', '!', '?']\n",
    "\n",
    "def handle_negation(tweet):\n",
    "    output = []\n",
    "    negate = False\n",
    "    for word in tweet:\n",
    "        if word in punctuations and negate:\n",
    "            negate = False\n",
    "        if negate and not word in negation_words:\n",
    "            output.append(word+\"_not\")\n",
    "        else:\n",
    "            output.append(word)\n",
    "        if word in negation_words and not negate:\n",
    "            negate = True\n",
    "        elif word in negation_words and negate:\n",
    "            negate = False\n",
    "    return output\n",
    "\n",
    "raw_tweets = [handle_negation(tweet) for tweet in raw_tweets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, we will lemmatize our words\n",
    "lemmatizing is like converting the word 'networks' into 'network'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i love nlp\n",
      "i love nlp\n"
     ]
    }
   ],
   "source": [
    "# Lemmatize the tweets\n",
    "def lemma(tweet):\n",
    "    mmer = WordNetLemmatizer()\n",
    "    #'tweet' here MUST be list like so ['i', 'love', 'nlp']\n",
    "    if type(tweet) == str:\n",
    "        tweet = TT.tokenize(tweet)\n",
    "    \n",
    "    return ' '.join([mmer.lemmatize(word) for word in tweet])\n",
    "\n",
    "print(lemma(['i', 'love', 'nlp']))\n",
    "print(lemma('i love nlp'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing tweets handles different issues:\n",
    "- removes punctuation characters like , . : ; etc.\n",
    "- removes numbers from the tweet.\n",
    "- removes any additional spaces in the tweet.\n",
    "- removes the occurrence of two or more characters in a word, eg. loooong -> loong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def preprocess(tweet):\n",
    "    # delete symbols and URIs and tags\n",
    "    tweet =  ' '.join(re.sub(\"(@[A-Za-z0-9_]+)|([^0-9A-Za-z_# \\t])|(\\w+:\\/\\/\\S+)\", '', tweet).split()) #here _#\n",
    "    # Convert '@username' to 'at_user'\n",
    "    # tweet = re.sub('@[^\\s]+','at_user',tweet)\n",
    "    # remove hashtags\n",
    "    tweet = re.sub(r'#', '', tweet)\n",
    "    # remove numbers\n",
    "    tweet = re.sub('[0-9]', '', tweet)\n",
    "    # remove additional spaces\n",
    "    tweet = re.sub('[\\s]+', ' ', tweet)\n",
    "    # replace the occurrence of 2 or more characters in a word, eg. loooong -> loong\n",
    "    tweet = re.sub(r'(.)\\1{2,}', r'\\1\\1', tweet)\n",
    "    return tweet\n",
    "\n",
    "lemmatized_tweets = [lemma(tweet) for tweet in raw_tweets]\n",
    "preprocessed_tweets = [preprocess(tweet) for tweet in lemmatized_tweets]\n",
    "del lemmatized_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete stopwords\n",
    "https://nlp.stanford.edu/IR-book/html/htmledition/dropping-common-terms-stop-words-1.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "359\n",
      "\n",
      "Compare tweets before / after\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3</th>\n",
       "      <th>final_tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gas by my house hit $3.39!!!! I'm going to Cha...</td>\n",
       "      <td>gas house hit going chapel hill sat positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Iranian general says Israel's Iron Dome can't ...</td>\n",
       "      <td>iranian general say israels iron dome deal_not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>with J Davlar 11th. Main rivals are team Polan...</td>\n",
       "      <td>davlar th main rival team poland hopefully mak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Talking about ACT's &amp;amp;&amp;amp; SAT's, deciding...</td>\n",
       "      <td>talking acts sats deciding want go college app...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>They may have a SuperBowl in Dallas, but Dalla...</td>\n",
       "      <td>may superbowl dallas dallas winning_not superb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Im bringing the monster load of candy tomorrow...</td>\n",
       "      <td>instant message bringing monster load candy to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Apple software, retail chiefs out in overhaul:...</td>\n",
       "      <td>apple software retail chief overhaul san franc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>@oluoch @victor_otti @kunjand I just watched i...</td>\n",
       "      <td>watched sridevis comeback remember sun morning...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>#Livewire Nadal confirmed for Mexican Open in ...</td>\n",
       "      <td>livewire nadal confirmed mexican open february...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>@MsSheLahY I didnt want to just pop up... but ...</td>\n",
       "      <td>didnt want pop yep chapel hill next wednesday ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    3  \\\n",
       "0   Gas by my house hit $3.39!!!! I'm going to Cha...   \n",
       "3   Iranian general says Israel's Iron Dome can't ...   \n",
       "6   with J Davlar 11th. Main rivals are team Polan...   \n",
       "7   Talking about ACT's &amp;&amp; SAT's, deciding...   \n",
       "9   They may have a SuperBowl in Dallas, but Dalla...   \n",
       "10  Im bringing the monster load of candy tomorrow...   \n",
       "11  Apple software, retail chiefs out in overhaul:...   \n",
       "12  @oluoch @victor_otti @kunjand I just watched i...   \n",
       "14  #Livewire Nadal confirmed for Mexican Open in ...   \n",
       "15  @MsSheLahY I didnt want to just pop up... but ...   \n",
       "\n",
       "                                         final_tweets  \n",
       "0        gas house hit going chapel hill sat positive  \n",
       "3   iranian general say israels iron dome deal_not...  \n",
       "6   davlar th main rival team poland hopefully mak...  \n",
       "7   talking acts sats deciding want go college app...  \n",
       "9   may superbowl dallas dallas winning_not superb...  \n",
       "10  instant message bringing monster load candy to...  \n",
       "11  apple software retail chief overhaul san franc...  \n",
       "12  watched sridevis comeback remember sun morning...  \n",
       "14  livewire nadal confirmed mexican open february...  \n",
       "15  didnt want pop yep chapel hill next wednesday ...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend([word+'_not' for word in stop_words]) #negation\n",
    "stop_words = set(stop_words)\n",
    "stop_words.update('j', 'im')\n",
    "print (len(stop_words))\n",
    "\n",
    "# remove stopwords\n",
    "def rem_stop(tweet):\n",
    "    words = tweet.split()\n",
    "    tweet = ' '.join([word for word in words if word not in stop_words])\n",
    "    return tweet\n",
    "\n",
    "final_tweets = [rem_stop(tweet) for tweet in preprocessed_tweets]\n",
    "del raw_tweets, preprocessed_tweets\n",
    "\n",
    "print(\"\\nCompare tweets before / after\")\n",
    "df['final_tweets'] = final_tweets\n",
    "df[[3, 'final_tweets']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## <font color='red'>Lexicon Classification</font>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using MPQA Lexicon\n",
    "\n",
    "These are the very first and last entries of the file 'mpqa.txt'\n",
    "- abandoned priorpolarity=negative\n",
    "- abandonment priorpolarity=negative\n",
    "- abandon priorpolarity=negative\n",
    "- abase priorpolarity=negative\n",
    "- abasement priorpolarity=negative\n",
    "- ...\n",
    "- zealot priorpolarity=negative\n",
    "- zealous priorpolarity=negative\n",
    "- zealously priorpolarity=negative\n",
    "- zenith priorpolarity=positive\n",
    "- zest priorpolarity=positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of MPQA words: 13772\n",
      "['watched', 'sridevis', 'positive', 'remember', 'sun', 'morning', 'nta', 'positive']\n",
      "['neutral', 'positive', 'negative']\n",
      "gas house hit going chapel hill sat positive\n",
      "['gas', 'house', 'hit', 'going', 'chapel', 'hill', 'sat', 'positive']\n"
     ]
    }
   ],
   "source": [
    "def MPQAdictionary(filename):\n",
    "    \"\"\"\n",
    "    reads mpqa file which contains the polarity of some of the english words. e.g. 'love': 'positive'\n",
    "    \"\"\"\n",
    "    MPQA_scores = {'priorpolarity=positive\\n': 'positive','priorpolarity=negative\\n': 'negative',\n",
    "                  'priorpolarity=neutral\\n': 'neutral', 'priorpolarity=both\\n': 'neutral'}\n",
    "    MPQA_score_list = {}\n",
    "    fi = open(filename,\"r\")\n",
    "    line = fi.readline()\n",
    "    while line: \n",
    "        li = line.split(\" \")\n",
    "        l2 = li[:-1] # the word as a list\n",
    "        sentiment=li[1] #the word's polarity\n",
    "        score=MPQA_scores[sentiment]\n",
    "        l2.append(score)\n",
    "        for i in range(0,len(l2)-1):\n",
    "            MPQA_score_list[l2[i]]=l2[-1]\n",
    "            # negation\n",
    "            if l2[-1] == 'positive':\n",
    "                MPQA_score_list[l2[i]+'_not']='positive' \n",
    "            else:\n",
    "                MPQA_score_list[l2[i]+'_not']='negative' \n",
    "        line=fi.readline()\n",
    "    return MPQA_score_list\n",
    "\n",
    "\n",
    "def subsMPQA(tweet,d):\n",
    "    tweet = TT.tokenize(tweet)\n",
    "    return [d[i] if i in d.keys() else i for i in tweet]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dictionary = MPQAdictionary('./resources/mpqa/mpqa.txt')\n",
    "print (\"Number of MPQA words: %d\" % len(dictionary.keys()))\n",
    "raw_tweets_MPQA = [subsMPQA(tweet,dictionary) for tweet in final_tweets]\n",
    "\n",
    "# watched sridevis comeback remember sun morning nta positive\n",
    "print (subsMPQA(final_tweets[7], dictionary))\n",
    "print(subsMPQA(\"surprise happy abandoned\", dictionary))\n",
    "\n",
    "print (final_tweets[0])\n",
    "print (raw_tweets_MPQA[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### WordSat Corpus\n",
    "These are the very first and last entries of the file 'WordSat_pos.txt':\n",
    "- ABIDE\n",
    "- ABIDED\n",
    "- ABIDES\n",
    "- ABIDING\n",
    "- ABILITY\n",
    "- ...\n",
    "- ZENITHS\n",
    "- ZEST\n",
    "- ZESTFULLY\n",
    "- ZESTFULNESS\n",
    "- ZESTS\n",
    "\n",
    "These are the very first and last entries of the file 'WordSat_neg.txt':\n",
    "- ABANDON\n",
    "- ABASE\n",
    "- ABASED\n",
    "- ABASES\n",
    "- ABATE\n",
    "- ...\n",
    "- YUKKY\n",
    "- ZEALOT\n",
    "- ZEALOTS\n",
    "- ZEALOUS\n",
    "- ZEALOUSLY\n",
    "- ZILCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive words 13841\n",
      "Number of negative words 13841\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['positive', 'firas', 'positive']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ENGLISH_WSD_LOCATION = os.path.join('resources/WSD')\n",
    "POS_WORDS_FILE = os.path.join(ENGLISH_WSD_LOCATION, 'WordSat_pos.txt')\n",
    "NEG_WORDS_FILE = os.path.join(ENGLISH_WSD_LOCATION, 'WordSat_neg.txt')\n",
    "\n",
    "pos_words = []\n",
    "neg_words = []\n",
    "\n",
    "for pos_word in open(POS_WORDS_FILE, 'r').readlines():\n",
    "    pos_word = pos_word.split(' ')[0]\n",
    "    if \"_\" not in pos_word:\n",
    "        pos_words.append(pos_word.lower().strip('*'))\n",
    "\n",
    "for neg_word in open(NEG_WORDS_FILE, 'r').readlines():\n",
    "    neg_word = neg_word.split(' ')[0]\n",
    "    if \"_\" not in neg_word:\n",
    "        neg_words.append(neg_word.lower().strip('*'))\n",
    "\n",
    "#negation\n",
    "expanded_pos = copy(pos_words)\n",
    "expanded_pos.extend([word+\"_not\" for word in neg_words])\n",
    "expanded_neg = copy(neg_words)\n",
    "expanded_neg.extend([word+\"_not\" for word in pos_words])\n",
    "\n",
    "#change its type into a set\n",
    "expanded_pos = set(expanded_pos)\n",
    "expanded_neg = set(expanded_neg)\n",
    "\n",
    "#delete unnecessary objects\n",
    "del pos_words, neg_words\n",
    "del ENGLISH_WSD_LOCATION, POS_WORDS_FILE, NEG_WORDS_FILE\n",
    "print (\"Number of positive words %d\" % len(expanded_pos))\n",
    "print (\"Number of negative words %d\" % len(expanded_neg))\n",
    "\n",
    "def subs_pos(tweet, pos_words):\n",
    "    return ['positive' if i in pos_words else i for i in tweet]\n",
    "\n",
    "def subs_neg(tweet, neg_words):\n",
    "    return ['negative' if i in neg_words else i for i in tweet]\n",
    "\n",
    "raw_tweets_wsd = [subs_pos(tweet, expanded_pos) for tweet in raw_tweets_MPQA]\n",
    "raw_tweets_wsd = [subs_neg(tweet, expanded_neg) for tweet in raw_tweets_wsd]\n",
    "\n",
    "subs_pos(\"enjoy firas extraordinarily\".split(' '), expanded_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Bing Liu Lexicon\n",
    "These are the very first and last entries of the file 'positive-words.txt':\n",
    "- a+\n",
    "- abound\n",
    "- abounds\n",
    "- abundance\n",
    "- abundant\n",
    "- ...\n",
    "- youthful\n",
    "- zeal\n",
    "- zenith\n",
    "- zest\n",
    "- zippy\n",
    "\n",
    "These are the very first and last entries of the file 'negative-words.txt':\n",
    "- 2-faced\n",
    "- 2-faces\n",
    "- abnormal\n",
    "- abolish\n",
    "- abominable\n",
    "- ...\n",
    "- zaps\n",
    "- zealot\n",
    "- zealous\n",
    "- zealously\n",
    "- zombie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive words 14676\n",
      "Number of negative words 14676\n"
     ]
    }
   ],
   "source": [
    "ENGLISH_OPINION_LEXICON_LOCATION = os.path.join('resources/opinion-lexicon-English')\n",
    "POS_WORDS_FILE = os.path.join(ENGLISH_OPINION_LEXICON_LOCATION, 'positive-words.txt')\n",
    "NEG_WORDS_FILE = os.path.join(ENGLISH_OPINION_LEXICON_LOCATION, 'negative-words.txt')\n",
    "\n",
    "for pos_word in open(POS_WORDS_FILE, 'r').readlines()[35:]:\n",
    "    word = pos_word.rstrip()\n",
    "    expanded_pos.add(word)\n",
    "    expanded_neg.add(word+\"_not\")  #negation\n",
    "\n",
    "for neg_word in open(NEG_WORDS_FILE, 'r').readlines()[35:]:\n",
    "    word = pos_word.rstrip()\n",
    "    expanded_neg.add(word)\n",
    "    expanded_pos.add(word+\"_not\")  #negation\n",
    "\n",
    "\n",
    "#delete unnecessary objects\n",
    "del raw_tweets_MPQA\n",
    "del ENGLISH_OPINION_LEXICON_LOCATION, POS_WORDS_FILE, NEG_WORDS_FILE\n",
    "\n",
    "print (\"Number of positive words %d\" % len(expanded_pos))\n",
    "print (\"Number of negative words %d\" % len(expanded_neg))\n",
    "\n",
    "\n",
    "raw_tweets_bing = [subs_pos(tweet, expanded_pos) for tweet in raw_tweets_wsd]\n",
    "raw_tweets_bing = [subs_neg(tweet, expanded_neg) for tweet in raw_tweets_bing]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Afinn](https://pypi.python.org/pypi/afinn)\n",
    "\n",
    "These are the very first and last entries of 'afinn.txt':\n",
    "- abandon\t-2\n",
    "- abandoned\t-2\n",
    "- abandons\t-2\n",
    "- abducted\t-2\n",
    "- abduction\t-2\n",
    "- ...\n",
    "- yucky\t-2\n",
    "- yummy\t3\n",
    "- zealot\t-2\n",
    "- zealots\t-2\n",
    "- zealous\t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Afinn entries 4922\n"
     ]
    }
   ],
   "source": [
    "def loadAfinn(filename):\n",
    "    f=open(filename,'r')\n",
    "    afinn={}\n",
    "    line=f.readline()\n",
    "    while line:\n",
    "        if \" \" in line:   #exclude entries like 'cool stuff    3'\n",
    "            pass\n",
    "        else:\n",
    "            l=line[:-1].split('\\t') #line[:-1] removes the '\\r\\n' character\n",
    "            afinn[l[0]]=float(l[1])\n",
    "            afinn[l[0]+\"_not\"] = -float(l[1])  # negation\n",
    "        line=f.readline()\n",
    "\n",
    "    return afinn\n",
    "\n",
    "afinn = loadAfinn('./resources/afinn.txt')\n",
    "print (\"Number of Afinn entries %d\" % len(afinn.keys()))\n",
    "del raw_tweets_wsd\n",
    "\n",
    "def afinnPolarity(tweet, afinn):\n",
    "    score=0.0\n",
    "    reps = 0\n",
    "    for w in tweet:\n",
    "        if w in afinn.keys():\n",
    "            reps += 1\n",
    "            score += afinn[w]\n",
    "    return score, reps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SentiWordNet\n",
    "\n",
    "Here is the very first five lines of the csv file 'sentiWordnetBig.csv':\n",
    "\n",
    "|POS|ID|PosSCore|NegScore|SynsetTerms|\n",
    "|-|-------|-----|-----|-------------------|\n",
    "|a|1740|0.125|0|able#1|\n",
    "|a|2098|0|0.75|unable#1|\n",
    "|a|2312|0|0|dorsal#2 abaxial#1|\n",
    "|a|2527|0|0|ventral#2 adaxial#1|\n",
    "|a|2730|0|0|acroscopic#1|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening the SentiWordnet file ...\n",
      "Loading...\n",
      "Number of sentiWordnet entries 294612\n"
     ]
    }
   ],
   "source": [
    "def loadSentiWordnet(filename): \n",
    "    output={}\n",
    "    print (\"Opening the SentiWordnet file ...\")\n",
    "    fi=open(filename,\"r\")\n",
    "    line=fi.readline() # ignore the header\n",
    "    line=fi.readline()\n",
    "    print (\"Loading...\")\n",
    "\n",
    "    while line:\n",
    "        l=line.split('\\t')\n",
    "        try:\n",
    "            sentence=l[4]\n",
    "            new = [word for word in sentence.split() if (word[-2] == \"#\" and word[-1].isdigit())]\n",
    "            pos=abs(float(l[2]))\n",
    "            neg=abs(float(l[3]))\n",
    "            neu=float(pos-neg)\n",
    "        except:\n",
    "            line=fi.readline()\n",
    "            continue\n",
    "\n",
    "        for w in new:\n",
    "            output[(w[:-2])]=neu\n",
    "            output[(w[:-2])+'_not'] = -neu   #negation\n",
    "        line=fi.readline()\n",
    "        \n",
    "    fi.close()\n",
    "    return output\n",
    "\n",
    "\n",
    "sentiWordnet = loadSentiWordnet('./resources/sentiWordnetBig.csv')\n",
    "print (\"Number of sentiWordnet entries %d\" % len(sentiWordnet.keys()))\n",
    "\n",
    "\n",
    "\n",
    "def WordnetPolarity(tweet, sentiWordnet):\n",
    "    score=0.0\n",
    "    reps = 0\n",
    "    for w in tweet:\n",
    "        if w in sentiWordnet.keys():\n",
    "            reps += 1\n",
    "            score += sentiWordnet[w]\n",
    "    return score, reps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SenticNet API\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from senticnet.senticnet import Senticnet\n",
    "\n",
    "def SenticnetPolarity(tweet):\n",
    "    score=0.0\n",
    "    reps = 0\n",
    "    for w in tweet:\n",
    "        try:\n",
    "            score += float(Senticnet().polarity_intense(w))\n",
    "            reps += 1\n",
    "        except KeyError:\n",
    "            pass\n",
    "    return score, reps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polarity calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7205, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bing_mpqa_score</th>\n",
       "      <th>afinn_score</th>\n",
       "      <th>wordnet_score</th>\n",
       "      <th>sem_eval_score</th>\n",
       "      <th>Senticnet_score</th>\n",
       "      <th>final_score</th>\n",
       "      <th>final_tweets</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.005781</td>\n",
       "      <td>0.005633</td>\n",
       "      <td>-0.003455</td>\n",
       "      <td>0.008469</td>\n",
       "      <td>0.003540</td>\n",
       "      <td>0.013675</td>\n",
       "      <td>gas house hit going chapel hill sat positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.011561</td>\n",
       "      <td>0.011266</td>\n",
       "      <td>0.003455</td>\n",
       "      <td>-0.003356</td>\n",
       "      <td>0.015782</td>\n",
       "      <td>0.027025</td>\n",
       "      <td>iranian general say israels iron dome deal_not...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.005781</td>\n",
       "      <td>0.005633</td>\n",
       "      <td>-0.017275</td>\n",
       "      <td>-0.002014</td>\n",
       "      <td>0.003375</td>\n",
       "      <td>0.014828</td>\n",
       "      <td>davlar th main rival team poland hopefully mak...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.010365</td>\n",
       "      <td>0.004899</td>\n",
       "      <td>-0.016398</td>\n",
       "      <td>-0.064760</td>\n",
       "      <td>talking acts sats deciding want go college app...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.005781</td>\n",
       "      <td>-0.005633</td>\n",
       "      <td>-0.008637</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.011845</td>\n",
       "      <td>-0.041825</td>\n",
       "      <td>may superbowl dallas dallas winning_not superb...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.005781</td>\n",
       "      <td>-0.005633</td>\n",
       "      <td>-0.017275</td>\n",
       "      <td>0.016953</td>\n",
       "      <td>0.004123</td>\n",
       "      <td>-0.021357</td>\n",
       "      <td>instant message bringing monster load candy to...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005182</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.008900</td>\n",
       "      <td>-0.014088</td>\n",
       "      <td>apple software retail chief overhaul san franc...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.011561</td>\n",
       "      <td>0.011266</td>\n",
       "      <td>0.005182</td>\n",
       "      <td>0.006484</td>\n",
       "      <td>0.014082</td>\n",
       "      <td>0.059524</td>\n",
       "      <td>watched sridevis comeback remember sun morning...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.011561</td>\n",
       "      <td>0.011266</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009598</td>\n",
       "      <td>0.011402</td>\n",
       "      <td>0.028304</td>\n",
       "      <td>livewire nadal confirmed mexican open february...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.011561</td>\n",
       "      <td>0.011266</td>\n",
       "      <td>-0.001727</td>\n",
       "      <td>0.018295</td>\n",
       "      <td>-0.002170</td>\n",
       "      <td>0.075563</td>\n",
       "      <td>didnt want pop yep chapel hill next wednesday ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    bing_mpqa_score  afinn_score  wordnet_score  sem_eval_score  \\\n",
       "0          0.005781     0.005633      -0.003455        0.008469   \n",
       "3          0.011561     0.011266       0.003455       -0.003356   \n",
       "6          0.005781     0.005633      -0.017275       -0.002014   \n",
       "7          0.000000     0.000000      -0.010365        0.004899   \n",
       "9         -0.005781    -0.005633      -0.008637        0.000000   \n",
       "10        -0.005781    -0.005633      -0.017275        0.016953   \n",
       "11         0.000000     0.000000      -0.005182        0.000000   \n",
       "12         0.011561     0.011266       0.005182        0.006484   \n",
       "14         0.011561     0.011266       0.000000        0.009598   \n",
       "15         0.011561     0.011266      -0.001727        0.018295   \n",
       "\n",
       "    Senticnet_score  final_score  \\\n",
       "0          0.003540     0.013675   \n",
       "3          0.015782     0.027025   \n",
       "6          0.003375     0.014828   \n",
       "7         -0.016398    -0.064760   \n",
       "9         -0.011845    -0.041825   \n",
       "10         0.004123    -0.021357   \n",
       "11        -0.008900    -0.014088   \n",
       "12         0.014082     0.059524   \n",
       "14         0.011402     0.028304   \n",
       "15        -0.002170     0.075563   \n",
       "\n",
       "                                         final_tweets         2  \n",
       "0        gas house hit going chapel hill sat positive  positive  \n",
       "3   iranian general say israels iron dome deal_not...  negative  \n",
       "6   davlar th main rival team poland hopefully mak...  positive  \n",
       "7   talking acts sats deciding want go college app...  negative  \n",
       "9   may superbowl dallas dallas winning_not superb...  negative  \n",
       "10  instant message bringing monster load candy to...   neutral  \n",
       "11  apple software retail chief overhaul san franc...   neutral  \n",
       "12  watched sridevis comeback remember sun morning...  positive  \n",
       "14  livewire nadal confirmed mexican open february...   neutral  \n",
       "15  didnt want pop yep chapel hill next wednesday ...  positive  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BingMpqaScore = []\n",
    "AfinnScore, AfinnReps = [], []\n",
    "WordnetScore, WordnetReps = [], []\n",
    "SenticnetScore, SenticnetReps = [], []\n",
    "length = len(raw_tweets_bing)\n",
    "\n",
    "for tw in raw_tweets_bing:\n",
    "    Bing_MPQA = 0\n",
    "    for i in tw:\n",
    "        if (i == 'positive'):\n",
    "            Bing_MPQA +=  1\n",
    "        if (i == 'negative'):\n",
    "            Bing_MPQA -= 1\n",
    "    BingMpqaScore.append(Bing_MPQA)\n",
    "    tmp = afinnPolarity(tw, afinn)\n",
    "    AfinnScore.append(tmp[0])\n",
    "    AfinnReps.append(tmp[1])\n",
    "    tmp = WordnetPolarity(tw, sentiWordnet)\n",
    "    WordnetScore.append(tmp[0])\n",
    "    WordnetReps.append(tmp[1])\n",
    "    tmp = SenticnetPolarity(tw)\n",
    "    SenticnetScore.append(tmp[0])\n",
    "    SenticnetReps.append(tmp[1])\n",
    "\n",
    "    \n",
    "#reshape\n",
    "BingMpqaScore = np.array(BingMpqaScore).reshape(length, 1)\n",
    "AfinnScore = np.array(AfinnScore).reshape(length, 1)\n",
    "AfinnReps = np.array(AfinnReps).reshape(length, 1)\n",
    "WordnetScore = np.array(WordnetScore).reshape(length, 1)\n",
    "WordnetReps = np.array(WordnetReps).reshape(length, 1)\n",
    "SemEvalScore = np.array(SemEvalScore).reshape(length, 1)\n",
    "SemEvalReps = np.array(SemEvalReps).reshape(length, 1)\n",
    "SenticnetScore = np.array(SenticnetScore).reshape(length, 1)\n",
    "SenticnetReps = np.array(SenticnetReps).reshape(length, 1)\n",
    "unigram140Score = np.array(unigram140Score).reshape(length, 1)\n",
    "unigram140Reps = np.array(unigram140Reps).reshape(length, 1)\n",
    "bigram140Score = np.array(bigram140Score).reshape(length, 1)\n",
    "bigram140Reps = np.array(bigram140Reps).reshape(length, 1)\n",
    "\n",
    "#Normalization\n",
    "BingMpqaScore = BingMpqaScore/np.linalg.norm(BingMpqaScore)\n",
    "AfinnScore = AfinnScore/np.linalg.norm(AfinnScore)\n",
    "AfinnReps = AfinnReps/np.linalg.norm(AfinnReps)\n",
    "WordnetScore = WordnetScore/np.linalg.norm(WordnetScore)\n",
    "WordnetReps = WordnetReps/np.linalg.norm(WordnetReps)\n",
    "SemEvalScore = SemEvalScore/np.linalg.norm(SemEvalScore)\n",
    "SemEvalReps = SemEvalReps/np.linalg.norm(SemEvalReps)\n",
    "SenticnetScore = SenticnetScore/np.linalg.norm(SenticnetScore)\n",
    "SenticnetReps = SenticnetReps/np.linalg.norm(SenticnetReps)\n",
    "unigram140Score = unigram140Score/np.linalg.norm(unigram140Score)\n",
    "unigram140Reps = unigram140Reps/np.linalg.norm(unigram140Reps)\n",
    "bigram140Score = bigram140Score/np.linalg.norm(bigram140Score)\n",
    "bigram140Reps = bigram140Reps/np.linalg.norm(bigram140Reps)\n",
    "\n",
    "\n",
    "\n",
    "#final_score_tweets (my score list)\n",
    "df['bing_mpqa_score'] = BingMpqaScore\n",
    "df['afinn_score'] = AfinnScore\n",
    "df['wordnet_score'] = WordnetScore\n",
    "df['sem_eval_score'] = SemEvalScore\n",
    "df['Senticnet_score'] = SenticnetScore\n",
    "all_scores = np.hstack( (BingMpqaScore, AfinnScore, WordnetScore, SemEvalScore, SenticnetScore, \\\n",
    "                                                                         unigram140Score, bigram140Score) )\n",
    "sum_score = np.sum(all_scores, axis=1).reshape(length, 1)\n",
    "print (all_scores.shape)\n",
    "df['final_score'] = sum_score\n",
    "\n",
    "df[['bing_mpqa_score','afinn_score', 'wordnet_score', 'sem_eval_score', 'Senticnet_score', \\\n",
    "                                'final_score', 'final_tweets' ,2]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Comparing the scores with the real results, we can conclude that the use of lexicon does not give very good results ... We must add scores for bi-grams.\n",
    "##### You must then combine the lexicon / machine learning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del df, raw_tweets_bing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## <font color='red'>Train the model</font>\n",
    "***\n",
    "#### Create a feature vector\n",
    "* See [Bag of Words](https://en.wikipedia.org/wiki/Bag-of-words_model) for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7205, 139521)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vectorizer = CountVectorizer(analyzer='word', preprocessor=None, stop_words=None, tokenizer=None, ngram_range=(1,3))\n",
    "count_features = count_vectorizer.fit_transform(final_tweets)\n",
    "count_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7205, 5)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reducing the CountVector\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_components=5, n_iter=7, random_state=42)\n",
    "count_features = svd.fit_transform(count_features)\n",
    "count_features = scipy.sparse.csr_matrix(count_features)\n",
    "print (type(count_features))\n",
    "count_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7205, 139521)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(analyzer='word', ngram_range=(1,3))\n",
    "tfidf_features = tfidf_vectorizer.fit_transform(final_tweets)\n",
    "del final_tweets\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7205, 7) (7205, 1) (7205, 1) (7205, 1) (7205, 1)\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "(7205, 14)\n"
     ]
    }
   ],
   "source": [
    "print (all_scores.shape, sum_score.shape, AfinnReps.shape, WordnetReps.shape, SemEvalReps.shape)\n",
    "final_total = scipy.sparse.csr_matrix(np.hstack( (all_scores, sum_score, AfinnReps, \\\n",
    "                                        SenticnetReps, WordnetReps, SemEvalReps, unigram140Reps, bigram140Reps) ))\n",
    "print (type(final_total))\n",
    "print (final_total.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7205, 139540)\n"
     ]
    }
   ],
   "source": [
    "features = scipy.sparse.hstack([count_features, tfidf_features, final_total])\n",
    "print (features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# delete unnecessary data objects\n",
    "del all_scores, sum_score, BingMpqaScore, AfinnScore, WordnetScore, SemEvalScore, SenticnetScore, \\\n",
    "    unigram140Score, bigram140Score\n",
    "del AfinnReps, WordnetReps, SemEvalReps, unigram140Reps, bigram140Reps\n",
    "del count_features, tfidf_features, final_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Put labels to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7205,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapper = {'positive': 1, 'negative': -1, 'neutral': 0}\n",
    "\n",
    "labels = labels.map(mapper)\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import SVM\n",
    "\n",
    "http://scikit-learn.org/stable/modules/svm.html\n",
    "\n",
    "For a mathematical overview,\n",
    "https://docs.opencv.org/2.4/doc/tutorials/ml/introduction_to_svm/introduction_to_svm.html\n",
    "\n",
    "#### Get the optimal regulation parameter using handout method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anwar/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.597211537819\n",
      "20\n",
      "{'C': 2.0997880359949823, 'gamma': 0.14634856553062073}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7f069dd150b8>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEKCAYAAAARnO4WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niEhIKOCLiISEAr6ISEgo4IuIhMT/B/QGdABrKKskAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f069dd02160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Takes around 30 minutes\n",
    "rand_list = {\"C\": scipy.stats.uniform(0, 5),\n",
    "             \"gamma\": scipy.stats.uniform(0.1, 1)}\n",
    "\n",
    "rand_search = RandomizedSearchCV(SVC(kernel='linear'), param_distributions = rand_list,\\\n",
    "                                 n_iter = 20, n_jobs = 4, scoring = 'f1_macro')\n",
    "rand_search.fit(features, labels)\n",
    "\n",
    "print(rand_search.best_score_)\n",
    "print (len(rand_search.cv_results_['param_C'].data))\n",
    "print (rand_search.best_params_)\n",
    "\n",
    "rand_search.cv_results_['param_gamma'].data\n",
    "plt.plot(sorted(rand_search.cv_results_['mean_test_score']), rand_search.cv_results_['param_C'].data, \"-\")\n",
    "plt.xlabel(\"Mean Test Score\")\n",
    "plt.ylabel(\"C value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=2.0997880359949823, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma=0.14634856553062073,\n",
       "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KERNEL = 'linear'\n",
    "classifier = SVC(kernel=KERNEL, C=rand_search.best_params_['C'], gamma=rand_search.best_params_['gamma'])\n",
    "classifier.fit(features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9950\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "nb_predict_train = classifier.predict(features)\n",
    "#check accuracy\n",
    "print(\"Accuracy: {:0.4f}\".format(metrics.accuracy_score(labels, nb_predict_train)))\n",
    "del features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2674    1   17]\n",
      " [   2 1008   14]\n",
      " [   2    0 3487]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       1.00      0.99      1.00      2692\n",
      "         -1       1.00      0.98      0.99      1024\n",
      "          0       0.99      1.00      1.00      3489\n",
      "\n",
      "avg / total       1.00      1.00      1.00      7205\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print confusion matrix\n",
    "print(\"{}\".format(metrics.confusion_matrix(labels, nb_predict_train, labels=[1,-1, 0])))\n",
    "\n",
    "print(\"{}\".format(metrics.classification_report(labels, nb_predict_train, labels=[1, -1, 0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict using the model\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8902, 4)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_df = pd.read_csv('./data/test/actual/test_B_labeled.tsv', sep='\\t', header=None)\n",
    "t_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7584, 4)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_df = t_df[t_df[3] != 'Not Available']\n",
    "t_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnMAAAHoCAYAAAAi+WkTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f069dc2a4e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The bar chart for the test data set\n",
    "\n",
    "y = [len(t_df[t_df[2] == i]) for i in ['positive', 'negative', 'neutral']]\n",
    "x = ['positive', 'negative', 'neutral']\n",
    "x_pos = range(len(x))\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.bar(x_pos, y, alpha=0.5)\n",
    "plt.xticks(x_pos, x)\n",
    "plt.ylabel('# Occurences').set_size(15)\n",
    "plt.xlabel('Classes').set_size(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-process tweets from the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_tweets_test = t_df[3]\n",
    "\n",
    "t_unigram140Score, t_unigram140Reps = [], []\n",
    "for tweet in raw_tweets_test:\n",
    "    score, reps = unigram140Polarity(tweet.lower(), unigram140_d)\n",
    "    t_unigram140Score.append(score)\n",
    "    t_unigram140Reps.append(reps)\n",
    "\n",
    "t_bigram140Score, t_bigram140Reps = [], []\n",
    "for tweet in raw_tweets_test:\n",
    "    score, reps = bigram140Polarity(tweet.lower(), bigram140_d)\n",
    "    t_bigram140Score.append(score)\n",
    "    t_bigram140Reps.append(reps)\n",
    "\n",
    "t_SemEvalScore, t_SemEvalReps = [], []\n",
    "for tweet in raw_tweets_test:\n",
    "    score, reps = SemEvalLexiconPolarity(tweet.lower(), EnglishLexicon)\n",
    "    t_SemEvalScore.append(score)\n",
    "    t_SemEvalReps.append(reps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw_tweets_test = [replaceSlangs(tweet, slangs) for tweet in raw_tweets_test]\n",
    "raw_tweets_test = [replace_apostrophe(tweet, apos) for tweet in raw_tweets_test]\n",
    "raw_tweets_test = [subsEmoticon(tweet, dict) for tweet in raw_tweets_test]\n",
    "raw_tweets_test = [handle_negation(tweet) for tweet in raw_tweets_test] #negation\n",
    "lemmatized_tweets_test = [lemma(tweet) for tweet in raw_tweets_test]\n",
    "preprocessed_tweets_test = [preprocess(tweet) for tweet in lemmatized_tweets_test]\n",
    "final_tweets_test = [rem_stop(tweet) for tweet in preprocessed_tweets_test]\n",
    "t_df[3] = final_tweets_test\n",
    "\n",
    "del raw_tweets_test, lemmatized_tweets_test, preprocessed_tweets_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done scoring test set ..\n",
      "Done reshaping test set ..\n",
      "Done normalizing test set ..\n",
      "(7584, 7)\n"
     ]
    }
   ],
   "source": [
    "t_raw_tweets_MPQA = [subsMPQA(tweet,dictionary) for tweet in final_tweets_test]\n",
    "t_raw_tweets_wsd = [subs_pos(tweet, expanded_pos) for tweet in t_raw_tweets_MPQA]\n",
    "t_raw_tweets_wsd = [subs_neg(tweet, expanded_neg) for tweet in t_raw_tweets_wsd]\n",
    "t_raw_tweets_bing = [subs_pos(tweet, expanded_pos) for tweet in t_raw_tweets_wsd]\n",
    "t_raw_tweets_bing = [subs_neg(tweet, expanded_neg) for tweet in t_raw_tweets_bing]\n",
    "\n",
    "t_BingMpqaScore = []\n",
    "t_AfinnScore, t_AfinnReps = [], []\n",
    "t_WordnetScore, t_WordnetReps = [], []\n",
    "t_SenticnetScore, t_SenticnetReps = [], []\n",
    "t_length = len(t_raw_tweets_bing)\n",
    "\n",
    "for tw in t_raw_tweets_bing:\n",
    "    Bing_MPQA = 0\n",
    "    for i in tw:\n",
    "        if (i == 'positive'):\n",
    "            Bing_MPQA +=  1\n",
    "        if (i == 'negative'):\n",
    "            Bing_MPQA -= 1\n",
    "    t_BingMpqaScore.append(Bing_MPQA)\n",
    "    tmp = afinnPolarity(tw, afinn)\n",
    "    t_AfinnScore.append(tmp[0])\n",
    "    t_AfinnReps.append(tmp[1])\n",
    "    tmp = WordnetPolarity(tw, sentiWordnet)\n",
    "    t_WordnetScore.append(tmp[0])\n",
    "    t_WordnetReps.append(tmp[1])\n",
    "    tmp = SenticnetPolarity(tw)\n",
    "    t_SenticnetScore.append(tmp[0])\n",
    "    t_SenticnetReps.append(tmp[1])\n",
    "print(\"Done scoring test set ..\")\n",
    "    \n",
    "#reshape\n",
    "t_BingMpqaScore = np.array(t_BingMpqaScore).reshape(t_length, 1)\n",
    "t_AfinnScore = np.array(t_AfinnScore).reshape(t_length, 1)\n",
    "t_AfinnReps = np.array(t_AfinnReps).reshape(t_length, 1)\n",
    "t_WordnetScore = np.array(t_WordnetScore).reshape(t_length, 1)\n",
    "t_WordnetReps = np.array(t_WordnetReps).reshape(t_length, 1)\n",
    "t_SemEvalScore = np.array(t_SemEvalScore).reshape(t_length, 1)\n",
    "t_SemEvalReps = np.array(t_SemEvalReps).reshape(t_length, 1)\n",
    "t_SenticnetScore = np.array(t_SenticnetScore).reshape(t_length, 1)\n",
    "t_SenticnetReps = np.array(t_SenticnetReps).reshape(t_length, 1)\n",
    "t_unigram140Score = np.array(t_unigram140Score).reshape(t_length, 1)\n",
    "t_unigram140Reps = np.array(t_unigram140Reps).reshape(t_length, 1)\n",
    "t_bigram140Score = np.array(t_bigram140Score).reshape(t_length, 1)\n",
    "t_bigram140Reps = np.array(t_bigram140Reps).reshape(t_length, 1)\n",
    "print(\"Done reshaping test set ..\")\n",
    "\n",
    "#Normalization\n",
    "t_BingMpqaScore = t_BingMpqaScore/np.linalg.norm(t_BingMpqaScore)\n",
    "t_AfinnScore = t_AfinnScore/np.linalg.norm(t_AfinnScore)\n",
    "t_AfinnReps = t_AfinnReps/np.linalg.norm(t_AfinnReps)\n",
    "t_WordnetScore = t_WordnetScore/np.linalg.norm(t_WordnetScore)\n",
    "t_WordnetReps = t_WordnetReps/np.linalg.norm(t_WordnetReps)\n",
    "t_SemEvalScore = t_SemEvalScore/np.linalg.norm(t_SemEvalScore)\n",
    "t_SemEvalReps = t_SemEvalReps/np.linalg.norm(t_SemEvalReps)\n",
    "t_SenticnetScore = t_SenticnetScore/np.linalg.norm(t_SenticnetScore)\n",
    "t_SenticnetReps = t_SenticnetReps/np.linalg.norm(t_SenticnetReps)\n",
    "t_unigram140Score = t_unigram140Score/np.linalg.norm(t_unigram140Score)\n",
    "t_unigram140Reps = t_unigram140Reps/np.linalg.norm(t_unigram140Reps)\n",
    "t_bigram140Score = t_bigram140Score/np.linalg.norm(t_bigram140Score)\n",
    "t_bigram140Reps = t_bigram140Reps/np.linalg.norm(t_bigram140Reps)\n",
    "print(\"Done normalizing test set ..\")\n",
    "\n",
    "t_all_scores = np.hstack( (t_BingMpqaScore, t_AfinnScore, t_WordnetScore, t_SemEvalScore, t_SenticnetScore, \\\n",
    "                                               t_unigram140Score, t_bigram140Score) )\n",
    "t_sum_score = np.sum(t_all_scores, axis=1).reshape(t_length, 1)\n",
    "print (t_all_scores.shape)\n",
    "\n",
    "# Delete\n",
    "del t_raw_tweets_MPQA, t_raw_tweets_bing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>282031301962395648</td>\n",
       "      <td>T14111200</td>\n",
       "      <td>neutral</td>\n",
       "      <td>dec st know end_not world_not baby_not boom_no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11975</td>\n",
       "      <td>SM112166</td>\n",
       "      <td>negative</td>\n",
       "      <td>yar quite clever aft many guess lor got ask br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>136592</td>\n",
       "      <td>LJ112295</td>\n",
       "      <td>negative</td>\n",
       "      <td>yeah thin lizzy hate informercial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>253421252956545024</td>\n",
       "      <td>T13114433</td>\n",
       "      <td>neutral</td>\n",
       "      <td>mt syria deir ezzor ali bashar altheeb wa mart...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>220880422320603137</td>\n",
       "      <td>T14114138</td>\n",
       "      <td>negative</td>\n",
       "      <td>hate life see_not roskilde_not festival_not sa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0          1         2  \\\n",
       "2  282031301962395648  T14111200   neutral   \n",
       "3               11975   SM112166  negative   \n",
       "4              136592   LJ112295  negative   \n",
       "5  253421252956545024  T13114433   neutral   \n",
       "6  220880422320603137  T14114138  negative   \n",
       "\n",
       "                                                   3  \n",
       "2  dec st know end_not world_not baby_not boom_no...  \n",
       "3  yar quite clever aft many guess lor got ask br...  \n",
       "4                  yeah thin lizzy hate informercial  \n",
       "5  mt syria deir ezzor ali bashar altheeb wa mart...  \n",
       "6  hate life see_not roskilde_not festival_not sa...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the features vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7584, 5)\n",
      "(7584, 139521)\n"
     ]
    }
   ],
   "source": [
    "test_count_features = count_vectorizer.transform(final_tweets_test)\n",
    "test_count_features = svd.transform(test_count_features)\n",
    "test_count_features = scipy.sparse.csr_matrix(test_count_features)\n",
    "print (test_count_features.shape)\n",
    "\n",
    "\n",
    "test_tfidf_features = tfidf_vectorizer.transform(final_tweets_test)\n",
    "test_tfidf_features = scipy.sparse.csr_matrix(test_tfidf_features)\n",
    "print (test_tfidf_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7584, 14)\n",
      "(7584, 139540)\n"
     ]
    }
   ],
   "source": [
    "t_final_total = scipy.sparse.csr_matrix(np.hstack( (t_all_scores, t_sum_score, t_AfinnReps, t_WordnetReps, \\\n",
    "                                            t_SemEvalReps, t_SenticnetReps, t_unigram140Reps, t_bigram140Reps) ))\n",
    "print (t_final_total.shape)\n",
    "test_features = scipy.sparse.hstack([test_count_features, test_tfidf_features, t_final_total])\n",
    "print (test_features.shape)\n",
    "\n",
    "del t_all_scores, t_sum_score, t_BingMpqaScore, t_AfinnScore, t_WordnetScore, t_SemEvalScore, \\\n",
    "    t_SenticnetScore, t_unigram140Score, t_bigram140Score\n",
    "del t_AfinnReps, t_WordnetReps, t_SemEvalReps, t_unigram140Reps, t_bigram140Reps\n",
    "del test_count_features, test_tfidf_features, t_final_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get labels from a set of test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7584,)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_labels = t_df[2]\n",
    "actual_labels = actual_labels.map(mapper)\n",
    "actual_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict labels using the template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted_labels = classifier.predict(test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Model\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 68.26%\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {:0.2f}%'.format(metrics.accuracy_score(actual_labels, predicted_labels) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy of cross-validation 10 times on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from sklearn import model_selection\n",
    "\n",
    "# scores = model_selection.cross_val_score(classifier, test_features, actual_labels, cv=10, scoring='accuracy')\n",
    "# print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "# del test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.64      0.52      0.58      1296\n",
      "          0       0.66      0.80      0.72      3448\n",
      "          1       0.75      0.61      0.67      2840\n",
      "\n",
      "avg / total       0.69      0.68      0.68      7584\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# draw the classification report\n",
    "print('{}'.format(metrics.classification_report(actual_labels, predicted_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See [Confusion Matrix](https://fr.wikipedia.org/wiki/Matrice_de_confusion) for more details\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1737  147  956]\n",
      " [ 128  677  491]\n",
      " [ 453  232 2763]]\n",
      "\n",
      "\u001b[31m\" macro f1 score \"\u001b[0m\n",
      "0.65693182255229\n",
      "\n",
      "\u001b[31m\" micro f1 score \"\u001b[0m\n",
      "0.6826213080168776\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print('{}\\n'.format(metrics.confusion_matrix(actual_labels, predicted_labels, labels=[1,-1,0])))\n",
    "print(\"\\x1b[31m\\\" macro f1 score \\\"\\x1b[0m\")\n",
    "print('{}\\n'.format(metrics.f1_score(actual_labels, predicted_labels, average='macro')))\n",
    "print(\"\\x1b[31m\\\" micro f1 score \\\"\\x1b[0m\")\n",
    "print('{}\\n'.format(metrics.f1_score(actual_labels, predicted_labels, average='micro')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison with the 5 best teams of subtask B\n",
    "\n",
    "We compare our average f-score with the other teams in the workshop. The results are taken from the attached document:\n",
    "[Final report SemEval 2014 Subtask 9](http://www.aclweb.org/anthology/S14-2009)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Team|Accuracy (Macro Averaged)| Accuracy (Micro Averaged)|\n",
    "|----|-------------------------|--------------------------|\n",
    "|TeamX|65.63%|69.99%|\n",
    "|coooolll|63.23%|70.51%|\n",
    "|RTRGO|63.08%|70.15%|\n",
    "|NRC-Canada|67.62%|71.37%|\n",
    "|TUGAS|63.89%|68.84%|\n",
    "|**_ME_**|_57.48%_|_64.86%_|\n",
    "| | |***classement : 23 / 50***|\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
