{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# <font color='green'>Analyse des sentiments</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>Lecture des données</font>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importer les bibliothèques\n",
    "\n",
    "Reportez-vous aux pages Web pour les bibliothèques individuelles\n",
    "* [pandas] (http://pandas.pydata.org/), pour charger et gérer les données\n",
    "* [matplotlib] (http://matplotlib.org/), pour la visualisation\n",
    "* [numpy] (http://www.numpy.org/) pour peindre la représentation et la manipulation\n",
    "* [re] (https://docs.python.org/3/library/re.html) pour l'expression régulière\n",
    "* [nltk] (http://www.nltk.org/) pour le prétraitement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "from copy import copy\n",
    "import collections\n",
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import make_scorer, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lecture de l'ensemble de données\n",
    "Certaines des données \"uploaded_cleansed_B\" sont produites à partir de \"uploaded_cleansed_A\". La différence est:\n",
    "- \"uploaded_cleansed_A\" a trois colonnes que nous n'utiliserons pas.\n",
    "- \"uploaded_cleansed_A\" a des tweets répété."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9665, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>264183816548130816</td>\n",
       "      <td>15140428</td>\n",
       "      <td>positive</td>\n",
       "      <td>Gas by my house hit $3.39!!!! I'm going to Cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>263405084770172928</td>\n",
       "      <td>591166521</td>\n",
       "      <td>negative</td>\n",
       "      <td>Not Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>262163168678248449</td>\n",
       "      <td>35266263</td>\n",
       "      <td>negative</td>\n",
       "      <td>Not Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>264249301910310912</td>\n",
       "      <td>18516728</td>\n",
       "      <td>negative</td>\n",
       "      <td>Iranian general says Israel's Iron Dome can't ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>262682041215234048</td>\n",
       "      <td>254373818</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Not Available</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0          1         2  \\\n",
       "0  264183816548130816   15140428  positive   \n",
       "1  263405084770172928  591166521  negative   \n",
       "2  262163168678248449   35266263  negative   \n",
       "3  264249301910310912   18516728  negative   \n",
       "4  262682041215234048  254373818   neutral   \n",
       "\n",
       "                                                   3  \n",
       "0  Gas by my house hit $3.39!!!! I'm going to Cha...  \n",
       "1                                      Not Available  \n",
       "2                                      Not Available  \n",
       "3  Iranian general says Israel's Iron Dome can't ...  \n",
       "4                                      Not Available  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/data/train/downloaded_cleansed_B.tsv', sep= '\\t', header=None)\n",
    "print (df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notez que certains tweets sont \"Non disponible\". Nous les rejetterons car cela n'aidera pas dans l'analyse des sentiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Supprimer tous les tweets \"NOT AVAILABLE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>264183816548130816</td>\n",
       "      <td>15140428</td>\n",
       "      <td>positive</td>\n",
       "      <td>Gas by my house hit $3.39!!!! I'm going to Cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>264249301910310912</td>\n",
       "      <td>18516728</td>\n",
       "      <td>negative</td>\n",
       "      <td>Iranian general says Israel's Iron Dome can't ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>264105751826538497</td>\n",
       "      <td>147088367</td>\n",
       "      <td>positive</td>\n",
       "      <td>with J Davlar 11th. Main rivals are team Polan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>264094586689953794</td>\n",
       "      <td>332474633</td>\n",
       "      <td>negative</td>\n",
       "      <td>Talking about ACT's &amp;amp;&amp;amp; SAT's, deciding...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>254941790757601280</td>\n",
       "      <td>557103111</td>\n",
       "      <td>negative</td>\n",
       "      <td>They may have a SuperBowl in Dallas, but Dalla...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0          1         2  \\\n",
       "0  264183816548130816   15140428  positive   \n",
       "3  264249301910310912   18516728  negative   \n",
       "6  264105751826538497  147088367  positive   \n",
       "7  264094586689953794  332474633  negative   \n",
       "9  254941790757601280  557103111  negative   \n",
       "\n",
       "                                                   3  \n",
       "0  Gas by my house hit $3.39!!!! I'm going to Cha...  \n",
       "3  Iranian general says Israel's Iron Dome can't ...  \n",
       "6  with J Davlar 11th. Main rivals are team Polan...  \n",
       "7  Talking about ACT's &amp;&amp; SAT's, deciding...  \n",
       "9  They may have a SuperBowl in Dallas, but Dalla...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df[3] != \"Not Available\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7205, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dessiner les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAncAAAHsCAYAAACwg4t/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npI4Y7iRJkjpiuJMkSerI/wHEC/Un6cIQXAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f697f4e98d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# calculate the total number of occurrences of each class\n",
    "y = [len(df[df[2] == i]) for i in ['positive', 'negative', 'neutral']]\n",
    "# X axis\n",
    "objects = ['positive', 'negative', 'neutral']\n",
    "x_pos = range(len(objects))\n",
    "\n",
    "# Draw Diagram\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.bar(x_pos, y, alpha=0.5)\n",
    "plt.xticks(x_pos, objects)\n",
    "plt.ylabel('Occurences').set_size(20)\n",
    "plt.xlabel('Classes').set_size(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interprétation\n",
    "À partir du graphique ci-dessus, nous pouvons clairement noter que la classe «négative» a le moins d'échantillons dans les données par rapport à «positif» et «neutre». Par conséquent, les données semblent déséquilibrées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7205,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_tweets = list(df[3])\n",
    "labels = df[2]\n",
    "mapper = {'positive': 1, 'negative': -1, 'neutral': 0}\n",
    "labels = labels.map(mapper)\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment140 Score\n",
    "\n",
    "Avant de faire un pré-traitement sur les tweets, nous allons d'abord utiliser le score du Sentiment140 corpus. Ce corpus a le score des mots les plus courants (formels, informels) utilisés dans twitter. Le score est un nombre compris entre [-4.999: 4.999].\n",
    "\n",
    "Le score sera divisé en trois parties:\n",
    "- unigram score  --> 'unigram140_score'\n",
    "- bigram score   --> 'bigram140_score'\n",
    "- pair score     --> 'pair140_score'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7205"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Sentiment140_dictionary(filename):\n",
    "    sentiment140 = {}\n",
    "    with open(filename) as fin:\n",
    "        line = fin.readline()[:-1]\n",
    "        while line:\n",
    "            line = line.split('\\t')\n",
    "            sentiment140[line[0]] = float(line[1])\n",
    "            line = fin.readline()[:-1]\n",
    "    return sentiment140\n",
    "\n",
    "\n",
    "def unigram140Polarity(tweet, d):\n",
    "    score=0.0\n",
    "    reps = 0\n",
    "    for w in tweet.split(' '):\n",
    "        if w in d.keys():\n",
    "            reps += 1\n",
    "            score+=d[w]\n",
    "    return score, reps\n",
    "\n",
    "unigram140_d = Sentiment140_dictionary('/data/resources/Sentiment140/unigrams-pmilexicon.txt')\n",
    "hashtag_words = [word for word in unigram140_d.keys() if word[0]=='#']\n",
    "unigram140Score, unigram140Reps = [], []\n",
    "for tweet in raw_tweets:\n",
    "    score, reps = unigram140Polarity(tweet.lower(), unigram140_d)\n",
    "    unigram140Score.append(score)\n",
    "    unigram140Reps.append(reps)\n",
    "\n",
    "len(unigram140Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7205"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_bigrams(input_list):\n",
    "    bigram_list = []\n",
    "    for i in range(len(input_list)-1):\n",
    "        bigram_list.append(input_list[i] + \" \" + input_list[i+1])\n",
    "    return bigram_list\n",
    "\n",
    "\n",
    "def bigram140Polarity(tweet, d):\n",
    "    score=0.0\n",
    "    reps = 0\n",
    "    tweet = find_bigrams(tweet.split(' '))\n",
    "    for w in tweet:\n",
    "        if w in d.keys():\n",
    "            reps += 1\n",
    "            score+=d[w]\n",
    "    return score, reps\n",
    "\n",
    "\n",
    "bigram140_d = Sentiment140_dictionary('/data/resources/Sentiment140/bigrams-pmilexicon.txt')\n",
    "bigram140Score, bigram140Reps = [], []\n",
    "for tweet in raw_tweets:\n",
    "    score, reps = bigram140Polarity(tweet.lower(), bigram140_d)\n",
    "    bigram140Score.append(score)\n",
    "    bigram140Reps.append(reps)\n",
    "\n",
    "len(bigram140Score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SemEval2015 English lexicon \n",
    "\n",
    "Ce sont les toutes premières et dernières entrées de 'SemEval2015-English-Twitter-Lexicon.txt':\n",
    "- 0.984\tloves\n",
    "- 0.984\t#inspirational\n",
    "- 0.969\tamazing\n",
    "- 0.969\t#peaceful\n",
    "- 0.953\t#greatness\n",
    "- ...\n",
    "- -0.969\tabuse\n",
    "- -0.969\t#failure\n",
    "- -0.982\tkill\n",
    "- -0.984\tbitches\n",
    "- -0.984\t#disappointment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of EnglishLexicon entries 1516\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7205"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def loadSemEval(filename):\n",
    "    f = open(filename,'r')\n",
    "    lexicon = {}\n",
    "    line = f.readline()\n",
    "    while line:\n",
    "        l = line[:-1].split('\\t')\n",
    "        lexicon[l[1]] = float(l[0])\n",
    "        line = f.readline()\n",
    "    return lexicon\n",
    "\n",
    "\n",
    "def SemEvalLexiconPolarity(tweet, EnglishLexicon):\n",
    "    score=0.0\n",
    "    reps = 0\n",
    "    for w in tweet.split(' '):\n",
    "        if w in EnglishLexicon.keys():\n",
    "            reps += 1\n",
    "            score += EnglishLexicon[w]\n",
    "    return score, reps\n",
    "\n",
    "EnglishLexicon = loadSemEval('/data/resources/SemEval2015-English-Twitter-Lexicon.txt')\n",
    "hashtag_words.extend([word for word in EnglishLexicon.keys() if word[0]=='#'])\n",
    "hashtag_words = set(hashtag_words)\n",
    "SemEvalScore, SemEvalReps = [], []\n",
    "for tweet in raw_tweets:\n",
    "    score, reps = SemEvalLexiconPolarity(tweet.lower(), EnglishLexicon)\n",
    "    SemEvalScore.append(score)\n",
    "    SemEvalReps.append(reps)\n",
    "\n",
    "print (\"Number of EnglishLexicon entries %d\" % len(EnglishLexicon.keys()))\n",
    "len(SemEvalScore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# <font color='red'>Pre-entraîner les tweets</font>\n",
    "https://nlp.stanford.edu/IR-book/html/htmledition/determining-the-vocabulary-of-terms-1.html\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Supprimer les slangs des tweets\n",
    "Par (slangs) argot, nous entendons des mots comme:\n",
    "- i've --> I have\n",
    "- 12be --> want to be\n",
    "- *4u  --> kiss for you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadSlangs(filename):\n",
    "    \"\"\"\n",
    "    This function reads the file that contains the slangs, and put them in a dictionary such that\n",
    "    the key is the \"slang\" and the value is the acronym.\n",
    "    slangs['i've'] = 'i have'\n",
    "    slang['12be'] = 'want to be'\n",
    "    ...\n",
    "    CAUTION: the keys and values are lower-case letters\n",
    "    \"\"\"\n",
    "    slangs={}\n",
    "    fi=open(filename,'r')\n",
    "    line=fi.readline()\n",
    "    while line:\n",
    "        l=line.split(r',%,')\n",
    "        if len(l) == 2:\n",
    "            slangs[l[0].lower()]=l[1][:-1].lower()  #HERE\n",
    "        line=fi.readline()\n",
    "    fi.close()\n",
    "    return slangs\n",
    "\n",
    "\n",
    "def replaceSlangs(tweet,slangs):\n",
    "    \"\"\"\n",
    "    This function is used to replace the slang in the original tweets and replace them with the acronym.\n",
    "    And it's also returns the the tweet in lower-case letters\n",
    "    \"\"\"\n",
    "    result=''\n",
    "    tweet = tweet.lower()\n",
    "    words=tweet.split()\n",
    "    for w in words:\n",
    "        if w in slangs.keys():\n",
    "            result=result+slangs[w]+\" \"\n",
    "        else:\n",
    "            result=result+w+\" \"\n",
    "    return result.strip()\n",
    "\n",
    "slangs = loadSlangs('/data/resources/internetSlangs.txt')\n",
    "raw_tweets = [replaceSlangs(tweet, slangs) for tweet in raw_tweets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remplacer les mots apostrophe\n",
    "\n",
    "Par cela, nous entendons changer des mots comme 'can't', 'cant' en 'can not'. Ces mots sont dans un fichier appelé 'apostrophe_words.txt' qui existait dans le répertoire 'resources'.\n",
    "\n",
    "Nous devons faire cela pour gérer le problème de la négation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_apostrophe_words(filename):\n",
    "    \"\"\"\n",
    "    This function reads the file that contains all words that have apostrophe, and put them in a dictionary \n",
    "    such that the key is the \"word containing apostrophe\" and the value is the \"the word without apostrophe\".\n",
    "    slangs['i've'] = 'i have'\n",
    "    slang['I'm] = 'I am'\n",
    "    ...\n",
    "    CAUTION: the keys and values are lower-case letters\n",
    "    \"\"\"\n",
    "    apo={}\n",
    "    fi=open(filename,'r')\n",
    "    line=fi.readline()\n",
    "    while line:\n",
    "        l=line.split(r',%,')\n",
    "        if len(l) == 2:\n",
    "            apo[l[0].lower()]=l[1][:-1].lower()\n",
    "        line=fi.readline()\n",
    "    fi.close()\n",
    "    return apo\n",
    "\n",
    "\n",
    "def replace_apostrophe(tweet,apos):\n",
    "    result=''\n",
    "    words=tweet.split()\n",
    "    for w in words:\n",
    "        if w in apos.keys():\n",
    "            result=result+apos[w]+\" \"\n",
    "        else:\n",
    "            result=result+w+\" \"\n",
    "    return result.strip()\n",
    "\n",
    "apos = load_apostrophe_words('/data/resources/apostrophe_words.txt')\n",
    "raw_tweets = [replace_apostrophe(tweet, apos) for tweet in raw_tweets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appliquer des techniques de prétraitement standard\n",
    "\n",
    "* https://nlp.stanford.edu/IR-book/html/htmledition/tokenization-1.html\n",
    "* https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utiliser NRC emoticon lexicon\n",
    "\n",
    "Nous remplacerons l'émoticône par sa signification associée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TT = TweetTokenizer()\n",
    "\n",
    "def emoticondictionary(filename):\n",
    "    \"\"\"\n",
    "    Reads the emoticon file and represents it as dictionary where the emoticon is the key, \n",
    "    and its indication as a value\n",
    "    \"\"\"\n",
    "    emo_scores = {'Positive': 'positive', 'Extremely-Positive': 'positive', \n",
    "                  'Negative': 'negative','Extremely-Negative': 'negative',\n",
    "                  'Neutral': 'neutral'}\n",
    "    emo_score_list = {}\n",
    "    fi = open(filename,\"r\")\n",
    "    l = fi.readline()\n",
    "    while l:\n",
    "        #replace the \"Non-break space\" with the ordinary space \" \"\n",
    "        l = l.replace(\"\\xa0\",\" \") #HERE\n",
    "        li = l.split(\" \")\n",
    "        l2 = li[:-1] #removes the polarity of the emoticon ('negative', 'positive')\n",
    "        l2.append(li[len(li) - 1].split(\"\\t\")[0]) #gets the last emoticon attached to the polarity by '\\t'\n",
    "        sentiment=li[len(li) - 1].split(\"\\t\")[1][:-1] #gets only the polarity, and removes '\\n'\n",
    "        score=emo_scores[sentiment]\n",
    "        l2.append(score)\n",
    "        for i in range(0,len(l2)-1):\n",
    "            emo_score_list[l2[i]]=l2[len(l2)-1]\n",
    "        l=fi.readline()\n",
    "    return emo_score_list\n",
    "\n",
    "dict = emoticondictionary('/data/resources/emoticon.txt')\n",
    "\n",
    "\n",
    "# substititue emoticon with its associated sentiment\n",
    "def subsEmoticon(tweet,d):\n",
    "    l = TT.tokenize(tweet)\n",
    "    tweet = [d[i] if i in d.keys() else i for i in l]\n",
    "    return tweet\n",
    "\n",
    "\n",
    "raw_tweets = [subsEmoticon(tweet, dict) for tweet in raw_tweets]\n",
    "# print(\":D X3 :|\")\n",
    "# subsEmoticon(\":D X3 :|\", dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gérer la négation\n",
    "\n",
    "Suite au travail de Pang et al (2002), nous définissons un contexte nié comme un segment d'un tweet qui commence par un mot de négation (par exemple, no, never) et se termine par l'un des signes de ponctuation: ',', ' . ',': ','; ','! ','? '.\n",
    "\n",
    "Après avoir manipulé la négation, un tweet comme  'I don't like vegan food' serait 'I do not like_not vegan_not food_not.'.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "negation_words = set(['barely', 'hardly', 'lack', 'never', 'neither', 'no', 'nobody', \\\n",
    "                      'not', 'nothing', 'none', 'nowhere', 'shortage', 'scarcely'])\n",
    "punctuations = [',', '.', ':', ';', '!', '?']\n",
    "\n",
    "def handle_negation(tweet):\n",
    "    output = []\n",
    "    negate = False\n",
    "    for word in tweet:\n",
    "        if word in punctuations and negate:\n",
    "            negate = False\n",
    "        if negate and not word in negation_words:\n",
    "            output.append(word+\"_not\")\n",
    "        else:\n",
    "            output.append(word)\n",
    "        if word in negation_words and not negate:\n",
    "            negate = True\n",
    "        elif word in negation_words and negate:\n",
    "            negate = False\n",
    "    return output\n",
    "\n",
    "raw_tweets = [handle_negation(tweet) for tweet in raw_tweets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### lemmatizer les mots \n",
    "La lemmatisation ressemble à la conversion du mot 'networks' en 'network'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mmer = WordNetLemmatizer()\n",
    "# Lemmatize the tweets\n",
    "def lemma(tweet):\n",
    "    return ' '.join([mmer.lemmatize(word) for word in tweet])\n",
    "\n",
    "lemmatized_tweets = [lemma(tweet) for tweet in raw_tweets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### supprimer les hashtags non importants\n",
    "Nous avons extrait les hashtags importants de deux corpus différents (Sentiment140 and SemEval2015 English lexicon) qui sont les seuls mots qui ont des scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_hashtags(tweet):\n",
    "    output = \"\"\n",
    "    for word in tweet.split():\n",
    "        if word[0] == '#' and word not in hashtag_words:\n",
    "            continue\n",
    "        else:\n",
    "            output += word + ' '\n",
    "    return output.strip()\n",
    "\n",
    "clean_tweets = [remove_hashtags(tweet) for tweet in lemmatized_tweets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On traite ici différents problèmes:\n",
    "- supprime les caractères de ponctuation comme,. :; etc.\n",
    "- supprime les numéros du tweet.\n",
    "- supprime les espaces supplémentaires dans le tweet.\n",
    "- supprime l'occurrence de deux ou plusieurs caractères dans un mot, par exemple. loooong -> loong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def preprocess(tweet):\n",
    "    # delete symbols and URIs and tags\n",
    "    tweet =  ' '.join(re.sub(\"(@[A-Za-z0-9_]+)|([^0-9A-Za-z_ \\t])|(\\w+:\\/\\/\\S+)\", '', tweet).split()) #here _\n",
    "    # Convert '@username' to 'at_user'\n",
    "    # tweet = re.sub('@[^\\s]+','at_user',tweet)\n",
    "    # remove hashtags\n",
    "    # tweet = re.sub(r'#\\s', '', tweet)\n",
    "    # remove numbers\n",
    "    tweet = re.sub('[0-9]', '', tweet)\n",
    "    # remove additional spaces\n",
    "    tweet = re.sub('[\\s]+', ' ', tweet)\n",
    "    # replace the occurrence of 2 or more characters in a word, eg. loooong -> loong\n",
    "    tweet = re.sub(r'(.)\\1{2,}', r'\\1\\1', tweet)\n",
    "    return tweet\n",
    "\n",
    "\n",
    "preprocessed_tweets = [preprocess(tweet) for tweet in clean_tweets]\n",
    "del lemmatized_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Supprimer stopwords\n",
    "https://nlp.stanford.edu/IR-book/html/htmledition/dropping-common-terms-stop-words-1.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "359\n",
      "\n",
      "Compare tweets before / after\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3</th>\n",
       "      <th>final_tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gas by my house hit $3.39!!!! I'm going to Cha...</td>\n",
       "      <td>gas house hit going chapel hill sat positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Iranian general says Israel's Iron Dome can't ...</td>\n",
       "      <td>iranian general say israels iron dome deal_not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>with J Davlar 11th. Main rivals are team Polan...</td>\n",
       "      <td>davlar th main rival team poland hopefully mak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Talking about ACT's &amp;amp;&amp;amp; SAT's, deciding...</td>\n",
       "      <td>talking acts sats deciding want go college app...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>They may have a SuperBowl in Dallas, but Dalla...</td>\n",
       "      <td>may superbowl dallas dallas winning_not superb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Im bringing the monster load of candy tomorrow...</td>\n",
       "      <td>instant message bringing monster load candy to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Apple software, retail chiefs out in overhaul:...</td>\n",
       "      <td>apple software retail chief overhaul san franc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>@oluoch @victor_otti @kunjand I just watched i...</td>\n",
       "      <td>watched sridevis comeback remember sun morning...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>#Livewire Nadal confirmed for Mexican Open in ...</td>\n",
       "      <td>nadal confirmed mexican open february rafael n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>@MsSheLahY I didnt want to just pop up... but ...</td>\n",
       "      <td>didnt want pop yep chapel hill next wednesday ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    3  \\\n",
       "0   Gas by my house hit $3.39!!!! I'm going to Cha...   \n",
       "3   Iranian general says Israel's Iron Dome can't ...   \n",
       "6   with J Davlar 11th. Main rivals are team Polan...   \n",
       "7   Talking about ACT's &amp;&amp; SAT's, deciding...   \n",
       "9   They may have a SuperBowl in Dallas, but Dalla...   \n",
       "10  Im bringing the monster load of candy tomorrow...   \n",
       "11  Apple software, retail chiefs out in overhaul:...   \n",
       "12  @oluoch @victor_otti @kunjand I just watched i...   \n",
       "14  #Livewire Nadal confirmed for Mexican Open in ...   \n",
       "15  @MsSheLahY I didnt want to just pop up... but ...   \n",
       "\n",
       "                                         final_tweets  \n",
       "0        gas house hit going chapel hill sat positive  \n",
       "3   iranian general say israels iron dome deal_not...  \n",
       "6   davlar th main rival team poland hopefully mak...  \n",
       "7   talking acts sats deciding want go college app...  \n",
       "9   may superbowl dallas dallas winning_not superb...  \n",
       "10  instant message bringing monster load candy to...  \n",
       "11  apple software retail chief overhaul san franc...  \n",
       "12  watched sridevis comeback remember sun morning...  \n",
       "14  nadal confirmed mexican open february rafael n...  \n",
       "15  didnt want pop yep chapel hill next wednesday ...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend([word+'_not' for word in stop_words]) #negation\n",
    "stop_words = set(stop_words)\n",
    "stop_words.update('j', 'im')\n",
    "print (len(stop_words))\n",
    "\n",
    "# remove stopwords\n",
    "def rem_stop(tweet):\n",
    "    words = tweet.split()\n",
    "    tweet = ' '.join([word for word in words if word not in stop_words])\n",
    "    return tweet\n",
    "\n",
    "final_tweets = [rem_stop(tweet) for tweet in preprocessed_tweets]\n",
    "del raw_tweets, preprocessed_tweets\n",
    "\n",
    "print(\"\\nCompare tweets before / after\")\n",
    "df['final_tweets'] = final_tweets\n",
    "df[[3, 'final_tweets']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# <font color='red'>Création de Features</font>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utilisation de MPQA Lexicon\n",
    "\n",
    "Ce sont les toutes premières et dernières entrées du fichier 'mpqa.txt'\n",
    "- abandoned priorpolarity=negative\n",
    "- abandonment priorpolarity=negative\n",
    "- abandon priorpolarity=negative\n",
    "- abase priorpolarity=negative\n",
    "- abasement priorpolarity=negative\n",
    "- ...\n",
    "- zealot priorpolarity=negative\n",
    "- zealous priorpolarity=negative\n",
    "- zealously priorpolarity=negative\n",
    "- zenith priorpolarity=positive\n",
    "- zest priorpolarity=positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of MPQA words: 13772\n",
      "['watched', 'sridevis', 'positive', 'remember', 'sun', 'morning', 'nta', 'positive']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['neutral', 'positive', 'negative']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def MPQAdictionary(filename):\n",
    "    \"\"\"\n",
    "    reads mpqa file which contains the polarity of some of the english words. e.g. 'love': 'positive'\n",
    "    \"\"\"\n",
    "    MPQA_scores = {'priorpolarity=positive\\n': 'positive','priorpolarity=negative\\n': 'negative',\n",
    "                  'priorpolarity=neutral\\n': 'neutral', 'priorpolarity=both\\n': 'neutral'}\n",
    "    MPQA_score_list = {}\n",
    "    fi = open(filename,\"r\")\n",
    "    line = fi.readline()\n",
    "    while line: \n",
    "        li = line.split(\" \")\n",
    "        l2 = li[:-1] # the word as a list\n",
    "        sentiment=li[1] #the word's polarity\n",
    "        score=MPQA_scores[sentiment]\n",
    "        l2.append(score)\n",
    "        for i in range(0,len(l2)-1):\n",
    "            MPQA_score_list[l2[i]]=l2[-1]\n",
    "            # negation\n",
    "            if l2[-1] == 'positive':\n",
    "                MPQA_score_list[l2[i]+'_not']='positive' \n",
    "            else:\n",
    "                MPQA_score_list[l2[i]+'_not']='negative' \n",
    "        line=fi.readline()\n",
    "    return MPQA_score_list\n",
    "\n",
    "\n",
    "def subsMPQA(tweet,d):\n",
    "    l = TT.tokenize(tweet)\n",
    "    #print(l)\n",
    "    tweet = [d[i] if i in d.keys() else i for i in l]\n",
    "    return tweet\n",
    "\n",
    "dictionary = MPQAdictionary('/data/resources/mpqa/mpqa.txt')\n",
    "print (\"Number of MPQA words: %d\" % len(dictionary.keys()))\n",
    "raw_tweets_MPQA = [subsMPQA(tweet,dictionary) for tweet in final_tweets]\n",
    "\n",
    "print (subsMPQA(final_tweets[7], dictionary))\n",
    "# watched sridevis comeback remember sun morning nta positive\n",
    "subsMPQA(\"surprise happy abandoned\", dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utilisation de WordSat Corpus\n",
    "Ce sont les toutes premières et dernières entrées du fichier 'WordSat_pos.txt':\n",
    "- ABIDE\n",
    "- ABIDED\n",
    "- ABIDES\n",
    "- ABIDING\n",
    "- ABILITY\n",
    "- ...\n",
    "- ZENITHS\n",
    "- ZEST\n",
    "- ZESTFULLY\n",
    "- ZESTFULNESS\n",
    "- ZESTS\n",
    "\n",
    "Ce sont les toutes premières et dernières entrées du fichier 'WordSat_neg.txt':\n",
    "- ABANDON\n",
    "- ABASE\n",
    "- ABASED\n",
    "- ABASES\n",
    "- ABATE\n",
    "- ...\n",
    "- YUKKY\n",
    "- ZEALOT\n",
    "- ZEALOTS\n",
    "- ZEALOUS\n",
    "- ZEALOUSLY\n",
    "- ZILCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive words 13841\n",
      "Number of negative words 13841\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['positive', 'firas', 'positive']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from copy import copy\n",
    "\n",
    "ENGLISH_WSD_LOCATION = os.path.join('/data/resources/WSD')\n",
    "POS_WORDS_FILE = os.path.join(ENGLISH_WSD_LOCATION, 'WordSat_pos.txt')\n",
    "NEG_WORDS_FILE = os.path.join(ENGLISH_WSD_LOCATION, 'WordSat_neg.txt')\n",
    "\n",
    "pos_words = []\n",
    "neg_words = []\n",
    "\n",
    "for pos_word in open(POS_WORDS_FILE, 'r').readlines():\n",
    "    pos_word = pos_word.split(' ')[0]\n",
    "    if \"_\" not in pos_word:\n",
    "        pos_words.append(pos_word.lower().strip('*'))\n",
    "\n",
    "for neg_word in open(NEG_WORDS_FILE, 'r').readlines():\n",
    "    neg_word = neg_word.split(' ')[0]\n",
    "    if \"_\" not in neg_word:\n",
    "        neg_words.append(neg_word.lower().strip('*'))\n",
    "\n",
    "#negation\n",
    "expanded_pos = copy(pos_words)\n",
    "expanded_pos.extend([word+\"_not\" for word in neg_words])\n",
    "expanded_neg = copy(neg_words)\n",
    "expanded_neg.extend([word+\"_not\" for word in pos_words])\n",
    "\n",
    "#change its type into a set\n",
    "expanded_pos = set(expanded_pos)\n",
    "expanded_neg = set(expanded_neg)\n",
    "\n",
    "#delete unnecessary objects\n",
    "del pos_words, neg_words\n",
    "del ENGLISH_WSD_LOCATION, POS_WORDS_FILE, NEG_WORDS_FILE\n",
    "print (\"Number of positive words %d\" % len(expanded_pos))\n",
    "print (\"Number of negative words %d\" % len(expanded_neg))\n",
    "\n",
    "def subs_pos(tweet, pos_words):\n",
    "    return ['positive' if i in pos_words else i for i in tweet]\n",
    "\n",
    "def subs_neg(tweet, neg_words):\n",
    "    return ['negative' if i in neg_words else i for i in tweet]\n",
    "\n",
    "raw_tweets_wsd = [subs_pos(tweet, expanded_pos) for tweet in raw_tweets_MPQA]\n",
    "raw_tweets_wsd = [subs_neg(tweet, expanded_neg) for tweet in raw_tweets_wsd]\n",
    "\n",
    "subs_pos(\"enjoy firas extraordinarily\".split(' '), expanded_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utilisation de Bing Liu Lexicon\n",
    "Ce sont les toutes premières et dernières entrées du fichier 'positive-words.txt':\n",
    "- a+\n",
    "- abound\n",
    "- abounds\n",
    "- abundance\n",
    "- abundant\n",
    "- ...\n",
    "- youthful\n",
    "- zeal\n",
    "- zenith\n",
    "- zest\n",
    "- zippy\n",
    "\n",
    "Ce sont les toutes premières et dernières entrées du fichier 'negative-words.txt':\n",
    "- 2-faced\n",
    "- 2-faces\n",
    "- abnormal\n",
    "- abolish\n",
    "- abominable\n",
    "- ...\n",
    "- zaps\n",
    "- zealot\n",
    "- zealous\n",
    "- zealously\n",
    "- zombie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive words 14676\n",
      "Number of negative words 14676\n"
     ]
    }
   ],
   "source": [
    "ENGLISH_OPINION_LEXICON_LOCATION = os.path.join('/data/resources/opinion-lexicon-English')\n",
    "POS_WORDS_FILE = os.path.join(ENGLISH_OPINION_LEXICON_LOCATION, 'positive-words.txt')\n",
    "NEG_WORDS_FILE = os.path.join(ENGLISH_OPINION_LEXICON_LOCATION, 'negative-words.txt')\n",
    "\n",
    "for pos_word in open(POS_WORDS_FILE, 'r').readlines()[35:]:\n",
    "    word = pos_word.rstrip()\n",
    "    expanded_pos.add(word)\n",
    "    expanded_neg.add(word+\"_not\")  #negation\n",
    "\n",
    "for neg_word in open(NEG_WORDS_FILE, 'r').readlines()[35:]:\n",
    "    word = pos_word.rstrip()\n",
    "    expanded_neg.add(word)\n",
    "    expanded_pos.add(word+\"_not\")  #negation\n",
    "\n",
    "\n",
    "#delete unnecessary objects\n",
    "del raw_tweets_MPQA\n",
    "del ENGLISH_OPINION_LEXICON_LOCATION, POS_WORDS_FILE, NEG_WORDS_FILE\n",
    "\n",
    "print (\"Number of positive words %d\" % len(expanded_pos))\n",
    "print (\"Number of negative words %d\" % len(expanded_neg))\n",
    "\n",
    "\n",
    "raw_tweets_bing = [subs_pos(tweet, expanded_pos) for tweet in raw_tweets_wsd]\n",
    "raw_tweets_bing = [subs_neg(tweet, expanded_neg) for tweet in raw_tweets_bing]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Afinn](https://pypi.python.org/pypi/afinn)\n",
    "\n",
    "Ce sont les toutes premières et dernières entrées de 'afinn.txt':\n",
    "- abandon\t-2\n",
    "- abandoned\t-2\n",
    "- abandons\t-2\n",
    "- abducted\t-2\n",
    "- abduction\t-2\n",
    "- ...\n",
    "- yucky\t-2\n",
    "- yummy\t3\n",
    "- zealot\t-2\n",
    "- zealots\t-2\n",
    "- zealous\t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Afinn entries 4922\n"
     ]
    }
   ],
   "source": [
    "def loadAfinn(filename):\n",
    "    f=open(filename,'r')\n",
    "    afinn={}\n",
    "    line=f.readline()\n",
    "    while line:\n",
    "        if \" \" in line:   #exclude entries like 'cool stuff    3'\n",
    "            pass\n",
    "        else:\n",
    "            l=line[:-1].split('\\t') #line[:-1] removes the '\\r\\n' character\n",
    "            afinn[l[0]]=float(l[1])    # normalization -------> \n",
    "            afinn[l[0]+\"_not\"] = -float(l[1])  # negation\n",
    "        line=f.readline()\n",
    "\n",
    "    return afinn\n",
    "\n",
    "afinn = loadAfinn('/data/resources/afinn.txt')\n",
    "# print (afinn)\n",
    "print (\"Number of Afinn entries %d\" % len(afinn.keys()))\n",
    "\n",
    "def afinnPolarity(tweet, afinn):\n",
    "    score=0.0\n",
    "    reps = 0\n",
    "    for w in tweet:\n",
    "        if w in afinn.keys():\n",
    "            reps += 1\n",
    "            score+=afinn[w]\n",
    "    return score, reps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SentiWordNet\n",
    "\n",
    "Voici les cinq premières lignes du fichier csv 'sentiWordnetBig.csv':\n",
    "\n",
    "|POS|ID|PosSCore|NegScore|SynsetTerms|\n",
    "|-|-------|-----|-----|-------------------|\n",
    "|a|1740|0.125|0|able#1|\n",
    "|a|2098|0|0.75|unable#1|\n",
    "|a|2312|0|0|dorsal#2 abaxial#1|\n",
    "|a|2527|0|0|ventral#2 adaxial#1|\n",
    "|a|2730|0|0|acroscopic#1|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening the SentiWordnet file ...\n",
      "Loading...\n",
      "Number of sentiWordnet entries 294612\n"
     ]
    }
   ],
   "source": [
    "def loadSentiWordnet(filename): \n",
    "    output={}\n",
    "    print (\"Opening the SentiWordnet file ...\")\n",
    "    fi=open(filename,\"r\")\n",
    "    line=fi.readline() # ignore the header\n",
    "    line=fi.readline()\n",
    "    print (\"Loading...\")\n",
    "\n",
    "    while line:\n",
    "        l=line.split('\\t')\n",
    "        try:\n",
    "            sentence=l[4]\n",
    "            new = [word for word in sentence.split() if (word[-2] == \"#\" and word[-1].isdigit())]\n",
    "            pos=abs(float(l[2]))\n",
    "            neg=abs(float(l[3]))\n",
    "            neu=float(pos-neg)\n",
    "        except:\n",
    "            line=fi.readline()\n",
    "            continue\n",
    "\n",
    "        for w in new:\n",
    "            output[(w[:-2])]=neu\n",
    "            output[(w[:-2])+'_not'] = -neu   #negation\n",
    "        line=fi.readline()\n",
    "        \n",
    "    fi.close()\n",
    "    return output\n",
    "\n",
    "\n",
    "sentiWordnet = loadSentiWordnet('/data/resources/sentiWordnetBig.csv')\n",
    "print (\"Number of sentiWordnet entries %d\" % len(sentiWordnet.keys()))\n",
    "\n",
    "\n",
    "\n",
    "def WordnetPolarity(tweet, sentiWordnet):\n",
    "    score=0.0\n",
    "    reps = 0\n",
    "    for w in tweet:\n",
    "        if w in sentiWordnet.keys():\n",
    "            reps += 1\n",
    "            score+=sentiWordnet[w]\n",
    "    return score, reps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SenticNet API\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from senticnet.senticnet import Senticnet\n",
    "\n",
    "def SenticnetPolarity(tweet):\n",
    "    score=0.0\n",
    "    reps = 0\n",
    "    for w in tweet:\n",
    "        try:\n",
    "            score += float(Senticnet().polarity_intense(w))\n",
    "            reps += 1\n",
    "        except KeyError:\n",
    "            pass\n",
    "    return score, reps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcul de polarité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7205, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bing_mpqa_score</th>\n",
       "      <th>afinn_score</th>\n",
       "      <th>wordnet_score</th>\n",
       "      <th>sem_eval_score</th>\n",
       "      <th>Senticnet_score</th>\n",
       "      <th>final_score</th>\n",
       "      <th>final_tweets</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.005794</td>\n",
       "      <td>0.005646</td>\n",
       "      <td>-0.003485</td>\n",
       "      <td>0.008469</td>\n",
       "      <td>0.003546</td>\n",
       "      <td>0.013677</td>\n",
       "      <td>gas house hit going chapel hill sat positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.011589</td>\n",
       "      <td>0.011292</td>\n",
       "      <td>0.003485</td>\n",
       "      <td>-0.003356</td>\n",
       "      <td>0.015808</td>\n",
       "      <td>0.027135</td>\n",
       "      <td>iranian general say israels iron dome deal_not...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.005794</td>\n",
       "      <td>0.005646</td>\n",
       "      <td>-0.017427</td>\n",
       "      <td>-0.002014</td>\n",
       "      <td>0.003380</td>\n",
       "      <td>0.014708</td>\n",
       "      <td>davlar th main rival team poland hopefully mak...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.010456</td>\n",
       "      <td>0.004899</td>\n",
       "      <td>-0.016425</td>\n",
       "      <td>-0.064878</td>\n",
       "      <td>talking acts sats deciding want go college app...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.005794</td>\n",
       "      <td>-0.005646</td>\n",
       "      <td>-0.008714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.011864</td>\n",
       "      <td>-0.041947</td>\n",
       "      <td>may superbowl dallas dallas winning_not superb...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.005794</td>\n",
       "      <td>-0.005646</td>\n",
       "      <td>-0.017427</td>\n",
       "      <td>0.016953</td>\n",
       "      <td>0.004129</td>\n",
       "      <td>-0.021529</td>\n",
       "      <td>instant message bringing monster load candy to...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005228</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.008915</td>\n",
       "      <td>-0.014149</td>\n",
       "      <td>apple software retail chief overhaul san franc...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.011589</td>\n",
       "      <td>0.011292</td>\n",
       "      <td>0.005228</td>\n",
       "      <td>0.006484</td>\n",
       "      <td>0.014105</td>\n",
       "      <td>0.059645</td>\n",
       "      <td>watched sridevis comeback remember sun morning...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.011589</td>\n",
       "      <td>0.011292</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009598</td>\n",
       "      <td>0.011420</td>\n",
       "      <td>0.028376</td>\n",
       "      <td>nadal confirmed mexican open february rafael n...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.011589</td>\n",
       "      <td>0.011292</td>\n",
       "      <td>-0.001743</td>\n",
       "      <td>0.018295</td>\n",
       "      <td>-0.002174</td>\n",
       "      <td>0.075597</td>\n",
       "      <td>didnt want pop yep chapel hill next wednesday ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    bing_mpqa_score  afinn_score  wordnet_score  sem_eval_score  \\\n",
       "0          0.005794     0.005646      -0.003485        0.008469   \n",
       "3          0.011589     0.011292       0.003485       -0.003356   \n",
       "6          0.005794     0.005646      -0.017427       -0.002014   \n",
       "7          0.000000     0.000000      -0.010456        0.004899   \n",
       "9         -0.005794    -0.005646      -0.008714        0.000000   \n",
       "10        -0.005794    -0.005646      -0.017427        0.016953   \n",
       "11         0.000000     0.000000      -0.005228        0.000000   \n",
       "12         0.011589     0.011292       0.005228        0.006484   \n",
       "14         0.011589     0.011292       0.000000        0.009598   \n",
       "15         0.011589     0.011292      -0.001743        0.018295   \n",
       "\n",
       "    Senticnet_score  final_score  \\\n",
       "0          0.003546     0.013677   \n",
       "3          0.015808     0.027135   \n",
       "6          0.003380     0.014708   \n",
       "7         -0.016425    -0.064878   \n",
       "9         -0.011864    -0.041947   \n",
       "10         0.004129    -0.021529   \n",
       "11        -0.008915    -0.014149   \n",
       "12         0.014105     0.059645   \n",
       "14         0.011420     0.028376   \n",
       "15        -0.002174     0.075597   \n",
       "\n",
       "                                         final_tweets         2  \n",
       "0        gas house hit going chapel hill sat positive  positive  \n",
       "3   iranian general say israels iron dome deal_not...  negative  \n",
       "6   davlar th main rival team poland hopefully mak...  positive  \n",
       "7   talking acts sats deciding want go college app...  negative  \n",
       "9   may superbowl dallas dallas winning_not superb...  negative  \n",
       "10  instant message bringing monster load candy to...   neutral  \n",
       "11  apple software retail chief overhaul san franc...   neutral  \n",
       "12  watched sridevis comeback remember sun morning...  positive  \n",
       "14  nadal confirmed mexican open february rafael n...   neutral  \n",
       "15  didnt want pop yep chapel hill next wednesday ...  positive  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BingMpqaScore = []\n",
    "AfinnScore, AfinnReps = [], []\n",
    "WordnetScore, WordnetReps = [], []\n",
    "SenticnetScore, SenticnetReps = [], []\n",
    "length = len(raw_tweets_bing)\n",
    "\n",
    "for tw in raw_tweets_bing:\n",
    "    Bing_MPQA = 0\n",
    "    for i in tw:\n",
    "        if (i == 'positive'):\n",
    "            Bing_MPQA +=  1\n",
    "        if (i == 'negative'):\n",
    "            Bing_MPQA -= 1\n",
    "    BingMpqaScore.append(Bing_MPQA)\n",
    "    tmp = afinnPolarity(tw, afinn)\n",
    "    AfinnScore.append(tmp[0])\n",
    "    AfinnReps.append(tmp[1])\n",
    "    tmp = WordnetPolarity(tw, sentiWordnet)\n",
    "    WordnetScore.append(tmp[0])\n",
    "    WordnetReps.append(tmp[1])\n",
    "    tmp = SenticnetPolarity(tw)\n",
    "    SenticnetScore.append(tmp[0])\n",
    "    SenticnetReps.append(tmp[1])\n",
    "\n",
    "    \n",
    "#reshape\n",
    "BingMpqaScore = np.array(BingMpqaScore).reshape(length, 1)\n",
    "AfinnScore = np.array(AfinnScore).reshape(length, 1)\n",
    "AfinnReps = np.array(AfinnReps).reshape(length, 1)\n",
    "WordnetScore = np.array(WordnetScore).reshape(length, 1)\n",
    "WordnetReps = np.array(WordnetReps).reshape(length, 1)\n",
    "SemEvalScore = np.array(SemEvalScore).reshape(length, 1)\n",
    "SemEvalReps = np.array(SemEvalReps).reshape(length, 1)\n",
    "SenticnetScore = np.array(SenticnetScore).reshape(length, 1)\n",
    "SenticnetReps = np.array(SenticnetReps).reshape(length, 1)\n",
    "unigram140Score = np.array(unigram140Score).reshape(length, 1)\n",
    "unigram140Reps = np.array(unigram140Reps).reshape(length, 1)\n",
    "bigram140Score = np.array(bigram140Score).reshape(length, 1)\n",
    "bigram140Reps = np.array(bigram140Reps).reshape(length, 1)\n",
    "\n",
    "#Normalization\n",
    "BingMpqaScore = BingMpqaScore/np.linalg.norm(BingMpqaScore)\n",
    "AfinnScore = AfinnScore/np.linalg.norm(AfinnScore)\n",
    "AfinnReps = AfinnReps/np.linalg.norm(AfinnReps)\n",
    "WordnetScore = WordnetScore/np.linalg.norm(WordnetScore)\n",
    "WordnetReps = WordnetReps/np.linalg.norm(WordnetReps)\n",
    "SemEvalScore = SemEvalScore/np.linalg.norm(SemEvalScore)\n",
    "SemEvalReps = SemEvalReps/np.linalg.norm(SemEvalReps)\n",
    "SenticnetScore = SenticnetScore/np.linalg.norm(SenticnetScore)\n",
    "SenticnetReps = SenticnetReps/np.linalg.norm(SenticnetReps)\n",
    "unigram140Score = unigram140Score/np.linalg.norm(unigram140Score)\n",
    "unigram140Reps = unigram140Reps/np.linalg.norm(unigram140Reps)\n",
    "bigram140Score = bigram140Score/np.linalg.norm(bigram140Score)\n",
    "bigram140Reps = bigram140Reps/np.linalg.norm(bigram140Reps)\n",
    "\n",
    "\n",
    "\n",
    "#final_score_tweets (my score list)\n",
    "df['bing_mpqa_score'] = BingMpqaScore\n",
    "df['afinn_score'] = AfinnScore\n",
    "df['wordnet_score'] = WordnetScore\n",
    "df['sem_eval_score'] = SemEvalScore\n",
    "df['Senticnet_score'] = SenticnetScore\n",
    "all_scores = np.hstack( (BingMpqaScore, AfinnScore, WordnetScore, SemEvalScore, SenticnetScore, \\\n",
    "                                                                         unigram140Score, bigram140Score) )\n",
    "sum_score = np.sum(all_scores, axis=1).reshape(length, 1)\n",
    "print (all_scores.shape)\n",
    "df['final_score'] = sum_score\n",
    "\n",
    "df[['bing_mpqa_score','afinn_score', 'wordnet_score', 'sem_eval_score', 'Senticnet_score', \\\n",
    "                                'final_score', 'final_tweets' ,2]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del df, raw_tweets_bing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## <font color='red'>Entraîner le modèle</font>\n",
    "***\n",
    "#### Créer le feature vector\n",
    "* See [Bag of Words](https://en.wikipedia.org/wiki/Bag-of-words_model) for more details (Supprimer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7205, 134911)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vectorizer = CountVectorizer(analyzer='word', preprocessor=None, stop_words=None, tokenizer=None, ngram_range=(1,3))\n",
    "count_features = count_vectorizer.fit_transform(final_tweets)\n",
    "count_features = scipy.sparse.csr_matrix(count_features)\n",
    "count_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7205, 5)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reducing the CountVector\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_components=5, n_iter=7, random_state=42)\n",
    "count_features = svd.fit_transform(count_features)\n",
    "count_features = scipy.sparse.csr_matrix(count_features)\n",
    "print (type(count_features))\n",
    "count_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7205, 134911)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(analyzer='word', preprocessor=None, stop_words=None, tokenizer=None, ngram_range=(1,3))\n",
    "tfidf_features = tfidf_vectorizer.fit_transform(final_tweets)\n",
    "del final_tweets\n",
    "tfidf_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7205, 7) (7205, 1) (7205, 1) (7205, 1) (7205, 1)\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "(7205, 13)\n"
     ]
    }
   ],
   "source": [
    "print (all_scores.shape, sum_score.shape, AfinnReps.shape, WordnetReps.shape, SemEvalReps.shape)\n",
    "final_total = scipy.sparse.csr_matrix(np.hstack( (all_scores, sum_score, AfinnReps, WordnetReps, SemEvalReps, unigram140Reps, bigram140Reps) ))\n",
    "print (type(final_total))\n",
    "print (final_total.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7205, 134929)\n"
     ]
    }
   ],
   "source": [
    "features = scipy.sparse.hstack([count_features, tfidf_features, final_total])\n",
    "print (features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# supprimer les objets inutiles\n",
    "del all_scores, sum_score, BingMpqaScore, AfinnScore, WordnetScore, SemEvalScore, unigram140Score, bigram140Score\n",
    "del AfinnReps, WordnetReps, SemEvalReps, unigram140Reps, bigram140Reps\n",
    "del count_features, tfidf_features, final_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import SVM\n",
    "\n",
    "http://scikit-learn.org/stable/modules/svm.html\n",
    "\n",
    "For a mathematical overview,\n",
    "https://docs.opencv.org/2.4/doc/tutorials/ml/introduction_to_svm/introduction_to_svm.html\n",
    "\n",
    "#### Get the optimal regulation parameter using handout method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anwar/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/anwar/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.594959494032\n",
      "20\n",
      "{'C': 4.6480402875255615, 'gamma': 0.54056011825237438}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'C value')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEKCAYAAAARnO4WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAAIABJREFUeJzt3Xl8VPW5+PHPk51AQoAEMoFA2NeE\nxYAKuIKKBEVb19rF1tZf77WL3WtXFevtdqvtrbXVtrZ2uWirt8ouO4hQNiGBhCVhS8hOWAIh+/f3\nx5xAxACTMDNn5pzn/XrNi8ls5zmZ4ZmT5/l+v0eMMSillHK+CLsDUEopFRya8JVSyiU04SullEto\nwldKKZfQhK+UUi6hCV8ppVxCE75SSrmEJnyllHIJTfhKKeUSUXYH0F5ycrLJyMiwOwyllAob27Zt\nqzbGpPjy2JBK+BkZGWzdutXuMJRSKmyIyGFfH6slHaWUcglN+Eop5RKa8JVSyiU04SullEtowldK\nKZfQhK+UUi6hCV8ppVxCE75SStnoX+8f5XRDc1C2pQlfKaVssrP4BI+/toPv/l9eULanCV8pZTtj\nDHklJ4N2pBsqzjR697fiVH1QthdSSysopdxp6a5y/uNv24mKECYOTGLq0GSmD09mQnoS0ZF6XOov\nmvCVUrb7++YjpPWM466J/dlQWM2vVu3nlyv30z0mkquH9GHq0D5MH57MyH4JiIjd4YYtTfhKKVsV\n19Sxfn81X5k5gi/PHA7AybomNh44xobCajYUVrNqTyUAyT1imTasD9OGJTNtWDL9k7rZGbrflJ7Q\nko5SygX+sbUYEbg3e8C523rGRzNrXCqzxqUCcPTE2XPJf0PhMd7aUQrA4OTuTBvWh+nDkrl2SDI9\n46Nt2YcrdaSmLijb0YSvlLJNS6vh9a0l3DAihbRLHK33T+rGfdnp3JedjjGGfRWnedf6Anhz+1H+\nuukIIpDZvyfThiUzfVgyVw3qRVx0ZBD3pvOE4JanNOErpWyzbl8V5afqefLOMT4/R0QYmZrAyNQE\nHpk+mKaWVnYWnzj3BfDyugO8uKaI2KgIJmf0tso/fRib1pPICHfX/zXhK6VsM3/LEZJ7xHDzqH5d\nfo3oyAiyM3qTndGbx2eO4HRDM5sPHmNDobcH8JOlewDo2S2aqUP7nPsLYFCfeNc1gDXhK6VsUVlb\nz8qCSh6ZPpiYKP8NvewRG8XNo/qd+xKprK1nY9Ex3t3v/Qtgya5ywFsmamsATx2aTEpCrN9iCFWa\n8JVStnhz+1GaWw33TU4P6Hb6JsQxd0J/5k7ojzGGQ8fqvOWf/dUs3VXO61tLABiVmnDu6H/K4N50\nj3VeenTeHimlQp4xhte2FDMlozdDU3oEbbsiwuDk7gxO7s4nrhlES6th19GTbCjyHv3/ZdNh/vDu\nQaIihEkDe52r/48P0ASwYFeUNOErpYJu88EaDlaf4Qs3DbM1jsgIYXx6EuPTk/jPG4dR39TC1kPH\nebewmveKqnl+5T6eWwHdYyK5Zsj58f8j+vUIy/q/JnylVNC9tqWYhNgoZmd67A7lA+KiI5k+3Lus\nA8CJukZv/d8aAbTSmgCWkhDLtKHnvwAuNaQ0lGjCV0oF1cmzTSzKK+Pe7AF0iwntcfJJ8THcnunh\nduuLqeR4He8Ver8A1u+v5l/WBLAhKd2ZNtSb/K8d0sfnCWDGBCz0DmnCV0oF1ds7jtLQ3MoDkwfa\nHUqnDegVz32T47lvcjqtrYa9FbXnZgC/sb2Ev2w6TIRA5oAkpg/rw7ShyUwKoQlgmvCVUkE1f0sx\nY9MSGde/p92hXJGICGG0J5HRnkQ+e90QGptb2WFNAHuvsJrfrj3AC6u9E8CmDO59bgTQGE8iEdYE\nMG3aKqUca9fRk+wuPcW8uWPtDsXvYqzEPmVwb756ywhq65vYfLDmXP3/x0u8E8CS4s9PAIuOCO7S\nz5rwlVJBM3/LEWKjIrhzQn+7Qwm4hLhoZozux4zR1gSwU/W8164BvDivPOgxacJXSgXF2cYW3nq/\nlJxMDz27heeqlleib6J3vf+7JnongB2oPsPtz6+nsaU1aDHoqWTURTW3tHKw+ozdYSiHWJxXRm1D\nM/cHeGZtOBARhqb0ICM5Pqjb1YSvOrRmbyW3/3I9N/18DXklJ+0ORznAa1uKGZzcnSmDe9sdSsgI\n9vLImvDVBxRW1vLwK5t5+JUtNLW0Eh0pLMgttTssFeaKqk6z+VAN909OD8sZqoES7F+FJnwFwPEz\njfzwrV3c9vx6th0+zvdyRvPOV27guuEpLMotwwR7hohylNe3FBMVIXxkkvObtZ0R7C8/bdq6XGNz\nK3/ZdJhfrtjH6YZmHrp6EI/PHE6fHt6lYmdneli1p5KdJSeZkJ5kc7QqHDU2t/LG9hJmjO5L34Q4\nu8MJKcH+WyfgCV9EIoGtwFFjzJxAb0/5xhjDyoJKfrS4gIPVZ7hueDLfnzOGEf0SPvC4W8b0IzpS\nWJRbqglfdcmqPRVUn24My5m1gRbkYfhBOcL/MlAAJAZhW8oHBWWneGZRPhsKjzE0pTuvPDyZG0em\ndPjnZc9u0Vw/PIXFeeV8Z/Zorb+qTpu/pZjUxDiuH5Fidyghx1FNWxEZAOQAvw/kdpRvqk838MSb\neeT8aj27jp7iyTvGsPTx67lpVN9LJvLZmR6OnjjLjuITQYxWOUHpibOs3VfFfdkDXH8+2Y44bWmF\n54FvAgmXe6AKnIbmFv604RC/XlXI2aYWPjU1gy/PGE5SfIxPz585ph8xkREsyi1j4sBeAY5WOck/\nrLNJ3ZutY+874pgavojMASqNMdtE5MZLPO5R4FGAgQO1xudPxhiW7irnv5bs4UhNHTNG9eU7OaM7\nfYahnt2iuX5EMovzyvjO7NHnFn5S6lJaWg2vby1m+rBk0nsHd4JR2AjyIX4gSzrTgDtF5BAwH7hZ\nRP564YOMMS8ZY7KNMdkpKVrj85ddR09y/0ub+I+/badbdCR/eWQKf3h4cpdPJzc700PpyXp2lGhZ\nR/lmQ2E1R0+c1Zm1lxDsY6eAHeEbY54AngCwjvC/boz5eKC2p7wqT9Xzs2V7+ef2EnrFx/DMXeN4\nYHI6UVd4Ps72ZZ1JWtZRPnhtSzG94qO5ZUw/u0MJWY4p6ajgqm9q4ffrD/CbNUU0tbTyueuG8NhN\nw/y2SFVi3Pmyzne1rKMu49jpBt7JL+eT12YQGxUaJ/8IRY6ceGWMWQOsCca23MYYw4LcMn6yZA9H\nT5zltrH9eOL20WQkd/f7tnKyPKwoqOT94hNcNUiP8tXF/d/7R2lqMVrOuQw9wlc+21F8gnkL89l2\n+DhjPIn8/N7xXDu0T8C2N3N0P2KivGUdTfjqYowxzN9SzKSBSR+ayKc+SNfSUZdVdvIsX3ltB3e9\nsIHDx+r4yUczWfDF6QFN9uA9oYN3ElYZra26to7q2PYjxymsPK0za33gyJKO8o+6xmZ+t/YAv1tX\nRKuB/7xxKP950zB6xAbvbZyT5WFFQQXvFx/nqkG6zK36sPmbi+keE0lOlsfuUEKeY0bpKP9pbTX8\na8dRfrp0L+Wn6snJ8vDtWaNsGds8Y3RfYqIiWJhbpglffUhtfRMLc8u4a2Ia3YN4IBKugr20gr4j\nIW7b4RqeXpDPzpKTZA3oyf98bCKTM+xLtAlx0dwwwlvW+X7OGB2toz5gwc4yzja1cL+Wc3zitKUV\nVBeVHK/jx0v2sDC3jH6Jsfz3veO5e2L/kEiwc7I8LM+vYPuR42Tb+OWjQs9rW44wKjWB8QN62h1K\nWNCE73KnG5p5cU0hL68/SITAl2cM5//dMIT4mNB5q2ZYo3UW5pZpwlfn5JeeYmfJSX54xxhdVdVH\nEdq0daeWVsMb20r42Tt7qapt4K4JaXxz1ijSkrrZHdqH9IiN4sYRKSzZVcYP5mhZR3m9vrWYmKgI\n7p6oZ7UKVZrwQ8DGomPMW5hPftkpJg1M4qVPXBXyq1LmZHl4J7+CbUeO29pTUKGhvqmFN7eXMGts\nqs+rsCodlukqh4+d4dnFBSzbXUH/pG786sGJ3JHlCYs/h2eM7kesNQlLE75atrucU/XNPKAzaztF\nZ9q6wKn6Jl5YVcgrGw4RFSl8/dYRfPa6IcRFh8+aIz1io7hxpHe0jpZ11PzNxQzsHc81QwI7+c9p\ntGnrYM0trczfUsxzy/dRU9fIPZMG8PXbRtIvMTxP7JyTlcay3RVsPXycKYP1KN+tDlWfYeOBY3zj\ntpH6xd9J2rR1qPX7q3hmYQF7K2qZMrg3f54zhnH9w3vo2oxRfa2yTqkmfBd7fWsxEQL3XDXA7lDC\njpZ0HKao6jTPLipg5Z5K0nt348WHJjFrXGpY1Okvp3tsFDeN7MuSXeX84I6xes5SF2puaeUf20q4\neVTfsP1L1U5a0nGIk3VN/HLlfl7deIi46Ei+ffsoHp6aEVZ1el/kZHlYurucrYdquFrrt66zem8V\nVbUNOrO2y7SkE9aaWlr526bDPL9yP6fONnH/5IF89ZYRpCTE2h1aQNw8qi9x0REsyivThO9Cr205\nQt+EWG4aqacn7Qo9wg9jq/dW8szCfIqqzjBtWB++lzOG0Z5Eu8MKqPZlnR9qWcdVyk/Ws2pPJZ+/\nYegVn0LTrXS1zDC0r6KWZxYVsG5fFYOTu/PyJ7OZObqvI+r0vsjJ8rBkVzlbDtXosDwXeWN7Ca0G\n7svWsfddpaN0wkjNmUaeW76Pv28+QnxMJN/LGc0nr80gJspdRzvnyjq5ZZrwXaK11fDalmKuHdIn\nIKfTdAst6YSBxuZWXt14iF+u3E9dYwsPXT2Qx2eOoHd3d04pj4+J4uZR3rLOk3dqWccNNh04xpGa\nOr526wi7Qwlruh5+CDPGsDy/gmcXF3DoWB03jEjhezmjGa7n7SQnM43FeeVsPlgT8FMtKvvN31JM\nz27R3DY21e5Qwpse4Yem/NJTPLMon/eKjjGsbw9e+fRkbhrZ1+6wQsZNo1Ks0TqlmvAd7viZRpbu\nKudjVw903DDjYNMafoipqm3gF8v3njuieerOsXzs6oFE66iED4iPiWLGqH4s3VXOU3eO07KOg/1r\nx1EaW1q5XxdKu2I60zZE1De18MqGQ7ywupD6phY+M20wX7p5OD3jo+0OLWTlZHlYlFfGvw8eY+rQ\nZLvDUQFgjGH+5mLGD+jp+CHHwaBNW5sZY1iyq5z/WlJAcc1ZZo7uy3dmj2ZISg+7Qwt5N43sS7fo\nSBbllmnCd6idJSfZW1HLs3dn2h2KI+gRvo3ySk4yb2E+mw/VMCo1gb8+cjXTh2vi8lW3mEhuHt2X\nZbvLeerOsToZx4Fe23KEbtGR3DHeY3cojqAnQLFBxal6frZsL29sL6F3fAzP3p3J/ZPTtQ7dBXMy\nPSzKLWPzwRqmDtMvSyc509DM2ztKmZPlISFOS5v+oEf4QVTf1MLL6w7w4toimlsMj14/hMduGkai\nfpi77EarrLMwr0wTvsMsyi3jTGMLD0zRZq2/6BF+EBhjeHtnKT9ZsofSk/XMGpvKE7NHMaiPzhi8\nUt1iIpkxui/LdpXztJZ1HGX+liMM69uDSSF+vuVwok3bANt+5DjzFubz/pETjE1L5Bf3T9DlAPxs\nTpaHhbll/PtgDdP0KN8R8kpOsv3ICb6XM9o1a0QFg5Z0AqT0xFl+snQPb+0oJSUhlp/ek8VHJw3Q\nOn0A3DiyL/ExkSzMLdOE7wCtrYYnF+ymT/cY7tWF0vxKJ1752ZmGZn63toiX1h+g1cAXbhrG528c\nSo9Yx++6beKiI5kxuh/Ldpczb66WdcLdG9tL2Hb4OD+7J4ue3bS/5U9a0vGT1lbDm+8f5WfL9lBx\nqoE7xqfxrVkjGdAr3u7QXCEn08OCnaVsOlCjQ1vD2MmzTfx4yR4mDUzio5P0nLX+pk1bP9hyqIZ5\nC/PJLTnJ+PQkfvPQJK4apCfZDqYbR6bQPSaSRXmlmvDD2HPL93G8rpE/f2YKEVr+9DvHHOGLSByw\nDoi1tvNPY8wPA7U9gOKaOn68ZA+L8spITYzjufvHM3d8f/2g2qCtrLN0Vznz5o7Tsk4Y2l16klc3\nHuLj1wxiXP+edofjSE5q2jYANxtjTotINPCuiCwxxmzy94Zq65v4zZoi/vDuQSIEHp85nEevH0J8\njCP/gAkbOVke3t5ZysYDx7huuJ7zNJy0thp++NZuesXH8LVbRtodjmM55gjfGGOA09aP0dbF+Hs7\nJ882MfMXa6mqbeAjE/vzjVkj8fTs5u/NqC64YYS3rLM4r0wTfph58/2jbD18nJ/ek6ULBgaQo06A\nIiKRwDZgGPCCMebf/t5Gz27RPDw1g2nDkpmQnuTvl1dXIC46kpljvGWdp+eO0yWlw4S3UVvAxIFJ\n3KON2oAKdrU5oP8DjTEtxpgJwABgioiMu/AxIvKoiGwVka1VVVVd2s5jNw3TZB+icjI9HK9rYmPR\nMbtDUT56bvk+as40Mm/uOO1/BViwR+kE5ZDLGHMCWAPM6uC+l4wx2caY7JQU/bPfaa4fkUKP2CgW\n55XZHYryQX7pKV7deIiHrtZGrRMFLOGLSIqIJFnXuwEzgT2B2p4KTXHRkcwc3Zelu8tpamm1Oxx1\nCcYYfvDWLpLiY/j6rdqoDYZgN20DeYTvAVaLSC6wBVhujFkYwO2pEDU708OJuibe07JOSHtzu7dR\n++1Zo7RRGySOadoaY3KBiYF6fRU+zpV1csu4YYSW7ULRybNN/NeSAiakJ3HPVdqoDRZHNW2VAm9Z\n55Yx/bSsE8KeW76PY2caeeYubdQGk5NKOkqdMzvTw8mzTWworLY7FHWBgrK2Ru1AbdQGWbBXy9SE\nr4LiuuHJJOhonZCjjVqb6RG+cqK2ss6y3RU0NmtZJ1T83/tH2XLoON+aNZKk+Bi7w3GdYDdtNeGr\noDlX1inSsk4oOFXfxLOL9zAhPYl7r9ITm9gh5Jq2ItJPRP4gIkusn8eIyCOBD005zXUjrLJOrpZ1\nQoG3UdugM2ptFIpN2z8By4A06+d9wOOBCkg5V2xUJLeM9Z4JS8s69tpTfopXNx7mY1MGkjlAG7V2\nCcWSTrIx5nWgFcAY0wy0BDQq5Vg5mR5O1TfraB0bGWP4wb92kxgXxTdu00atnULxCP+MiPTBWtpY\nRK4BTgY0KuVY04cnkxAXxSIdrWObf+04yuZDNXxr1iht1Nos2IU0XxL+V4G3gaEisgF4FfhiQKNS\njhUbFcmtY1K1rGOTtkbt+PQk7svWRq3dQm61TGPMduAGYCrw/4Cx1rIJSnVJTlYqtfXNvFvYteWw\nVdc9v3w/1acbmDd3rDZqQ0DInfFKRD55wU2TRARjzKsBikk53PRhKd6yTm45N4/qZ3c4rrGn/BR/\n3niIB6cMJGuAnj8iFITi4mmT212PA2YA2/GWdpTqtJioCG4b6y3rNDSPIzYq0u6QHO8DjVqdURsy\nQq5pa4z5YrvL5/CugKmdHnVFcjI93rLOfh2tEwxv7Shl86EavjlrFL2663/fUBGKTdsL1QHD/R2I\ncpdpw5JJ1NE6QVFb38SPFhcwfkBP7tdGbUgJdh/Flxr+AqwhmXi/IMYArwcyKOV8bWWdpbvKaWhu\n0bJOAD2/wtuo/f0ns7VRG2JCrmkL/Lzd9WbgsDGmJEDxKBeZneXhH9tKWL+vmpljtHkbCHvLa/nT\ne4d4YPJAxqdrozbUhFzT1hizNhiBKPeZNjSZnt2iWZxXpgk/AIwxfP+tXSTERfFNnVEbkkLmCF9E\najlfyvnAXYAxxiQGLCrlCt6yTj+W5JVT39RCXLSWdfzp7Z2lbD5Yw7N3Z2qjNkSFTNPWGJNgjEns\n4JKgyV75y+xMD7UNzazX0Tp+VVvfxI8WWY3aydqoVV4+j9IRkb4iMrDtEsiglHtMG3a+rKP855cr\n9lN1uoGn544jUhu1ISvkxuGLyJ0ish84CKwFDgFLAhyXconoSG9ZZ3l+BfVNugirP+wtr+WV9w7x\nwOR0bdSqD/DlCH8ecA2wzxgzGO9M2w0BjUq5Sk5WGqe1rOMXbeeoTYiL4hu3jbI7HHUZobgefpMx\n5hgQISIRxpjVwIQAx6VcZOrQPiTFR7Mot9TuUMLe2ztL+ffBGr5x20h6a6M25JkOx8UEji/j8E+I\nSA9gHfA3EanEOx5fKb+IjozgtjGpLMor09E6V6CtUZs1oCcPTNY2m/owX47w5+JdTuErwFKgCLgj\nkEEp98nJ8nC6oZl1+3TJ5K761Upt1IabUCzpPAqkGWOajTF/Nsb8yirxKOU31w7tQ6/4aF1bp4v2\nVdTyyoZD3J+dzgRt1IaNkBulAyQCy0RkvYg8JiI6JVL5nXe0TiordLROp7U1arvHRvHNWdqoVRfn\ny/LITxljxgKPAWnAWhFZEfDIlOvkZHk409jCWi3rdMqC3DI2HdBGrbq8ziyPXAmUA8eAvoEJR7nZ\ntUOssk6ulnV8dbqhmR8tyiezf08enKKNWnVpvky8+g8RWQOsBJKBzxljsgIdmHKfqMgIZo1LZUWB\nlnV89auV+6k41cDTc8dqozYMhdxJzIFBwOPGmLHGmB8aY/IDHZRyr5zMNOoaW1izV8s6l7O/opY/\nvnuQ+7PTmTiwl93hqDDgSw3/28aYHcEIRqlrhvSmd/cYHa1zGd5G7W6rUatLHyvfdOUUh0oFTJQ1\nWmellnUuaWFuGRsPHOPrt42kT49Yu8NRYUITvgo5c7I8Vlmn0u5QQtLphmaeWZTPuP6JfEwbtWEt\nZNbDF5FhIjKtg9uvE5Ghl3thEUkXkdUiUiAiu0Xky1carHKHqwf3pk/3GBbqaJ0O/c+5Rq3OqA13\noTTx6nmgtoPbz1r3XU4z8DVjzGi8q20+JiJjOh+icpuoyAhuG5fKyoJKzjZqWae9wspa/mA1aidp\no1Z10qUSfoYxJvfCG40xW4GMy72wMabMGLPdul4LFAD9uxincpk5mR7ONmlZp722Rm18TKQ2alWX\nXCrhx13ivm6d2YiIZAATgX935nnKvaYM7k1yjxgW6midcxbllfFe0TG+oY1a1UWXSvhbRORzF94o\nIo8A23zdgLW08ht4x/Kf6uD+R0Vkq4hsrarSsdfKq220ziot6wBwpqGZZxYWMDYtkY9dPcjucFSY\nulTCfxz4tIisEZH/ti5rgc8CPjVgRSQab7L/mzHmzY4eY4x5yRiTbYzJTklJ6Wz8ysFysrxlndVa\n1uFXq/ZTfqpeG7UOE+x38qInQDHGVABTReQmYJx18yJjzCpfXli8c4b/ABQYY35xxZEq17l6cB+S\ne8SwKLeM2Zkeu8OxTWFlLX9Yf5D7sgdw1SBt1DpJsJdWuOwZr6xTGq7uwmtPAz4B5IlI20zd7xhj\nFnfhtZQLRUYIs8al8s9tJdQ1NhMf48sJ2pzFGMMP3/Y2ar+lSx+rKxSwiVfGmHeNMWKMyTLGTLAu\nmuxVp+RkplHf1MrqPe7s7yzOK2dDoc6oVf6hM21VSPOO1ollUZ77TnB+pqGZeQvzGZuWyEPaqHWk\nUJp4pZTtIiOE28elsmpPJXWNzXaHE1T/s6pQG7UOFzJLKygVKnKyPNQ3tbJqj3tG6xRWnub36w9w\n71XaqFX+owlfhbzJGVZZxyVr6xhjeLKtUXu7NmqV/2jCVyEvMkKYnZnK6r2VnGlwfllnya5y3i2s\n5mu3jiRZG7XKjzThq7CQk+mOsk5bo3aMJ5GHrtaljx0vBE9xqJTtsjN6k5Lg/LLOr1cXUnaynnl3\njSUqUv97Op02bZXqQGSEMHucs8s6RVXeRu09Vw3gqkG97Q5HBYEJ8vY04auwkZOVRkNzKysdWNZp\na9TGRUfybW3UqgDRhK/CRvagXvRNiGVRrvMmYS3ZVc76/dV8XRu1rqIlHaUuIiJCmJ3pYc3eKk47\nqKxT19jMMwvzGa2NWhVgmvBVWMnJ8njLOgUVdofiN79eVUjpyXrmzdVGrQos/XSpsHLVwF70S3TO\naJ2iqtO8vP4AH500gOwMbdS6ja6lo9QlREQIt4/zsGZf+Jd1tFGrJMhVfE34KuzMyfLQ6ICyzlKr\nUfu1W0aQkqCNWhV4mvBV2Jk0sBepiXEsDOOyTl2jd0btqNQEPn6NLn2sgkMTvgo7ERHC7ZmprN1X\nRW19k93hdMkLq61G7V3jtFHrYlrDV8oH58s64TcJ60DVaV5ad4CPTOrPZG3UupqOw1fKBxPTw7Os\n03aO2rioSJ64fbTd4SiX0YSvwlLbJKx1YVbWWbbb26j96q3aqFXBpwlfha2crFQaW1pZESajdbyN\n2gJGpSbwCW3UKrSGr5TPJqb3wtMzLmwmYb2wupCjJ87y9Fxt1Cp76KdOha3zZZ1qToV4Wedg9Rle\nXneQj0zsz5TB2qhV9tCEr8La7EyPt6yTH7plnbZGbWxUBN+erTNqlX004auwNjE9ibQQL+ss213B\nun1VfOWWEfRNiLM7HBVCdGkFpTqhrayzfn81J8+GXlnnbGPLuRm1n7xWG7XKXprwVdibnRW6ZR1t\n1KpQop9AFfYmpifRP6kbi/JCq6xzsPoML607wN3aqFUXo8MyleocEWF2Zirr91eFTFnHGMNTC3YT\nExXBE7r0sboIXVpBqS6YnemhqcWwPETKOu/kV7Bmr9WoTdRGrQoNmvCVI0xoK+uEwAnOzza28PSC\nfEb2S+BT2qhVIUQTvnIEESEny8O7hdWcrLO3rPObNW2NWj1Hrbo0CfLaCvppVI7RVtZ5J7/cthgO\nVZ/hd2sPcNeENK4e0se2OFR40Bq+Ul00fkBP+id1Y7FNo3WMMTxpNWq/M1uXPlahRxO+cgwRYU6W\nNQnLhrLOcqtR+/jM4dqoVSEpYAlfRP4oIpUisitQ21DqQrMzPTS3GpYFuaxztrGFpxbkM6JfDz41\nNSOo21bKV4E8wv8TMCuAr6/Uh2QN6MmAXsEv67y45vyM2mht1CofOWY9fGPMOqAmUK+vVEfOjdbZ\nX82JusagbPNQ9Rl+u+4AcyekcY02alUIs/1QREQeFZGtIrK1qqrK7nCUA+RYZZ13dgd+ElbbjNro\nCNFGrQp5tid8Y8xLxphsY0x2SkqK3eEoB8js35P03sFZW2dFQSWrrRm1/bRRq0Kc7QlfKX/zrq3j\nYUNhNcfPBK6sU9/UwlMLdmswQBG8AAAMG0lEQVSjVnWZY2r4StlpTmaat6wTwNE6v1lTRMnxszx1\npzZqVXgI5LDM/wU2AiNFpEREHgnUtpS60Lj+iQzsHc+ivMAk/MPHzvDbtUXcOT6Na4dqo1Z1TbDP\neBUVqBc2xjwYqNdW6nLayjovrz/A8TON9Ooe49fXf2pBPtERwndztFGruk5LOkr5yZwsDy2thmW7\n/XuUvyK/glV7Knl8pjZqVXjRhK8ca2xaIoP6xPt1tE59UwtPLdzN8L49eHhaht9eV6lg0ISvHKut\nrPNe0TFq/DRa58U1RRTXnOWpuWO1UavCjn5ilaPlZPqvrHPkWB0vri3ijvFpTB2a7IfolAouTfjK\n0camJZLRJ94va+u0zaj9rs6oVWFKE75ytPZlnWOnG7r8OivyK1i5p5IvzxxOak9t1KrwpAlfOV7O\nudE6XVtbp61RO6xvDz49bbCfo1NultGne1C3pwlfOd4YTyKDk7t3uazz27XeRu3Td2qjVvnX+PSk\noG5PP73K8bxlnVTeK6rudFnnyLE6XlxTxJwsD1OHaaNWhTdN+MoVcjLTaDWwtJOjdZ5euJvICOF7\nOWMCFJlSwaMJX7nCaE8CQzpZ1llZUMGKgkq+PEMbtcoZNOErV2gbrbOx6BjVPpR1vEsf5zM0pbs2\napVjaMJXrpGT5fGWdXZdvqzzu7UHOFJTx9NzxxETpf9NlDPoJ1m5xqjUBIakXL6sU1xTx2/WFJKT\n5WGaNmqVg2jCV64hIuRketh04BhVtRcv6zy1IN9q1OqMWuUsmvCVq5wr61xktM6qPRWsKKjgSzOG\n4+nZLcjRKRVYmvCVq4zsl8DQlO4szv1wWae+qYUn3/Y2aj+jjVrlQJrwlau0lXX+ffDDZZ2X1nkb\ntU/dqY1a5Uz6qVauk5P14UlYxTV1vLC6kJxMD9OHa6NWOZMmfOU6I/r1YGhKdxbllp677emFVqN2\njjZqlXNpwleuIyLkZKXx74M1VNbWs3pPJcvzK/jizdqoVc6mCV+50pwsD8bA2ztKeXLBboakdOeR\n6dqoVc4WZXcAStlhRL8EhvXtwU+X7qWxpZW/PnK1NmqV4+knXLlWTqaHxpZWZmemaqNWuYIe4SvX\nun9yOgVlp/j+HF36WLmDJnzlWmlJ3Xjpk9l2h6FU0GhJRymlXEITvlJKuYQmfKWUcglN+Eop5RKa\n8JVSyiU04SullEtowldKKZfQcfhKKWWjH8wZw7VD+wRlWwE9wheRWSKyV0QKReTbgdyWUkqFo89M\nH8xoT2JQthWwhC8ikcALwO3AGOBBEdE57EopZZNAHuFPAQqNMQeMMY3AfGBuALenlFLqEgKZ8PsD\nxe1+LrFuU0opZYNAJnzp4DbzoQeJPCoiW0Vka1VVVQDDUUopdwtkwi8B0tv9PAAovfBBxpiXjDHZ\nxpjslJSUAIajlFLuFsiEvwUYLiKDRSQGeAB4O4DbU0opdQkBG4dvjGkWkS8Ay4BI4I/GmN2B2p5S\nSqlLC+jEK2PMYmBxILehlFLKN2LMh/qothGRKuBwkDebDFQHeZt2cdO+grv2V/fVmXzZ10HGGJ8a\noCGV8O0gIluNMa44z52b9hXctb+6r87k733VxdOUUsolNOErpZRLaMKHl+wOIIjctK/grv3VfXUm\nv+6r62v4SinlFnqEr5RSLuHohH+59fhF5PMikiciO0Tk3bblm0UkQ0TOWrfvEJHfBj/6zvH13AMi\nco+IGBHJbnfbE9bz9orIbcGJuOu6uq9OfF9F5GERqWq3T59td9+nRGS/dflUcCPvvCvc15Z2t4fF\njH5fPscicp+I5IvIbhH5e7vbu/beGmMcecE7u7cIGALEADuBMRc8JrHd9TuBpdb1DGCX3fvgz321\nHpcArAM2AdnWbWOsx8cCg63XibR7nwK0r457X4GHgV938NzewAHr317W9V5271Mg9tW677Td+xCA\n/R0OvN/2vgF9r/S9dfIR/mXX4zfGnGr3Y3c6WM0zTPh67oF5wE+B+na3zQXmG2MajDEHgULr9ULV\nlexruLmSc0rcBiw3xtQYY44Dy4FZAYrTH9x2/gxf9vdzwAvW+4cxptK6vcvvrZMTvk/r8YvIYyJS\nhDc5fKndXYNF5H0RWSsi1wU21Ct22X0VkYlAujFmYWefG2KuZF/BYe+r5aMikisi/xSRthVqHfe+\nWjraV4A4a5n1TSJyV0Aj9Q9f9ncEMEJENlj7NasTz+2QkxO+T+vxG2NeMMYMBb4FfM+6uQwYaIyZ\nCHwV+LuIBOekk11zyX0VkQjgOeBrnX1uCLqSfXXU+2pZAGQYY7KAFcCfO/HcUHIl+wre9zUb+Bjw\nvIgMDUyYfuPL/kbhLevcCDwI/F5Eknx8boecnPB9Wo+/nfnAXQBWeeOYdX0b3lrbiADF6Q+X29cE\nYBywRkQOAdcAb1vNzM7+nuzW5X114PuKMeaYMabB+vFl4CpfnxtirmRfMcaUWv8eANYAEwMZrB/4\n8v6UAG8ZY5qscutevF8AXX9v7W5eBLApEoW3mTGY802RsRc2RdpdvwPYal1PwWpc4m2qHAV6271P\nV7KvFzx+DecbmWP5YNP2AKHdtL2SfXXc+wp42l2/G9hkXe8NHMTb1OtlXXfqvvYCYq3rycB+Omjk\nh9LFx/2dBfy53X4VA32u5L0N6PLIdjIXWY9fRJ7Gm9jfBr4gIjOBJuA40Da86XrgaRFpBlqAzxtj\naoK/F77xcV8v9tzdIvI6kA80A48ZY1qCEngXXMm+4sz39Usicife964G70gWjDE1IjIP74mIAJ52\n6r4Co4HfiUgr3qrFj40x+UHfiU7wcX+XAbeKSD7ez+s3jPUXalffW51pq5RSLuHkGr5SSql2NOEr\npZRLaMJXSimX0ISvlFIuoQlfKaVcQhO+CgnWqpZ/afdzlLUyYkfLI/hrmy9YqyvmX7CK5j2dfJ1J\n7aa9X3hfDxGZL95VWXeJyHoRiffPHijVOY4dh6/CzhlgnIh0M8acBW7BOzEqYIwxj4F32WRgoTFm\nQhdfahLe2b1LO7jvK8ARY8wD1rZG4Z330WUiEmWMab6S11DupEf4KpQsAXKs6w8C/9t2h4h0F5E/\nisgWa/GzudbtGdZR83brMtW6/UYRWWMtsrVHRP4mIh2tQdIhERkuIstEZJuIrBOREdbtD1hH6jtF\nZLWIdAN+ADx0kb8OPLT74jLG7DHGNFmv9WlrIbCdIvKKddtg63VzRWS5iAywbv+riPy3iKwGnrX+\ncviTiGy2fh93dOYXrVzK7inGetGLMd71zIEs4J9AHLAD76JRC637nwU+bl1PAvbhXdI6Hoizbh/O\n+eUxbgRO4l1nJALYCEy/yLYzuGCdfGA1MNS6Pg14x7peAPRri8P697PA8xd57auAKuA9vEs2D7Nu\nHw/swZoS3+7fJcBD1vVHgX9a1/8K/AuIsH7+KfCAdb2X9fuIs/t91EtoX7Sko0KGMSbXKq88CCy+\n4O5bgTtF5OvWz3HAQLyLRv1aRCbgnX7efjG0zcaYEgAR2YE3sb97uTisFQmvAd5o90dB2/+VDcCr\nIvIP4E0f9mmbiAyx4p8JbBWRKcDNwGvGmhJvzk+NvxqYY11/Fe+XRJt/GGNareu3ArfL+TMltf0+\n9l0uJuVemvBVqHkb+DneI/Q+7W4X4KPGmL3tHywiTwIVeI+YI/jgCU8a2l1vwffPuwDVpuOa/uc4\nn5R3ikjW5V7MGFMLvIH3C0SA261tdHZdkzMXxHiXMaaok6+hXExr+CrU/BHvYlB5F9y+DPhiWx1e\nvCc5AegJlFlHvp/AuxDVFTHeswiVicjd1rYiRGS8dfcQY8wm4Pt4F9zrD9TiXZb5Q0RkuvUXAyIS\ni3ehr8N413N/QER6W/f1tp6yCbjPuv5xvKdp7Mgy2p2wp93vQ6mL0oSvQooxpsQY88sO7poHRAO5\nIrKL86WO3wCfEpFNeMs5Zzp4blc8AHxeRHYCuzlfZnlORPKAPGCFMWYXsAoYbzVPL2zaDgfWW8/Z\njreX8JYxJhdvHX6dVW76mfX4LwCPikgucD/eUT4deQqIt4Z77gaevPJdVk6nq2UqpZRL6BG+Ukq5\nhCZ8pZRyCU34SinlEprwlVLKJTThK6WUS2jCV0opl9CEr5RSLqEJXymlXOL/A4y2Y8XyH3e9AAAA\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f696ef27d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Takes around 30 minutes\n",
    "rand_list = {\"C\": scipy.stats.uniform(0, 5),\n",
    "             \"gamma\": scipy.stats.uniform(0.1, 1)}\n",
    "\n",
    "rand_search = RandomizedSearchCV(SVC(kernel='linear'), param_distributions = rand_list,\\\n",
    "                                 n_iter = 20, n_jobs = 4, scoring = 'f1_macro')\n",
    "rand_search.fit(features, labels)\n",
    "\n",
    "print(rand_search.best_score_)\n",
    "print (len(rand_search.cv_results_['param_C'].data))\n",
    "print (rand_search.best_params_)\n",
    "\n",
    "rand_search.cv_results_['param_gamma'].data\n",
    "plt.plot(sorted(rand_search.cv_results_['mean_test_score']), rand_search.cv_results_['param_C'].data, \"-\")\n",
    "plt.xlabel(\"Mean Test Score\")\n",
    "plt.ylabel(\"C value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=4.6480402875255615, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.54056011825237438,\n",
       "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KERNEL = 'linear'\n",
    "classifier = SVC(kernel=KERNEL, C=rand_search.best_params_['C'], gamma=rand_search.best_params_['gamma'])\n",
    "classifier.fit(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "def plot_learning_curve(estimator, title, training_curve=False, X, y, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if not training_curve:\n",
    "        plt.ylim((0.4, 0.7))\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve( estimator, X, y, cv=None, n_jobs=1, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "    \n",
    "    if training_curve:\n",
    "        plt.fill_between(train_sizes, train_scores_mean-train_scores_std, \\\n",
    "                         train_scores_mean+train_scores_std, alpha=0.1, color=\"r\")\n",
    "        plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "    \n",
    "    plt.fill_between(train_sizes, test_scores_mean-test_scores_std,test_scores_mean+test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "\n",
    "plot_learning_curve(classifier, \"SVM Learning Curve\", features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prédiction sur les données d'apprentissage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9968\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "nb_predict_train = classifier.predict(features)\n",
    "#check accuracy\n",
    "print(\"Accuracy: {:0.4f}\".format(metrics.accuracy_score(labels, nb_predict_train)))\n",
    "del features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2682    1    9]\n",
      " [   2 1014    8]\n",
      " [   3    0 3486]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       1.00      1.00      1.00      2692\n",
      "         -1       1.00      0.99      0.99      1024\n",
      "          0       1.00      1.00      1.00      3489\n",
      "\n",
      "avg / total       1.00      1.00      1.00      7205\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print confusion matrix\n",
    "print(\"{}\".format(metrics.confusion_matrix(labels, nb_predict_train, \n",
    "                                           labels=[1,-1, 0])))\n",
    "\n",
    "print(\"{}\".format(metrics.classification_report(labels, nb_predict_train, \n",
    "                                                labels=[1, -1, 0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prédire en utilisant le modèle\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importer test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8902, 4)\n"
     ]
    }
   ],
   "source": [
    "t_df = pd.read_csv('/data/test/actual/test_B_labeled.tsv', sep='\\t', header=None)\n",
    "print(t_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7584, 4)\n",
      "(7584,)\n"
     ]
    }
   ],
   "source": [
    "t_df = t_df[t_df[3] != 'Not Available']\n",
    "actual_labels = t_df[2]\n",
    "actual_labels = actual_labels.map(mapper)\n",
    "print(t_df.shape)\n",
    "print(actual_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnMAAAHoCAYAAAAi+WkTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4JgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f696da08b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = [len(t_df[t_df[2] == i]) for i in ['positive', 'negative', 'neutral']]\n",
    "x = ['positive', 'negative', 'neutral']\n",
    "x_pos = range(len(x))\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.bar(x_pos, y, alpha=0.5)\n",
    "plt.xticks(x_pos, x)\n",
    "plt.ylabel('# Occurences').set_size(15)\n",
    "plt.xlabel('Classes').set_size(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pré-traiter les tweets de l'ensemble de données de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_tweets_test = t_df[3]\n",
    "\n",
    "t_unigram140Score, t_unigram140Reps = [], []\n",
    "for tweet in raw_tweets_test:\n",
    "    score, reps = unigram140Polarity(tweet.lower(), unigram140_d)\n",
    "    t_unigram140Score.append(score)\n",
    "    t_unigram140Reps.append(reps)\n",
    "\n",
    "t_bigram140Score, t_bigram140Reps = [], []\n",
    "for tweet in raw_tweets_test:\n",
    "    score, reps = bigram140Polarity(tweet.lower(), bigram140_d)\n",
    "    t_bigram140Score.append(score)\n",
    "    t_bigram140Reps.append(reps)\n",
    "\n",
    "t_SemEvalScore, t_SemEvalReps = [], []\n",
    "for tweet in raw_tweets_test:\n",
    "    score, reps = SemEvalLexiconPolarity(tweet.lower(), EnglishLexicon)\n",
    "    t_SemEvalScore.append(score)\n",
    "    t_SemEvalReps.append(reps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_tweets_test = [replaceSlangs(tweet, slangs) for tweet in raw_tweets_test]\n",
    "raw_tweets_test = [replace_apostrophe(tweet, apos) for tweet in raw_tweets_test]\n",
    "raw_tweets_test = [subsEmoticon(tweet, dict) for tweet in raw_tweets_test]\n",
    "raw_tweets_test = [handle_negation(tweet) for tweet in raw_tweets_test] #negation\n",
    "lemmatized_tweets_test = [lemma(tweet) for tweet in raw_tweets_test]\n",
    "clean_tweets_test = [remove_hashtags(tweet) for tweet in lemmatized_tweets_test]\n",
    "preprocessed_tweets_test = [preprocess(tweet) for tweet in clean_tweets_test]\n",
    "final_tweets_test = [rem_stop(tweet) for tweet in preprocessed_tweets_test]\n",
    "t_df[3] = final_tweets_test\n",
    "\n",
    "del raw_tweets_test, lemmatized_tweets_test, preprocessed_tweets_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done scoring test set ..\n",
      "Done reshaping test set ..\n",
      "Done normalizing test set ..\n",
      "(7584, 7)\n"
     ]
    }
   ],
   "source": [
    "t_raw_tweets_MPQA = [subsMPQA(tweet,dictionary) for tweet in final_tweets_test]\n",
    "t_raw_tweets_wsd = [subs_pos(tweet, expanded_pos) for tweet in t_raw_tweets_MPQA]\n",
    "t_raw_tweets_wsd = [subs_neg(tweet, expanded_neg) for tweet in t_raw_tweets_wsd]\n",
    "t_raw_tweets_bing = [subs_pos(tweet, expanded_pos) for tweet in t_raw_tweets_wsd]\n",
    "t_raw_tweets_bing = [subs_neg(tweet, expanded_neg) for tweet in t_raw_tweets_bing]\n",
    "\n",
    "t_BingMpqaScore = []\n",
    "t_AfinnScore, t_AfinnReps = [], []\n",
    "t_WordnetScore, t_WordnetReps = [], []\n",
    "t_SenticnetScore, t_SenticnetReps = [], []\n",
    "t_length = len(t_raw_tweets_bing)\n",
    "\n",
    "for tw in t_raw_tweets_bing:\n",
    "    Bing_MPQA = 0\n",
    "    for i in tw:\n",
    "        if (i == 'positive'):\n",
    "            Bing_MPQA +=  1\n",
    "        if (i == 'negative'):\n",
    "            Bing_MPQA -= 1\n",
    "    t_BingMpqaScore.append(Bing_MPQA)\n",
    "    tmp = afinnPolarity(tw, afinn)\n",
    "    t_AfinnScore.append(tmp[0])\n",
    "    t_AfinnReps.append(tmp[1])\n",
    "    tmp = WordnetPolarity(tw, sentiWordnet)\n",
    "    t_WordnetScore.append(tmp[0])\n",
    "    t_WordnetReps.append(tmp[1])\n",
    "    tmp = SenticnetPolarity(tw)\n",
    "    t_SenticnetScore.append(tmp[0])\n",
    "    t_SenticnetReps.append(tmp[1])\n",
    "print(\"Done scoring test set ..\")\n",
    "    \n",
    "#reshape\n",
    "t_BingMpqaScore = np.array(t_BingMpqaScore).reshape(t_length, 1)\n",
    "t_AfinnScore = np.array(t_AfinnScore).reshape(t_length, 1)\n",
    "t_AfinnReps = np.array(t_AfinnReps).reshape(t_length, 1)\n",
    "t_WordnetScore = np.array(t_WordnetScore).reshape(t_length, 1)\n",
    "t_WordnetReps = np.array(t_WordnetReps).reshape(t_length, 1)\n",
    "t_SemEvalScore = np.array(t_SemEvalScore).reshape(t_length, 1)\n",
    "t_SemEvalReps = np.array(t_SemEvalReps).reshape(t_length, 1)\n",
    "t_SenticnetScore = np.array(t_SenticnetScore).reshape(t_length, 1)\n",
    "t_SenticnetReps = np.array(t_SenticnetReps).reshape(t_length, 1)\n",
    "t_unigram140Score = np.array(t_unigram140Score).reshape(t_length, 1)\n",
    "t_unigram140Reps = np.array(t_unigram140Reps).reshape(t_length, 1)\n",
    "t_bigram140Score = np.array(t_bigram140Score).reshape(t_length, 1)\n",
    "t_bigram140Reps = np.array(t_bigram140Reps).reshape(t_length, 1)\n",
    "print(\"Done reshaping test set ..\")\n",
    "\n",
    "#Normalization\n",
    "t_BingMpqaScore = t_BingMpqaScore/np.linalg.norm(t_BingMpqaScore)\n",
    "t_AfinnScore = t_AfinnScore/np.linalg.norm(t_AfinnScore)\n",
    "t_AfinnReps = t_AfinnReps/np.linalg.norm(t_AfinnReps)\n",
    "t_WordnetScore = t_WordnetScore/np.linalg.norm(t_WordnetScore)\n",
    "t_WordnetReps = t_WordnetReps/np.linalg.norm(t_WordnetReps)\n",
    "t_SemEvalScore = t_SemEvalScore/np.linalg.norm(t_SemEvalScore)\n",
    "t_SemEvalReps = t_SemEvalReps/np.linalg.norm(t_SemEvalReps)\n",
    "t_SenticnetScore = t_SenticnetScore/np.linalg.norm(t_SenticnetScore)\n",
    "t_SenticnetReps = t_SenticnetReps/np.linalg.norm(t_SenticnetReps)\n",
    "t_unigram140Score = t_unigram140Score/np.linalg.norm(t_unigram140Score)\n",
    "t_unigram140Reps = t_unigram140Reps/np.linalg.norm(t_unigram140Reps)\n",
    "t_bigram140Score = t_bigram140Score/np.linalg.norm(t_bigram140Score)\n",
    "t_bigram140Reps = t_bigram140Reps/np.linalg.norm(t_bigram140Reps)\n",
    "print(\"Done normalizing test set ..\")\n",
    "\n",
    "t_all_scores = np.hstack( (t_BingMpqaScore, t_AfinnScore, t_WordnetScore, t_SemEvalScore, t_SenticnetScore, \\\n",
    "                                               t_unigram140Score, t_bigram140Score) )\n",
    "t_sum_score = np.sum(t_all_scores, axis=1).reshape(t_length, 1)\n",
    "print (t_all_scores.shape)\n",
    "\n",
    "# Delete\n",
    "del t_raw_tweets_MPQA, t_raw_tweets_bing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>282031301962395648</td>\n",
       "      <td>T14111200</td>\n",
       "      <td>neutral</td>\n",
       "      <td>dec st know end_not world_not baby_not boom_not</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11975</td>\n",
       "      <td>SM112166</td>\n",
       "      <td>negative</td>\n",
       "      <td>yar quite clever aft many guess lor got ask br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>136592</td>\n",
       "      <td>LJ112295</td>\n",
       "      <td>negative</td>\n",
       "      <td>yeah thin lizzy hate informercial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>253421252956545024</td>\n",
       "      <td>T13114433</td>\n",
       "      <td>neutral</td>\n",
       "      <td>mt deir ezzor ali bashar altheeb wa martyred w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>220880422320603137</td>\n",
       "      <td>T14114138</td>\n",
       "      <td>negative</td>\n",
       "      <td>hate life see_not roskilde_not festival_not sa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0          1         2  \\\n",
       "2  282031301962395648  T14111200   neutral   \n",
       "3               11975   SM112166  negative   \n",
       "4              136592   LJ112295  negative   \n",
       "5  253421252956545024  T13114433   neutral   \n",
       "6  220880422320603137  T14114138  negative   \n",
       "\n",
       "                                                   3  \n",
       "2    dec st know end_not world_not baby_not boom_not  \n",
       "3  yar quite clever aft many guess lor got ask br...  \n",
       "4                  yeah thin lizzy hate informercial  \n",
       "5  mt deir ezzor ali bashar altheeb wa martyred w...  \n",
       "6  hate life see_not roskilde_not festival_not sa...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Créer le features vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7584, 5)\n",
      "(7584, 134911)\n"
     ]
    }
   ],
   "source": [
    "test_count_features = count_vectorizer.transform(final_tweets_test)\n",
    "test_count_features = svd.transform(test_count_features)\n",
    "test_count_features = scipy.sparse.csr_matrix(test_count_features)\n",
    "print (test_count_features.shape)\n",
    "\n",
    "\n",
    "test_tfidf_features = tfidf_vectorizer.transform(final_tweets_test)\n",
    "test_tfidf_features = scipy.sparse.csr_matrix(test_tfidf_features)\n",
    "print (test_tfidf_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7584, 13)\n",
      "(7584, 134929)\n"
     ]
    }
   ],
   "source": [
    "t_final_total = scipy.sparse.csr_matrix(np.hstack( (t_all_scores, t_sum_score, t_AfinnReps, t_WordnetReps, t_SemEvalReps, t_unigram140Reps, t_bigram140Reps) ))\n",
    "print (t_final_total.shape)\n",
    "test_features = scipy.sparse.hstack([test_count_features, test_tfidf_features, t_final_total])\n",
    "print (test_features.shape)\n",
    "\n",
    "del t_all_scores, t_sum_score, t_BingMpqaScore, t_AfinnScore, t_WordnetScore, t_SemEvalScore, t_unigram140Score, t_bigram140Score\n",
    "del t_AfinnReps, t_WordnetReps, t_SemEvalReps, t_unigram140Reps, t_bigram140Reps\n",
    "del test_count_features, test_tfidf_features, t_final_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prédire les étiquettes en utilisant le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_labels = classifier.predict(test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Évaluer le modèle\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 68.06%\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {:0.2f}%'.format(metrics.accuracy_score(actual_labels, predicted_labels) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.65      0.52      0.58      1296\n",
      "          0       0.66      0.79      0.72      3448\n",
      "          1       0.74      0.62      0.67      2840\n",
      "\n",
      "avg / total       0.69      0.68      0.68      7584\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Rapport de classification\n",
    "print('{}'.format(metrics.classification_report(actual_labels, predicted_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voir [Confusion Matrix](https://fr.wikipedia.org/wiki/Matrice_de_confusion) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1752  143  945]\n",
      " [ 138  671  487]\n",
      " [ 486  223 2739]]\n",
      "\n",
      "\u001b[31m\" macro f1 score \"\u001b[0m\n",
      "0.6553320556505682\n",
      "\n",
      "\u001b[31m\" micro f1 score \"\u001b[0m\n",
      "0.6806434599156118\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print('{}\\n'.format(metrics.confusion_matrix(actual_labels, predicted_labels, labels=[1,-1,0])))\n",
    "#-------------------- F1-score --------------------\n",
    "print(\"\\x1b[31m\\\" macro f1 score \\\"\\x1b[0m\")\n",
    "print('{}\\n'.format(metrics.f1_score(actual_labels, predicted_labels, average='macro')))\n",
    "print(\"\\x1b[31m\\\" micro f1 score \\\"\\x1b[0m\")\n",
    "print('{}\\n'.format(metrics.f1_score(actual_labels, predicted_labels, average='micro')))\n",
    "\n",
    "#-------------------- precision-score --------------------\n",
    "print(\"\\x1b[31m\\\" macro precision score \\\"\\x1b[0m\")\n",
    "print('{}\\n'.format(metrics.precision_score(actual_labels, predicted_labels, average='macro')))\n",
    "print(\"\\x1b[31m\\\" micro precision score \\\"\\x1b[0m\")\n",
    "print('{}\\n'.format(metrics.precision_score(actual_labels, predicted_labels, average='micro')))\n",
    "\n",
    "#-------------------- recall-score --------------------\n",
    "print(\"\\x1b[31m\\\" macro recall score \\\"\\x1b[0m\")\n",
    "print('{}\\n'.format(metrics.recall_score(actual_labels, predicted_labels, average='macro')))\n",
    "print(\"\\x1b[31m\\\" micro recall score \\\"\\x1b[0m\")\n",
    "print('{}\\n'.format(metrics.recall_score(actual_labels, predicted_labels, average='micro')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparaison avec les 5 meilleures équipes du subtask B\n",
    "\n",
    "Nous comparons notre score avec les autres équipes de l'atelier. Les résultats sont tirés du document joint:\n",
    "[Final report SemEval 2014 Subtask 9](http://www.aclweb.org/anthology/S14-2009)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Team|Accuracy (Macro Averaged)| Accuracy (Micro Averaged)|\n",
    "|----|-------------------------|--------------------------|\n",
    "|TeamX|65.63%|69.99%|\n",
    "|coooolll|63.23%|70.51%|\n",
    "|RTRGO|63.08%|70.15%|\n",
    "|NRC-Canada|67.62%|71.37%|\n",
    "|TUGAS|63.89%|68.84%|\n",
    "|**_ME_**|_63.67%_|_67.44%_|\n",
    "| | |***classement : 10 / 50***|\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# <font color='red'> Analyse des modèles de classification:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Model|F1 Macro Averaging|F1 Micro Averaging|Accuracy|\n",
    "|-----|---------------|----------------|--|\n",
    "|NB (without Lexicons)|51.17%|60.28%|60.28%|\n",
    "|NB (with Lexicons)|46.00%|59.53%|59.53%|\n",
    "|LR (without Lexicons)|55.42%|64.39%|64.39%|\n",
    "|LR (with Lexicons)|40.83%|52.26%|52.26%|\n",
    "|SVM (without Lexicons)|61.92%|66.16%|66.17%|\n",
    "|SVM (with Afinn Lexicon)|59.81%|65.50%|65.51%|\n",
    "|SVM (with Lexicon)|65.53%|68.06%|68.06%|\n",
    "\n",
    "Notes:\n",
    "- I have used CountVector and tfidfVector as bag of words.\n",
    "- In NB, I didn't use the TruncatedSVD model which summarizes the Count Vector. And that's because NB model doesn't accept negative numbers as input.\n",
    "- I used the whole Count Vector with NB and LR. I believe it's better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
