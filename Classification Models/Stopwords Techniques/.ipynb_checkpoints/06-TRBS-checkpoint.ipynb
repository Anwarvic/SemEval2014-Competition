{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# <font color='green'>Sentiment Analysis</font> ![title](./resources/img/sent_twitter.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>Reading Data</font>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import liberies\n",
    "\n",
    "Refer to the web pages for individual libraries\n",
    "* [Pandas](http://pandas.pydata.org/), to load and manage data\n",
    "* [Matplotlib](http://matplotlib.org/), for visualization\n",
    "* [numpy](http://www.numpy.org/) for painting representation and manipulation\n",
    "* [re](https://docs.python.org/3/library/re.html) for regular expression\n",
    "* [nltk](http://www.nltk.org/) for pretreatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "from copy import copy\n",
    "import collections\n",
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import make_scorer, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading the dataset\n",
    "Some of the data \"downloaded_cleansed_B\" is produced out of the \"downloaded_cleansed_A\". The difference is:\n",
    "- \"downloaded_cleansed_A\" has three columns that we won't use.\n",
    "- \"downloaded_cleansed_A\" has repeatted tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9665, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>264183816548130816</td>\n",
       "      <td>15140428</td>\n",
       "      <td>positive</td>\n",
       "      <td>Gas by my house hit $3.39!!!! I'm going to Cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>263405084770172928</td>\n",
       "      <td>591166521</td>\n",
       "      <td>negative</td>\n",
       "      <td>Not Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>262163168678248449</td>\n",
       "      <td>35266263</td>\n",
       "      <td>negative</td>\n",
       "      <td>Not Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>264249301910310912</td>\n",
       "      <td>18516728</td>\n",
       "      <td>negative</td>\n",
       "      <td>Iranian general says Israel's Iron Dome can't ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>262682041215234048</td>\n",
       "      <td>254373818</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Not Available</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0          1         2  \\\n",
       "0  264183816548130816   15140428  positive   \n",
       "1  263405084770172928  591166521  negative   \n",
       "2  262163168678248449   35266263  negative   \n",
       "3  264249301910310912   18516728  negative   \n",
       "4  262682041215234048  254373818   neutral   \n",
       "\n",
       "                                                   3  \n",
       "0  Gas by my house hit $3.39!!!! I'm going to Cha...  \n",
       "1                                      Not Available  \n",
       "2                                      Not Available  \n",
       "3  Iranian general says Israel's Iron Dome can't ...  \n",
       "4                                      Not Available  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/train/downloaded_cleansed_B.tsv', sep= '\\t', header=None)\n",
    "print (df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that some tweets are \"Not Available\". We will reject them because it will not help in the analysis of feelings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Supprimer tous les tweets \"NOT AVAILABLE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>264183816548130816</td>\n",
       "      <td>15140428</td>\n",
       "      <td>positive</td>\n",
       "      <td>Gas by my house hit $3.39!!!! I'm going to Cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>264249301910310912</td>\n",
       "      <td>18516728</td>\n",
       "      <td>negative</td>\n",
       "      <td>Iranian general says Israel's Iron Dome can't ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>264105751826538497</td>\n",
       "      <td>147088367</td>\n",
       "      <td>positive</td>\n",
       "      <td>with J Davlar 11th. Main rivals are team Polan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>264094586689953794</td>\n",
       "      <td>332474633</td>\n",
       "      <td>negative</td>\n",
       "      <td>Talking about ACT's &amp;amp;&amp;amp; SAT's, deciding...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>254941790757601280</td>\n",
       "      <td>557103111</td>\n",
       "      <td>negative</td>\n",
       "      <td>They may have a SuperBowl in Dallas, but Dalla...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0          1         2  \\\n",
       "0  264183816548130816   15140428  positive   \n",
       "3  264249301910310912   18516728  negative   \n",
       "6  264105751826538497  147088367  positive   \n",
       "7  264094586689953794  332474633  negative   \n",
       "9  254941790757601280  557103111  negative   \n",
       "\n",
       "                                                   3  \n",
       "0  Gas by my house hit $3.39!!!! I'm going to Cha...  \n",
       "3  Iranian general says Israel's Iron Dome can't ...  \n",
       "6  with J Davlar 11th. Main rivals are team Polan...  \n",
       "7  Talking about ACT's &amp;&amp; SAT's, deciding...  \n",
       "9  They may have a SuperBowl in Dallas, but Dalla...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df[3] != \"Not Available\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7205, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='blue'>Training tweets are too limited: just 7205 tweets ...</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Draw the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAncAAAHsCAYAAACwg4t/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6454cafb38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# calculate the total number of occurrences of each class\n",
    "y = [len(df[df[2] == i]) for i in ['negative', 'positive', 'neutral']]\n",
    "# X axis\n",
    "objects = ['negative', 'positive', 'neutral']\n",
    "x_pos = range(len(objects))\n",
    "\n",
    "# Draw Diagram\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.bar(x_pos, y, alpha=0.5)\n",
    "plt.xticks(x_pos, objects)\n",
    "plt.ylabel('Occurences').set_size(20)\n",
    "plt.xlabel('Classes').set_size(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretation\n",
    "From the graph above, we can clearly note that the \"negative\" class has the fewest samples in the data compared to \"positive\" and \"neutral\". As a result, the data appears to be unbalanced and underfit the \"negative\" class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raw_tweets = list(df[3])\n",
    "labels = df[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## <font color='red'>Pre-train the tweets</font>\n",
    "https://nlp.stanford.edu/IR-book/html/htmledition/determining-the-vocabulary-of-terms-1.html\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment140 Score\n",
    "\n",
    "Before doing any preprocessing over the tweets, we will use the score of Sentiment140 corpus first. This corpus has the score of the most common words (formal, informal) used in twitter. The score is a number between [-4.999: 4.999].\n",
    "\n",
    "The score will be divided into three parts:\n",
    "- unigram score  --> 'unigram140_score'\n",
    "- bigram score   --> 'bigram140_score'\n",
    "- pair score     --> 'pair140_score'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7205"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Sentiment140_dictionary(filename):\n",
    "    sentiment140 = {}\n",
    "    with open(filename) as fin:\n",
    "        line = fin.readline()[:-1]\n",
    "        while line:\n",
    "            line = line.split('\\t')\n",
    "            sentiment140[line[0]] = float(line[1])\n",
    "            line = fin.readline()[:-1]\n",
    "    return sentiment140\n",
    "\n",
    "\n",
    "def unigram140Polarity(tweet, d):\n",
    "    score=0.0\n",
    "    reps = 0\n",
    "    for w in tweet.split(' '):\n",
    "        if w in d.keys():\n",
    "            reps += 1\n",
    "            score+=d[w]\n",
    "    return score, reps\n",
    "\n",
    "unigram140_d = Sentiment140_dictionary('resources/Sentiment140/unigrams-pmilexicon.txt')\n",
    "unigram140Score, unigram140Reps = [], []\n",
    "for tweet in raw_tweets:\n",
    "    score, reps = unigram140Polarity(tweet.lower(), unigram140_d)\n",
    "    unigram140Score.append(score)\n",
    "    unigram140Reps.append(reps)\n",
    "\n",
    "len(unigram140Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7205"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_bigrams(input_list):\n",
    "    bigram_list = []\n",
    "    for i in range(len(input_list)-1):\n",
    "        bigram_list.append(input_list[i] + \" \" + input_list[i+1])\n",
    "    return bigram_list\n",
    "\n",
    "\n",
    "def bigram140Polarity(tweet, d):\n",
    "    score=0.0\n",
    "    reps = 0\n",
    "    tweet = find_bigrams(tweet.split(' '))\n",
    "    for w in tweet:\n",
    "        if w in d.keys():\n",
    "            reps += 1\n",
    "            score+=d[w]\n",
    "    return score, reps\n",
    "\n",
    "\n",
    "bigram140_d = Sentiment140_dictionary('resources/Sentiment140/bigrams-pmilexicon.txt')\n",
    "bigram140Score, bigram140Reps = [], []\n",
    "for tweet in raw_tweets:\n",
    "    score, reps = bigram140Polarity(tweet.lower(), bigram140_d)\n",
    "    bigram140Score.append(score)\n",
    "    bigram140Reps.append(reps)\n",
    "\n",
    "len(bigram140Score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SemEval2015 English lexicon \n",
    "\n",
    "These are the very first and last entries of 'SemEval2015-English-Twitter-Lexicon.txt':\n",
    "- 0.984\tloves\n",
    "- 0.984\t#inspirational\n",
    "- 0.969\tamazing\n",
    "- 0.969\t#peaceful\n",
    "- 0.953\t#greatness\n",
    "- ...\n",
    "- -0.969\tabuse\n",
    "- -0.969\t#failure\n",
    "- -0.982\tkill\n",
    "- -0.984\tbitches\n",
    "- -0.984\t#disappointment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of EnglishLexicon entries 1516\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7205"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def loadSemEval(filename):\n",
    "    f = open(filename,'r')\n",
    "    lexicon = {}\n",
    "    line = f.readline()\n",
    "    while line:\n",
    "        l = line[:-1].split('\\t')\n",
    "        lexicon[l[1]] = float(l[0])\n",
    "        line = f.readline()\n",
    "    return lexicon\n",
    "\n",
    "\n",
    "def SemEvalLexiconPolarity(tweet, EnglishLexicon):\n",
    "    score=0.0\n",
    "    reps = 0\n",
    "    for w in tweet.split(' '):\n",
    "        if w in EnglishLexicon.keys():\n",
    "            reps += 1\n",
    "            score += EnglishLexicon[w]\n",
    "    return score, reps\n",
    "\n",
    "EnglishLexicon = loadSemEval('./resources/SemEval2015-English-Twitter-Lexicon.txt')\n",
    "SemEvalScore, SemEvalReps = [], []\n",
    "for tweet in raw_tweets:\n",
    "    score, reps = SemEvalLexiconPolarity(tweet.lower(), EnglishLexicon)\n",
    "    SemEvalScore.append(score)\n",
    "    SemEvalReps.append(reps)\n",
    "\n",
    "print (\"Number of EnglishLexicon entries %d\" % len(EnglishLexicon.keys()))\n",
    "len(SemEvalScore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete slangs from tweets\n",
    "By slangs, we mean words like:\n",
    "- i've --> I have\n",
    "- 12be --> want to be\n",
    "- *4u  --> kiss for you\n",
    "- ...\n",
    "\n",
    "And these parallel-terms are read from <font color='red'>'./resources/internetSlangs.txt'</font> file. Here is the first five lines in that file:\n",
    "- *4u,%,kiss for you\n",
    "- *67,%,unknown\n",
    "- *eg*,%,evil grin\n",
    "- 7734,%,hello\n",
    "- 0day,%,software illegally obtained before it was released"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadSlangs(filename):\n",
    "    \"\"\"\n",
    "    This function reads the file that contains the slangs, and put them in a dictionary such that\n",
    "    the key is the \"slang\" and the value is the acronym.\n",
    "    slangs['i've'] = 'i have'\n",
    "    slang['12be'] = 'want to be'\n",
    "    ...\n",
    "    CAUTION: the keys and values are lower-case letters\n",
    "    \"\"\"\n",
    "    slangs={}\n",
    "    fi=open(filename,'r')\n",
    "    line=fi.readline()\n",
    "    while line:\n",
    "        l=line.split(r',%,')\n",
    "        if len(l) == 2:\n",
    "            slangs[l[0].lower()]=l[1][:-1].lower()  #HERE\n",
    "        line=fi.readline()\n",
    "    fi.close()\n",
    "    return slangs\n",
    "\n",
    "\n",
    "def replaceSlangs(tweet,slangs):\n",
    "    \"\"\"\n",
    "    This function is used to replace the slang in the original tweets and replace them with the acronym.\n",
    "    And it's also returns the the tweet in lower-case letters\n",
    "    \"\"\"\n",
    "    result=''\n",
    "    tweet = tweet.lower()\n",
    "    words=tweet.split()\n",
    "    for w in words:\n",
    "        if w in slangs.keys():\n",
    "            result=result+slangs[w]+\" \"\n",
    "        else:\n",
    "            result=result+w+\" \"\n",
    "    return result.strip()\n",
    "\n",
    "slangs = loadSlangs('./resources/internetSlangs.txt')\n",
    "raw_tweets = [replaceSlangs(tweet, slangs) for tweet in raw_tweets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replacing apostrophe words\n",
    "\n",
    "By that, we mean to change words like 'can't', 'cant' into 'can not'. These words are in a txt file called 'apostrophe_words.txt' existed in 'resources' directory. \n",
    "We need to do that to handle the negation problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_apostrophe_words(filename):\n",
    "    \"\"\"\n",
    "    This function reads the file that contains all words that have apostrophe, and put them in a dictionary \n",
    "    such that the key is the \"word containing apostrophe\" and the value is the \"the word without apostrophe\".\n",
    "    slangs['i've'] = 'i have'\n",
    "    slang['I'm] = 'I am'\n",
    "    ...\n",
    "    CAUTION: the keys and values are lower-case letters\n",
    "    \"\"\"\n",
    "    apo={}\n",
    "    fi=open(filename,'r')\n",
    "    line=fi.readline()\n",
    "    while line:\n",
    "        l=line.split(r',%,')\n",
    "        if len(l) == 2:\n",
    "            apo[l[0].lower()]=l[1][:-1].lower()\n",
    "        line=fi.readline()\n",
    "    fi.close()\n",
    "    return apo\n",
    "\n",
    "\n",
    "def replace_apostrophe(tweet,apos):\n",
    "    result=''\n",
    "    words=tweet.split()\n",
    "    for w in words:\n",
    "        if w in apos.keys():\n",
    "            result=result+apos[w]+\" \"\n",
    "        else:\n",
    "            result=result+w+\" \"\n",
    "    return result.strip()\n",
    "\n",
    "apos = load_apostrophe_words('./resources/apostrophe_words.txt')\n",
    "raw_tweets = [replace_apostrophe(tweet, apos) for tweet in raw_tweets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply standard preprocessing techniques\n",
    "\n",
    "* https://nlp.stanford.edu/IR-book/html/htmledition/tokenization-1.html\n",
    "* https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use NRC emoticon lexicon\n",
    "\n",
    "We will replace the emoticon with its associated meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "TT = TweetTokenizer()\n",
    "\n",
    "def emoticondictionary(filename):\n",
    "    \"\"\"\n",
    "    Reads the emoticon file and represents it as dictionary where the emoticon is the key, \n",
    "    and its indication as a value\n",
    "    \"\"\"\n",
    "    emo_scores = {'Positive': 'positive', 'Extremely-Positive': 'positive', \n",
    "                  'Negative': 'negative','Extremely-Negative': 'negative',\n",
    "                  'Neutral': 'neutral'}\n",
    "    emo_score_list = {}\n",
    "    fi = open(filename,\"r\")\n",
    "    l = fi.readline()\n",
    "    while l:\n",
    "        #replace the \"Non-break space\" with the ordinary space \" \"\n",
    "        l = l.replace(\"\\xa0\",\" \") #HERE\n",
    "        li = l.split(\" \")\n",
    "        l2 = li[:-1] #removes the polarity of the emoticon ('negative', 'positive')\n",
    "        l2.append(li[len(li) - 1].split(\"\\t\")[0]) #gets the last emoticon attached to the polarity by '\\t'\n",
    "        sentiment=li[len(li) - 1].split(\"\\t\")[1][:-1] #gets only the polarity, and removes '\\n'\n",
    "        score=emo_scores[sentiment]\n",
    "        l2.append(score)\n",
    "        for i in range(0,len(l2)-1):\n",
    "            emo_score_list[l2[i]]=l2[len(l2)-1]\n",
    "        l=fi.readline()\n",
    "    return emo_score_list\n",
    "\n",
    "dict = emoticondictionary('./resources/emoticon.txt')\n",
    "\n",
    "\n",
    "# substititue emoticon with its associated sentiment\n",
    "def subsEmoticon(tweet,d):\n",
    "    l = TT.tokenize(tweet)\n",
    "    tweet = [d[i] if i in d.keys() else i for i in l]\n",
    "    return tweet\n",
    "\n",
    "\n",
    "raw_tweets = [subsEmoticon(tweet, dict) for tweet in raw_tweets]\n",
    "# print(\":D X3 :|\")\n",
    "# subsEmoticon(\":D X3 :|\", dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handle Negation\n",
    "\n",
    "Following the work of Pang et al.(2002), we define a negated context as a segment of a tweet that starts with a negation word (e.g., no, never) and ends with one of the punctuation marks: ‘,’, ‘.’, ‘:’, ‘;’, ‘!’, ‘?’.\n",
    "\n",
    "After handling the negtation, a tweet like the that 'I don't like vegan food' would be 'I do not like_not vegan_not food_not.'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "negation_words = set(['barely', 'hardly', 'lack', 'never', 'neither', 'no', 'nobody', \\\n",
    "                      'not', 'nothing', 'none', 'nowhere', 'shortage', 'scarcely'])\n",
    "punctuations = [',', '.', ':', ';', '!', '?']\n",
    "\n",
    "def handle_negation(tweet):\n",
    "    output = []\n",
    "    negate = False\n",
    "    for word in tweet:\n",
    "        if word in punctuations and negate:\n",
    "            negate = False\n",
    "        if negate and not word in negation_words:\n",
    "            output.append(word+\"_not\")\n",
    "        else:\n",
    "            output.append(word)\n",
    "        if word in negation_words and not negate:\n",
    "            negate = True\n",
    "        elif word in negation_words and negate:\n",
    "            negate = False\n",
    "    return output\n",
    "\n",
    "raw_tweets = [handle_negation(tweet) for tweet in raw_tweets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, we will lemmatize our words\n",
    "lemmatizing is like converting the word 'networks' into 'network'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mmer = WordNetLemmatizer()\n",
    "# Lemmatize the tweets\n",
    "def lemma(tweet):\n",
    "    return ' '.join([mmer.lemmatize(word) for word in tweet])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing tweets handles different issues:\n",
    "- removes punctuation characters like , . : ; etc.\n",
    "- removes numbers from the tweet.\n",
    "- removes any additional spaces in the tweet.\n",
    "- removes the occurrence of two or more characters in a word, eg. loooong -> loong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def preprocess(tweet):\n",
    "    # delete symbols and URIs and tags (keep # and _)\n",
    "    tweet =  ' '.join(re.sub(\"(@[A-Za-z0-9_]+)|([^0-9A-Za-z_# \\t])|(\\w+:\\/\\/\\S+)\", '', tweet).split()) #here _#\n",
    "    # Convert '@username' to 'at_user'\n",
    "    # tweet = re.sub('@[^\\s]+','at_user',tweet)\n",
    "    # remove hashtags\n",
    "    # tweet = re.sub(r'#\\s', '', tweet)\n",
    "    # remove numbers\n",
    "    tweet = re.sub('[0-9]', '', tweet)\n",
    "    # remove additional spaces\n",
    "    tweet = re.sub('[\\s]+', ' ', tweet)\n",
    "    # replace the occurrence of 2 or more characters in a word, eg. loooong -> loong\n",
    "    tweet = re.sub(r'(.)\\1{2,}', r'\\1\\1', tweet)\n",
    "    return tweet\n",
    "\n",
    "lemmatized_tweets = [lemma(tweet) for tweet in raw_tweets]\n",
    "preprocessed_tweets = [preprocess(tweet) for tweet in lemmatized_tweets]\n",
    "del lemmatized_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete stopwords\n",
    "Here, we are going to used TRBS method, which works by iterating over separate chunks of data randomly selected. It then ranks terms in each chunk based on their informativeness values using the Kullback-Leibler divergence measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our training set vocabulary has 16151 word.\n",
      "564\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter, defaultdict\n",
    "import math\n",
    "\n",
    "#create our training corpus Vocabulary\n",
    "tmp_unigram = Counter()\n",
    "for tweet in preprocessed_tweets:\n",
    "    for word in tweet.split():\n",
    "        tmp_unigram[word] += 1.\n",
    "\n",
    "#normalize the vocabulary\n",
    "total = sum(tmp_unigram.values())\n",
    "normalized_unigram = {}\n",
    "for word in tmp_unigram.keys():\n",
    "    normalized_unigram[word] = tmp_unigram[word]/total\n",
    "\n",
    "#calculate the Kullback-Leibler measure\n",
    "#and get the stopwords list\n",
    "stop_words = []\n",
    "divergence_score = Counter()\n",
    "for i in range(len(preprocessed_tweets)//1000+1):\n",
    "    chunk_unigram = Counter()\n",
    "    for tweet in preprocessed_tweets[i*1000:(i+1)*1000]: #iterate over 1000-word chunks\n",
    "        for word in tweet.split():\n",
    "            chunk_unigram[word] += 1.\n",
    "    total = sum(chunk_unigram.values())\n",
    "    for word in chunk_unigram.keys():\n",
    "        p_x = chunk_unigram[word]/total\n",
    "        p = normalized_unigram[word]\n",
    "        divergence_score[word] = p_x * math.log(p_x/p, 2)\n",
    "        chunk_unigram[word] = divergence_score[word]\n",
    "    stop_words.extend([word for word, score in chunk_unigram.most_common()[-200:]]) #add the smallest 700 words\n",
    "\n",
    "stop_words = set(stop_words)\n",
    "print (\"Our training set vocabulary has\", len(tmp_unigram), \"word.\")\n",
    "print (len(stop_words))\n",
    "del tmp_unigram, normalized_unigram, chunk_unigram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We chose the least 700 based on the elbow in the floowing graph. As the elbow appears at 14,000 which means that thare are 2151 words should be excluded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sure',\n",
       " 'keep',\n",
       " 'gone',\n",
       " 'good',\n",
       " 'st',\n",
       " 'black',\n",
       " 'read',\n",
       " 'interview',\n",
       " 'there',\n",
       " 'medium']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(stop_words)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEKCAYAAAAW8vJGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f644ba36fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "word_rank, score = [0], [0]\n",
    "for k, v in divergence_score.most_common():\n",
    "    word_rank.append(word_rank[-1] + 1)\n",
    "    score.append(score[-1] + v)\n",
    "\n",
    "\n",
    "plt.plot(word_rank[1:], score[1:], \"-\")\n",
    "plt.axvline(x=14000, color='red', linestyle='--')\n",
    "plt.xlabel(\"Rank of Words\")\n",
    "plt.ylabel(\"Divergence_score\")\n",
    "del word_rank, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Compare tweets before / after\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3</th>\n",
       "      <th>final_tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gas by my house hit $3.39!!!! I'm going to Cha...</td>\n",
       "      <td>gas chapel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Iranian general says Israel's Iron Dome can't ...</td>\n",
       "      <td>iranian general israels iron dome deal_not the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>with J Davlar 11th. Main rivals are team Polan...</td>\n",
       "      <td>j davlar main rival poland successful tough tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Talking about ACT's &amp;amp;&amp;amp; SAT's, deciding...</td>\n",
       "      <td>talking acts sats deciding applying everything...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>They may have a SuperBowl in Dallas, but Dalla...</td>\n",
       "      <td>superbowl winning_not superbowl_not quarterbac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Im bringing the monster load of candy tomorrow...</td>\n",
       "      <td>bringing monster load candy all_not squiched_not</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Apple software, retail chiefs out in overhaul:...</td>\n",
       "      <td>software retail chief overhaul francisco inc t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>@oluoch @victor_otti @kunjand I just watched i...</td>\n",
       "      <td>sridevis comeback nta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>#Livewire Nadal confirmed for Mexican Open in ...</td>\n",
       "      <td>#livewire nadal confirmed mexican rafael nadal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>@MsSheLahY I didnt want to just pop up... but ...</td>\n",
       "      <td>pop yep chapel shes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    3  \\\n",
       "0   Gas by my house hit $3.39!!!! I'm going to Cha...   \n",
       "3   Iranian general says Israel's Iron Dome can't ...   \n",
       "6   with J Davlar 11th. Main rivals are team Polan...   \n",
       "7   Talking about ACT's &amp;&amp; SAT's, deciding...   \n",
       "9   They may have a SuperBowl in Dallas, but Dalla...   \n",
       "10  Im bringing the monster load of candy tomorrow...   \n",
       "11  Apple software, retail chiefs out in overhaul:...   \n",
       "12  @oluoch @victor_otti @kunjand I just watched i...   \n",
       "14  #Livewire Nadal confirmed for Mexican Open in ...   \n",
       "15  @MsSheLahY I didnt want to just pop up... but ...   \n",
       "\n",
       "                                         final_tweets  \n",
       "0                                          gas chapel  \n",
       "3   iranian general israels iron dome deal_not the...  \n",
       "6   j davlar main rival poland successful tough tr...  \n",
       "7   talking acts sats deciding applying everything...  \n",
       "9   superbowl winning_not superbowl_not quarterbac...  \n",
       "10   bringing monster load candy all_not squiched_not  \n",
       "11  software retail chief overhaul francisco inc t...  \n",
       "12                              sridevis comeback nta  \n",
       "14  #livewire nadal confirmed mexican rafael nadal...  \n",
       "15                                pop yep chapel shes  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove stopwords\n",
    "def rem_stop(tweet):\n",
    "    words = tweet.split()\n",
    "    tweet = ' '.join([word for word in words if word not in stop_words])\n",
    "    return tweet\n",
    "\n",
    "final_tweets = [rem_stop(tweet) for tweet in preprocessed_tweets]\n",
    "del raw_tweets, preprocessed_tweets, divergence_score\n",
    "\n",
    "print(\"\\nCompare tweets before / after\")\n",
    "df['final_tweets'] = final_tweets\n",
    "df[[3, 'final_tweets']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## <font color='red'>Lexicon Classification</font>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using MPQA Lexicon\n",
    "\n",
    "These are the very first and last entries of the file 'mpqa.txt'\n",
    "- abandoned priorpolarity=negative\n",
    "- abandonment priorpolarity=negative\n",
    "- abandon priorpolarity=negative\n",
    "- abase priorpolarity=negative\n",
    "- abasement priorpolarity=negative\n",
    "- ...\n",
    "- zealot priorpolarity=negative\n",
    "- zealous priorpolarity=negative\n",
    "- zealously priorpolarity=negative\n",
    "- zenith priorpolarity=positive\n",
    "- zest priorpolarity=positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of MPQA words: 13772\n",
      "['sridevis', 'positive', 'nta']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['neutral', 'positive', 'negative']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def MPQAdictionary(filename):\n",
    "    \"\"\"\n",
    "    reads mpqa file which contains the polarity of some of the english words. e.g. 'love': 'positive'\n",
    "    \"\"\"\n",
    "    MPQA_scores = {'priorpolarity=positive\\n': 'positive','priorpolarity=negative\\n': 'negative',\n",
    "                  'priorpolarity=neutral\\n': 'neutral', 'priorpolarity=both\\n': 'neutral'}\n",
    "    MPQA_score_list = {}\n",
    "    fi = open(filename,\"r\")\n",
    "    line = fi.readline()\n",
    "    while line: \n",
    "        li = line.split(\" \")\n",
    "        l2 = li[:-1] # the word as a list\n",
    "        sentiment=li[1] #the word's polarity\n",
    "        score=MPQA_scores[sentiment]\n",
    "        l2.append(score)\n",
    "        for i in range(0,len(l2)-1):\n",
    "            MPQA_score_list[l2[i]]=l2[-1]\n",
    "            # negation\n",
    "            if l2[-1] == 'positive':\n",
    "                MPQA_score_list[l2[i]+'_not']='positive' \n",
    "            else:\n",
    "                MPQA_score_list[l2[i]+'_not']='negative' \n",
    "        line=fi.readline()\n",
    "    return MPQA_score_list\n",
    "\n",
    "\n",
    "def subsMPQA(tweet,d):\n",
    "    l = TT.tokenize(tweet)\n",
    "    #print(l)\n",
    "    tweet = [d[i] if i in d.keys() else i for i in l]\n",
    "    return tweet\n",
    "\n",
    "dictionary = MPQAdictionary('./resources/mpqa/mpqa.txt')\n",
    "print (\"Number of MPQA words: %d\" % len(dictionary.keys()))\n",
    "raw_tweets_MPQA = [subsMPQA(tweet,dictionary) for tweet in final_tweets]\n",
    "\n",
    "print (subsMPQA(final_tweets[7], dictionary))\n",
    "# watched sridevis comeback remember sun morning nta positive\n",
    "subsMPQA(\"surprise happy abandoned\", dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Bing Liu Lexicon\n",
    "These are the very first and last entries of the file 'positive-words.txt':\n",
    "- a+\n",
    "- abound\n",
    "- abounds\n",
    "- abundance\n",
    "- abundant\n",
    "- ...\n",
    "- youthful\n",
    "- zeal\n",
    "- zenith\n",
    "- zest\n",
    "- zippy\n",
    "\n",
    "These are the very first and last entries of the file 'negative-words.txt':\n",
    "- 2-faced\n",
    "- 2-faces\n",
    "- abnormal\n",
    "- abolish\n",
    "- abominable\n",
    "- ...\n",
    "- zaps\n",
    "- zealot\n",
    "- zealous\n",
    "- zealously\n",
    "- zombie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive words 6789\n",
      "Number of negative words 6789\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['positive', 'firas', 'positive']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatized_tweets_MPQA = [lemma(tweet) for tweet in raw_tweets_MPQA]\n",
    "ENGLISH_OPINION_LEXICON_LOCATION = os.path.join('resources/opinion-lexicon-English')\n",
    "POS_WORDS_FILE = os.path.join(ENGLISH_OPINION_LEXICON_LOCATION, 'positive-words.txt')\n",
    "NEG_WORDS_FILE = os.path.join(ENGLISH_OPINION_LEXICON_LOCATION, 'negative-words.txt')\n",
    "\n",
    "pos_words = []\n",
    "neg_words = []\n",
    "\n",
    "for pos_word in open(POS_WORDS_FILE, 'r').readlines()[35:]:\n",
    "    pos_words.append(pos_word.rstrip())\n",
    "\n",
    "for neg_word in open(NEG_WORDS_FILE, 'r').readlines()[35:]: #HERE\n",
    "    neg_words.append(neg_word.rstrip())\n",
    "\n",
    "#negation\n",
    "expanded_pos = copy(pos_words)\n",
    "expanded_pos.extend([word+\"_not\" for word in neg_words])\n",
    "expanded_neg = copy(neg_words)\n",
    "expanded_neg.extend([word+\"_not\" for word in pos_words])\n",
    "\n",
    "#delete unnecessary objects\n",
    "del pos_words, neg_words\n",
    "del ENGLISH_OPINION_LEXICON_LOCATION, POS_WORDS_FILE, NEG_WORDS_FILE\n",
    "print (\"Number of positive words %d\" % len(expanded_pos))\n",
    "print (\"Number of negative words %d\" % len(expanded_neg))\n",
    "\n",
    "def subsBINGP(tweet, pos_words):\n",
    "    l = TT.tokenize(tweet)\n",
    "    tweet = ['positive' if i in pos_words else i for i in l]\n",
    "    return tweet\n",
    "\n",
    "def subsBINGN(tweet, neg_words):\n",
    "    l = TT.tokenize(tweet)\n",
    "    tweet = ['negative' if i in neg_words else i for i in l]\n",
    "    return tweet\n",
    "\n",
    "raw_tweets_bing = [subsBINGP(tweet, expanded_pos) for tweet in lemmatized_tweets_MPQA]\n",
    "raw_tweets_bing = [subsBINGN(tweet, expanded_neg) for tweet in lemmatized_tweets_MPQA]\n",
    "del raw_tweets_MPQA, lemmatized_tweets_MPQA\n",
    "\n",
    "subsBINGP(\"enjoy firas extraordinarily\", expanded_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Afinn](https://pypi.python.org/pypi/afinn)\n",
    "\n",
    "These are the very first and last entries of 'afinn.txt':\n",
    "- abandon\t-2\n",
    "- abandoned\t-2\n",
    "- abandons\t-2\n",
    "- abducted\t-2\n",
    "- abduction\t-2\n",
    "- ...\n",
    "- yucky\t-2\n",
    "- yummy\t3\n",
    "- zealot\t-2\n",
    "- zealots\t-2\n",
    "- zealous\t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Afinn entries 4922\n"
     ]
    }
   ],
   "source": [
    "def loadAfinn(filename):\n",
    "    f=open(filename,'r')\n",
    "    afinn={}\n",
    "    line=f.readline()\n",
    "    while line:\n",
    "        if \" \" in line:   #exclude entries like 'cool stuff    3'\n",
    "            pass\n",
    "        else:\n",
    "            l=line[:-1].split('\\t') #line[:-1] removes the '\\r\\n' character\n",
    "            afinn[l[0]]=float(l[1])    # normalization -------> \n",
    "            afinn[l[0]+\"_not\"] = -float(l[1])  # negation\n",
    "        line=f.readline()\n",
    "\n",
    "    return afinn\n",
    "\n",
    "afinn = loadAfinn('./resources/afinn.txt')\n",
    "# print (afinn)\n",
    "print (\"Number of Afinn entries %d\" % len(afinn.keys()))\n",
    "\n",
    "def afinnPolarity(tweet, afinn):\n",
    "    score=0.0\n",
    "    reps = 0\n",
    "    for w in tweet:\n",
    "        if w in afinn.keys():\n",
    "            reps += 1\n",
    "            score+=afinn[w]\n",
    "    return score, reps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SentiWordNet\n",
    "\n",
    "Here is the very first five lines of the csv file 'sentiWordnetBig.csv':\n",
    "\n",
    "|POS|ID|PosSCore|NegScore|SynsetTerms|\n",
    "|-|-------|-----|-----|-------------------|\n",
    "|a|1740|0.125|0|able#1|\n",
    "|a|2098|0|0.75|unable#1|\n",
    "|a|2312|0|0|dorsal#2 abaxial#1|\n",
    "|a|2527|0|0|ventral#2 adaxial#1|\n",
    "|a|2730|0|0|acroscopic#1|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening the SentiWordnet file ...\n",
      "Loading...\n",
      "Number of sentiWordnet entries 294612\n"
     ]
    }
   ],
   "source": [
    "def loadSentiWordnet(filename): \n",
    "    output={}\n",
    "    print (\"Opening the SentiWordnet file ...\")\n",
    "    fi=open(filename,\"r\")\n",
    "    line=fi.readline() # ignore the header\n",
    "    line=fi.readline()\n",
    "    print (\"Loading...\")\n",
    "\n",
    "    while line:\n",
    "        l=line.split('\\t')\n",
    "        try:\n",
    "            sentence=l[4]\n",
    "            new = [word for word in sentence.split() if (word[-2] == \"#\" and word[-1].isdigit())]\n",
    "            pos=abs(float(l[2]))\n",
    "            neg=abs(float(l[3]))\n",
    "            neu=float(pos-neg)\n",
    "        except:\n",
    "            line=fi.readline()\n",
    "            continue\n",
    "\n",
    "        for w in new:\n",
    "            output[(w[:-2])]=neu\n",
    "            output[(w[:-2])+'_not'] = -neu   #negation\n",
    "        line=fi.readline()\n",
    "        \n",
    "    fi.close()\n",
    "    return output\n",
    "\n",
    "\n",
    "sentiWordnet = loadSentiWordnet('./resources/sentiWordnetBig.csv')\n",
    "print (\"Number of sentiWordnet entries %d\" % len(sentiWordnet.keys()))\n",
    "\n",
    "\n",
    "\n",
    "def WordnetPolarity(tweet, sentiWordnet):\n",
    "    score=0.0\n",
    "    reps = 0\n",
    "    for w in tweet:\n",
    "        if w in sentiWordnet.keys():\n",
    "            reps += 1\n",
    "            score+=sentiWordnet[w]\n",
    "    return score, reps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polarity calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7205, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bing_mpqa_score</th>\n",
       "      <th>afinn_score</th>\n",
       "      <th>wordnet_score</th>\n",
       "      <th>sem_eval_score</th>\n",
       "      <th>final_score</th>\n",
       "      <th>final_tweets</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008469</td>\n",
       "      <td>0.002176</td>\n",
       "      <td>gas chapel</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.011709</td>\n",
       "      <td>0.010834</td>\n",
       "      <td>0.004762</td>\n",
       "      <td>-0.003356</td>\n",
       "      <td>0.012265</td>\n",
       "      <td>iranian general israels iron dome deal_not the...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.002014</td>\n",
       "      <td>0.017315</td>\n",
       "      <td>j davlar main rival poland successful tough tr...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.011709</td>\n",
       "      <td>-0.010834</td>\n",
       "      <td>-0.007143</td>\n",
       "      <td>0.004899</td>\n",
       "      <td>-0.067682</td>\n",
       "      <td>talking acts sats deciding applying everything...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.011709</td>\n",
       "      <td>-0.010834</td>\n",
       "      <td>-0.011904</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.044375</td>\n",
       "      <td>superbowl winning_not superbowl_not quarterbac...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.011709</td>\n",
       "      <td>-0.010834</td>\n",
       "      <td>-0.021428</td>\n",
       "      <td>0.016953</td>\n",
       "      <td>-0.040761</td>\n",
       "      <td>bringing monster load candy all_not squiched_not</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.007143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.007148</td>\n",
       "      <td>software retail chief overhaul francisco inc t...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.011709</td>\n",
       "      <td>0.010834</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006484</td>\n",
       "      <td>0.039974</td>\n",
       "      <td>sridevis comeback nta</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002381</td>\n",
       "      <td>0.009598</td>\n",
       "      <td>-0.003544</td>\n",
       "      <td>#livewire nadal confirmed mexican rafael nadal...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.011709</td>\n",
       "      <td>0.010834</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018295</td>\n",
       "      <td>0.079176</td>\n",
       "      <td>pop yep chapel shes</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    bing_mpqa_score  afinn_score  wordnet_score  sem_eval_score  final_score  \\\n",
       "0          0.000000     0.000000       0.000000        0.008469     0.002176   \n",
       "3          0.011709     0.010834       0.004762       -0.003356     0.012265   \n",
       "6          0.000000     0.000000       0.000000       -0.002014     0.017315   \n",
       "7         -0.011709    -0.010834      -0.007143        0.004899    -0.067682   \n",
       "9         -0.011709    -0.010834      -0.011904        0.000000    -0.044375   \n",
       "10        -0.011709    -0.010834      -0.021428        0.016953    -0.040761   \n",
       "11         0.000000     0.000000      -0.007143        0.000000    -0.007148   \n",
       "12         0.011709     0.010834       0.000000        0.006484     0.039974   \n",
       "14         0.000000     0.000000       0.002381        0.009598    -0.003544   \n",
       "15         0.011709     0.010834       0.000000        0.018295     0.079176   \n",
       "\n",
       "                                         final_tweets         2  \n",
       "0                                          gas chapel  positive  \n",
       "3   iranian general israels iron dome deal_not the...  negative  \n",
       "6   j davlar main rival poland successful tough tr...  positive  \n",
       "7   talking acts sats deciding applying everything...  negative  \n",
       "9   superbowl winning_not superbowl_not quarterbac...  negative  \n",
       "10   bringing monster load candy all_not squiched_not   neutral  \n",
       "11  software retail chief overhaul francisco inc t...   neutral  \n",
       "12                              sridevis comeback nta  positive  \n",
       "14  #livewire nadal confirmed mexican rafael nadal...   neutral  \n",
       "15                                pop yep chapel shes  positive  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BingMpqaScore = []\n",
    "AfinnScore, AfinnReps = [], []\n",
    "WordnetScore, WordnetReps = [], []\n",
    "length = len(raw_tweets_bing)\n",
    "\n",
    "for tw in raw_tweets_bing:\n",
    "    Bing_MPQA = 0\n",
    "    for i in tw:\n",
    "        if (i == 'positive'):\n",
    "            Bing_MPQA +=  1\n",
    "        if (i == 'negative'):\n",
    "            Bing_MPQA -= 1\n",
    "    BingMpqaScore.append(Bing_MPQA)\n",
    "    tmp = afinnPolarity(tw, afinn)\n",
    "    AfinnScore.append(tmp[0])\n",
    "    AfinnReps.append(tmp[1])\n",
    "    tmp = WordnetPolarity(tw, sentiWordnet)\n",
    "    WordnetScore.append(tmp[0])\n",
    "    WordnetReps.append(tmp[1])\n",
    "\n",
    "    \n",
    "#reshape\n",
    "BingMpqaScore = np.array(BingMpqaScore).reshape(length, 1)\n",
    "AfinnScore = np.array(AfinnScore).reshape(length, 1)\n",
    "AfinnReps = np.array(AfinnReps).reshape(length, 1)\n",
    "WordnetScore = np.array(WordnetScore).reshape(length, 1)\n",
    "WordnetReps = np.array(WordnetReps).reshape(length, 1)\n",
    "SemEvalScore = np.array(SemEvalScore).reshape(length, 1)\n",
    "SemEvalReps = np.array(SemEvalReps).reshape(length, 1)\n",
    "unigram140Score = np.array(unigram140Score).reshape(length, 1)\n",
    "unigram140Reps = np.array(unigram140Reps).reshape(length, 1)\n",
    "bigram140Score = np.array(bigram140Score).reshape(length, 1)\n",
    "bigram140Reps = np.array(bigram140Reps).reshape(length, 1)\n",
    "\n",
    "#Normalization\n",
    "BingMpqaScore = BingMpqaScore/np.linalg.norm(BingMpqaScore)\n",
    "AfinnScore = AfinnScore/np.linalg.norm(AfinnScore)\n",
    "AfinnReps = AfinnReps/np.linalg.norm(AfinnReps)\n",
    "WordnetScore = WordnetScore/np.linalg.norm(WordnetScore)\n",
    "WordnetReps = WordnetReps/np.linalg.norm(WordnetReps)\n",
    "SemEvalScore = SemEvalScore/np.linalg.norm(SemEvalScore)\n",
    "SemEvalReps = SemEvalReps/np.linalg.norm(SemEvalReps)\n",
    "unigram140Score = unigram140Score/np.linalg.norm(unigram140Score)\n",
    "unigram140Reps = unigram140Reps/np.linalg.norm(unigram140Reps)\n",
    "bigram140Score = bigram140Score/np.linalg.norm(bigram140Score)\n",
    "bigram140Reps = bigram140Reps/np.linalg.norm(bigram140Reps)\n",
    "\n",
    "\n",
    "\n",
    "#final_score_tweets (my score list)\n",
    "df['bing_mpqa_score'] = BingMpqaScore\n",
    "df['afinn_score'] = AfinnScore\n",
    "df['wordnet_score'] = WordnetScore\n",
    "df['sem_eval_score'] = SemEvalScore\n",
    "all_scores = np.hstack( (BingMpqaScore, AfinnScore, WordnetScore, SemEvalScore, unigram140Score, bigram140Score) )\n",
    "sum_score = np.sum(all_scores, axis=1).reshape(length, 1)\n",
    "print (all_scores.shape)\n",
    "df['final_score'] = sum_score\n",
    "\n",
    "df[['bing_mpqa_score','afinn_score', 'wordnet_score', 'sem_eval_score','final_score', 'final_tweets' ,2]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Comparing the scores with the real results, we can conclude that the use of lexicon does not give very good results ... We must add scores for bi-grams.\n",
    "##### You must then combine the lexicon / machine learning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df, raw_tweets_bing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# <font color='red'>Train the model</font>\n",
    "***\n",
    "#### Create a feature vector\n",
    "* See [Bag of Words](https://en.wikipedia.org/wiki/Bag-of-words_model) for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7205, 80050)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vectorizer = CountVectorizer(analyzer='word', preprocessor=None, stop_words=None, tokenizer=None, ngram_range=(1,3))\n",
    "features = count_vectorizer.fit_transform(final_tweets)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7205, 5)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reducing the CountVector\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_components=5, n_iter=7, random_state=42)\n",
    "count_features = svd.fit_transform(features)\n",
    "count_features = scipy.sparse.csr_matrix(count_features)\n",
    "print (type(count_features))\n",
    "count_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7205, 80050)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(analyzer='word', preprocessor=None, stop_words=None, tokenizer=None, ngram_range=(1,3))\n",
    "tfidf_features = tfidf_vectorizer.fit_transform(final_tweets)\n",
    "del final_tweets\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7205, 6) (7205, 1) (7205, 1) (7205, 1) (7205, 1)\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "(7205, 12)\n"
     ]
    }
   ],
   "source": [
    "print (all_scores.shape, sum_score.shape, AfinnReps.shape, WordnetReps.shape, SemEvalReps.shape)\n",
    "final_total = scipy.sparse.csr_matrix(np.hstack( (all_scores, sum_score, AfinnReps, WordnetReps, SemEvalReps, unigram140Reps, bigram140Reps) ))\n",
    "print (type(final_total))\n",
    "print (final_total.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7205, 80067)\n"
     ]
    }
   ],
   "source": [
    "features = scipy.sparse.hstack([count_features, tfidf_features, final_total])\n",
    "print (features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# delete unnecessary data objects\n",
    "del all_scores, sum_score, BingMpqaScore, AfinnScore, WordnetScore, SemEvalScore, unigram140Score, bigram140Score\n",
    "del AfinnReps, WordnetReps, SemEvalReps, unigram140Reps, bigram140Reps\n",
    "del count_features, tfidf_features, final_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Put labels to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7205,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapper = {'positive': 1, 'negative': -1, 'neutral': 0}\n",
    "\n",
    "labels = labels.map(mapper)\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import SVM\n",
    "\n",
    "http://scikit-learn.org/stable/modules/svm.html\n",
    "\n",
    "For a mathematical overview,\n",
    "https://docs.opencv.org/2.4/doc/tutorials/ml/introduction_to_svm/introduction_to_svm.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the optimal regulation parameter using handout method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anwar/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/anwar/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/anwar/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/anwar/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/anwar/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/anwar/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.532982407399\n",
      "20\n",
      "{'C': 1.5540150506633914, 'gamma': 0.93466400959821538}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7f644b330d68>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEKCAYAAAARnO4WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRKRKKOCLiFQJBXwRkSrx/wGDBg4SNoJLCAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f644b322780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Takes around 70 minutes (Because the tfidfVectorizer is doubled its size)\n",
    "rand_list = {\"C\": scipy.stats.uniform(0, 5),\n",
    "             \"gamma\": scipy.stats.uniform(0.1, 1)}\n",
    "\n",
    "rand_search = RandomizedSearchCV(SVC(kernel='linear'), param_distributions = rand_list,\\\n",
    "                                 n_iter = 20, n_jobs = 4, scoring = 'f1_macro')\n",
    "rand_search.fit(features, labels)\n",
    "\n",
    "print(rand_search.best_score_)\n",
    "print (len(rand_search.cv_results_['param_C'].data))\n",
    "print (rand_search.best_params_)\n",
    "\n",
    "rand_search.cv_results_['param_gamma'].data\n",
    "plt.plot(sorted(rand_search.cv_results_['mean_test_score']), rand_search.cv_results_['param_C'].data, \"-\")\n",
    "plt.xlabel(\"Mean Test Score\")\n",
    "plt.ylabel(\"C value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.5540150506633914, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma=0.93466400959821538,\n",
       "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KERNEL = 'linear'\n",
    "classifier = SVC(kernel=KERNEL, C=rand_search.best_params_['C'], gamma=rand_search.best_params_['gamma'])\n",
    "classifier.fit(features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell is just a check point for me:\n",
    "\n",
    "- With removing Stopwords --> C=1.6887473909571904, gamma=0.74544949995820042\n",
    "- Without removing Stopwords --> C=4.7673773527480776, gamma=0.56674222725911638\n",
    "- TF-High --> C=1.874363978223947, gamma=0.81224157130129537\n",
    "- TF1 --> C=4.8425189480402828, gamma=0.91806748508609359\n",
    "- TRBS --> 'C': 1.5540150506633914, 'gamma': 0.93466400959821538"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9888\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "nb_predict_train = classifier.predict(features)\n",
    "#check accuracy\n",
    "print(\"Accuracy: {:0.4f}\".format(metrics.accuracy_score(labels, nb_predict_train)))\n",
    "del features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2657    2   33]\n",
      " [   5 1001   18]\n",
      " [  21    2 3466]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.99      0.99      0.99      2692\n",
      "         -1       1.00      0.98      0.99      1024\n",
      "          0       0.99      0.99      0.99      3489\n",
      "\n",
      "avg / total       0.99      0.99      0.99      7205\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print confusion matrix\n",
    "print(\"{}\".format(metrics.confusion_matrix(labels, nb_predict_train, \n",
    "                                           labels=[1,-1, 0])))\n",
    "\n",
    "print(\"{}\".format(metrics.classification_report(labels, nb_predict_train, \n",
    "                                                labels=[1, -1, 0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>Tesing Our Model</font>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8902, 4)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_df = pd.read_csv('./data/test/actual/test_B_labeled.tsv', sep='\\t', header=None)\n",
    "t_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7584, 4)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_df = t_df[t_df[3] != 'Not Available']\n",
    "t_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnMAAAHoCAYAAAAi+WkTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3X+4ZmVd7/H3R0CkFMEYiZ+CBSZQYUyEWieLVPTYQcts\nqARPJhpoZVZCnk5oBzNTSY/5A5OAjobTDwNJSByxskQcFIEBwUkgmAaYBEJKJ8Hv+WPdk4/bvfc8\ne3z2s/c9835d13M967nv9eP7zLX27M9ea91rpaqQJElSnx6y1AVIkiRp2xnmJEmSOmaYkyRJ6phh\nTpIkqWOGOUmSpI4Z5iRJkjpmmJMkSeqYYU6SJKljhjlJkqSO7bzUBUzTXnvtVQcddNBSlyFJkrRV\nV1111b9W1YqtzbdDhbmDDjqItWvXLnUZkiRJW5Xk1nHm8zSrJElSxwxzkiRJHTPMSZIkdcwwJ0mS\n1DHDnCRJUscMc5IkSR0zzEmSJHXMMCdJktQxw5wkSVLHphrmkjwsyZVJPpNkXZJXt/YzkmxIcnV7\nPXNkmdOTrE9yY5Knj7QfleTa1veWJJnmd5EkSVoOpv04r83Aj1bV/Ul2AT6W5JLWd1ZVvWF05iSH\nAauAw4F9gQ8nObSqHgTeDrwI+ATwQeA44BIkSZJ2IFM9MleD+9vHXdqr5lnkeOCCqtpcVTcD64Gj\nk+wD7F5VV1RVAecDz17M2iVJkpajqV8zl2SnJFcDdwGXVdUnWtfLklyT5Jwke7a2/YDbRha/vbXt\n16Znts+2vZOTrE2ydtOmTRP9LpIkSUtt6mGuqh6sqiOB/RmOsh3BcMr0scCRwEbgjRPc3tlVtbKq\nVq5YsWJSq5UkSVoWlmw0a1XdC1wOHFdVd7aQ91XgXcDRbbYNwAEji+3f2ja06ZntkiRJO5Rpj2Zd\nkWSPNr0b8FTgs+0auC2eA1zXpi8CViXZNcnBwCHAlVW1EbgvyTFtFOuJwIVT+yKSJEnLxLRHs+4D\nnJdkJ4YgubqqLk7yJ0mOZBgMcQvwYoCqWpdkNXA98ABwahvJCnAKcC6wG8MoVkeySpKkHU6GwaA7\nhpUrV9batWuXugxJkqStSnJVVa3c2nw+AUKSJKlj0z7NKknSkjrrspuWugR17uVPPXSpS/g6HpmT\nJEnqmGFOkiSpY4Y5SZKkjhnmJEmSOmaYkyRJ6phhTpIkqWOGOUmSpI4Z5iRJkjpmmJMkSeqYYU6S\nJKljhjlJkqSOGeYkSZI6ZpiTJEnqmGFOkiSpY4Y5SZKkjhnmJEmSOmaYkyRJ6phhTpIkqWOGOUmS\npI4Z5iRJkjpmmJMkSeqYYU6SJKljhjlJkqSOGeYkSZI6ZpiTJEnqmGFOkiSpY4Y5SZKkjhnmJEmS\nOmaYkyRJ6phhTpIkqWOGOUmSpI4Z5iRJkjpmmJMkSeqYYU6SJKljhjlJkqSOGeYkSZI6ZpiTJEnq\nmGFOkiSpY4Y5SZKkjhnmJEmSOmaYkyRJ6phhTpIkqWOGOUmSpI4Z5iRJkjpmmJMkSeqYYU6SJKlj\nhjlJkqSOGeYkSZI6ZpiTJEnq2FTDXJKHJbkyyWeSrEvy6tb+qCSXJflce99zZJnTk6xPcmOSp4+0\nH5Xk2tb3liSZ5neRJElaDqZ9ZG4z8KNV9b3AkcBxSY4BTgPWVNUhwJr2mSSHAauAw4HjgLcl2amt\n6+3Ai4BD2uu4aX4RSZKk5WCqYa4G97ePu7RXAccD57X284Bnt+njgQuqanNV3QysB45Osg+we1Vd\nUVUFnD+yjCRJ0g5j6tfMJdkpydXAXcBlVfUJYO+q2thmuQPYu03vB9w2svjtrW2/Nj2zfbbtnZxk\nbZK1mzZtmuA3kSRJWnpTD3NV9WBVHQnsz3CU7YgZ/cVwtG5S2zu7qlZW1coVK1ZMarWSJEnLwpKN\nZq2qe4HLGa51u7OdOqW939Vm2wAcMLLY/q1tQ5ue2S5JkrRDmfZo1hVJ9mjTuwFPBT4LXASc1GY7\nCbiwTV8ErEqya5KDGQY6XNlOyd6X5Jg2ivXEkWUkSZJ2GDtPeXv7AOe1EakPAVZX1cVJPg6sTvJC\n4FbgeQBVtS7JauB64AHg1Kp6sK3rFOBcYDfgkvaSJEnaoUw1zFXVNcATZmn/AnDsHMucCZw5S/ta\n4IhvXEKSJGnH4RMgJEmSOmaYkyRJ6phhTpIkqWOGOUmSpI4Z5iRJkjpmmJMkSeqYYU6SJKljhjlJ\nkqSOGeYkSZI6ZpiTJEnqmGFOkiSpY4Y5SZKkjhnmJEmSOmaYkyRJ6tjOS13A9uasy25a6hLUuZc/\n9dClLkGS1BGPzEmSJHXMMCdJktQxw5wkSVLHDHOSJEkdM8xJkiR1zDAnSZLUMcOcJElSxwxzkiRJ\nHTPMSZIkdcwwJ0mS1DHDnCRJUscMc5IkSR0zzEmSJHXMMCdJktQxw5wkSVLHDHOSJEkdM8xJkiR1\nzDAnSZLUMcOcJElSxwxzkiRJHTPMSZIkdcwwJ0mS1DHDnCRJUscMc5IkSR0zzEmSJHXMMCdJktQx\nw5wkSVLHDHOSJEkdM8xJkiR1zDAnSZLUMcOcJElSxwxzkiRJHTPMSZIkdcwwJ0mS1DHDnCRJUscM\nc5IkSR2baphLckCSy5Ncn2Rdkl9u7Wck2ZDk6vZ65sgypydZn+TGJE8faT8qybWt7y1JMs3vIkmS\ntBzsPOXtPQC8oqo+leQRwFVJLmt9Z1XVG0ZnTnIYsAo4HNgX+HCSQ6vqQeDtwIuATwAfBI4DLpnS\n95AkSVoWpnpkrqo2VtWn2vQXgRuA/eZZ5HjggqraXFU3A+uBo5PsA+xeVVdUVQHnA89e5PIlSZKW\nnSW7Zi7JQcATGI6sAbwsyTVJzkmyZ2vbD7htZLHbW9t+bXpmuyRJ0g5lScJckocDfwH8SlXdx3DK\n9LHAkcBG4I0T3NbJSdYmWbtp06ZJrVaSJGlZmHqYS7ILQ5B7T1X9JUBV3VlVD1bVV4F3AUe32TcA\nB4wsvn9r29CmZ7Z/g6o6u6pWVtXKFStWTPbLSJIkLbFpj2YN8G7ghqp600j7PiOzPQe4rk1fBKxK\nsmuSg4FDgCuraiNwX5Jj2jpPBC6cypeQJElaRqY9mvXJwPOBa5Nc3dp+EzghyZFAAbcALwaoqnVJ\nVgPXM4yEPbWNZAU4BTgX2I1hFKsjWSVJ0g5nqmGuqj4GzHY/uA/Os8yZwJmztK8FjphcdZIkSf3x\nCRCSJEkdM8xJkiR1zDAnSZLUMcOcJElSxwxzkiRJHTPMSZIkdcwwJ0mS1DHDnCRJUscMc5IkSR0z\nzEmSJHXMMCdJktQxw5wkSVLHDHOSJEkdM8xJkiR1zDAnSZLUMcOcJElSxwxzkiRJHTPMSZIkdcww\nJ0mS1DHDnCRJUscMc5IkSR0zzEmSJHXMMCdJktQxw5wkSVLHDHOSJEkdM8xJkiR1zDAnSZLUsbHC\nXJIfSnL8yOe9krw3ydVJ3phkl8UrUZIkSXMZ98jc64EjRj6/GTgWuAJ4AfDqyZYlSZKkcYwb5h4H\nXAWQ5FuA5wC/XFUvAX4D+OnFKU+SJEnzGTfMPRT4cpt+MrAz8Nft803APhOuS5IkSWMYN8x9Fjiu\nTf8s8PGq+mL7vC9w96QLkyRJ0tbtPOZ8rwH+LMkLgUcCx4/0HQd8etKFSZIkaevGCnNVdVGSxwNP\nAK6tqptGuj8OXLMYxUmSJGl+4x6Zo6o+D3x+lvazJ1qRJEmSxjb2TYOTfE+S9yX5pySbk3xfaz8z\nyTMWr0RJkiTNZdybBj+D4dYk3w6cD4zeJHgz8LLJlyZJkqStGffI3O8C51bVDwNnzui7GjhyolVJ\nkiRpLOOGue8C3tema0bffcCjJlaRJEmSxjZumLsLeOwcfYcD/zyZciRJkrQQ44a5C4DXJPnBkbZK\ncijwSuA9E69MkiRJWzXurUl+CzgM+FvgjtZ2IcOAiA8Br518aZIkSdqacW8avBl4VpJjgWOBvRge\n4bWmqi5bxPokSZI0j7FvGgxQVWuANYtUiyRJkhZo3PvMrUry63P0/VqS5022LEmSJI1j3AEQpwFf\nnqPvP4DTJ1OOJEmSFmLcMHcIcN0cfTe0fkmSJE3ZuGHuP4D95+g7gOGRXpIkSZqyccPch4HfSvLo\n0cYkK4BXMdyeRJIkSVM27mjWVwJXAP+U5FJgI7AP8HTgXuA3Fqc8SZIkzWesI3NV9c/A9wJvZTit\n+oz2/n+B76uq2xatQkmSJM1p3NOsVNWmqjq9qo6pqkPa+6uq6l/HXUeSA5JcnuT6JOuS/HJrf1SS\ny5J8rr3vObLM6UnWJ7kxydNH2o9Kcm3re0uSjFuHJEnS9mLsMDchDwCvqKrDgGOAU5McxnDrkzVV\ndQjDTYlPA2h9q4DDgeOAtyXZqa3r7cCLGEbSHtL6JUmSdijj3jR4l3Zz4H9M8s9J7pr5Gmc9VbWx\nqj7Vpr/IcFuT/YDjgfPabOcBz27TxwMXVNXmqroZWA8cnWQfYPequqKqCjh/ZBlJkqQdxrgDIM4C\nXgxcDFwO/Oc3u+EkBwFPAD4B7F1VG1vXHcDebXo/hoEXW9ze2r7Spme2S5Ik7VDGDXM/BZxWVW+c\nxEaTPBz4C+BXquq+0cvdqqqS1CS207Z1MnAywIEHHjip1UqSJC0L414zF+CaSWwwyS4MQe49VfWX\nrfnOduqU9r7ltO0GhlGzW+zf2jbw9Tcx3tL+Darq7KpaWVUrV6xYMYmvIEmStGyMG+beBZzwzW6s\njTh9N3BDVb1ppOsi4KQ2fRJw4Uj7qiS7JjmYYaDDle2U7H1JjmnrPHFkGUmSpB3GuKdZ7wR+Nsnl\nwGUMNwoeVVX19jHW82Tg+cC1Sa5ubb8JvA5YneSFwK3A89pK1yVZDVzPMBL21Kp6sC13CnAusBtw\nSXtJkiTtUMYNc3/Q3g8EfniW/mK4Vci8qupjDKdsZ3PsHMucCZw5S/ta4IitbVOSJGl7NlaYq6pp\n349OkiRJYzCkSZIkdWzsMJfk0Ul+L8maJDclOby1/3KSJy5eiZIkSZrLuE+AOBr4HPCTwC3AdwC7\ntu59gFcsRnGSJEma37hH5s5iePLDoQxPghgdxHAlcPSE65IkSdIYxh3N+n3A8VX11Yw+rmHwBeDR\nky1LkiRJ4xj3yNy/AXM9PuGxDPehkyRJ0pSNG+YuAl6d5LEjbZVkL+DXgL+cfTFJkiQtpnHD3CuB\n+xiexPB3re0dwI3Al4D/PfnSJEmStDXj3jT4niTHMDyK61jg34G7gT8Czq+qzYtXoiRJkuay1TCX\nZFfguQwPuH838O5Fr0qSJElj2epp1nbU7Y+AfRe/HEmSJC3EuNfMXctwjzlJkiQtI+PeZ+7lwLlJ\nNgKXVtUDi1iTJEmSxjRumPsr4FuACxluSXIPUKMzVJU3DpYkSZqyccPcHzIjvEmSJGnpjXtrkjMW\nuQ5JkiRtg3EHQEiSJGkZGuvIXJJPspXTrFV19EQqkiRJ0tjGvWZuHd8Y5vYEnsTwOK81kyxKkiRJ\n4xn3mrkXzNae5OHARcA/TrAmSZIkjembumauqu4H3gi8ajLlSJIkaSEmMQBiD4ZTrpIkSZqycQdA\nPHOW5ocCj2d4OsTlkyxKkiRJ4xl3AMTFDAMgMqP9KwxPhXjpJIuSJEnSeMYNcwfP0vZl4K6q8skQ\nkiRJS2Tc0ay3LnYhkiRJWrixBkAk+aUkr5uj73eTeJpVkiRpCYw7mvUUYP0cfTe1fkmSJE3ZuGHu\nMcwd5m4GDppINZIkSVqQccPcPcDj5uh7HHDfZMqRJEnSQowb5j4AnJHku0cbkxwB/DbD7UkkSZI0\nZePemuR04EnAp5N8GtgI7AM8AbgOOG1xypMkSdJ8xjoyV1V3A98PnAr8E7Bbe/9F4Aeq6p5Fq1CS\nJElzGvfIHFX1ZeCd7SVJkqRlYNz7zB2b5AVz9L0gyY9MtCpJkiSNZdwBEGcCe8/Rtxfw2smUI0mS\npIUYN8wdDqydo+/TwGGTKUeSJEkLMW6YewB41Bx93zahWiRJkrRA44a5jwG/nuSho43t8yuAv590\nYZIkSdq6cUezvooh0K1P8j6+dp+55wGPBF64OOVJkiRpPmOFuaq6Jsn3A2cAz2c4tfoFYA3w6qq6\nadEqlCRJ0pwWcp+5G4ETFrEWSZIkLdDYYS7JvsB+7ePtVbVxcUqSJEnSuOYdAJHBLyVZD9wGXNFe\ntydZn+SlSTKNQiVJkvSN5jwyl2Rn4C+BZwEfBd4C3Nq6HwMc39qemuQnqurBxS1VkiRJM813mvVl\nwLHAM6vq0ln635LkaQyB76XAmxehPkmSJM1jvtOsLwBeP0eQA6CqPgT8PvDzE65LkiRJY5gvzB3C\ncHp1az7a5pUkSdKUzRfmvsRwQ+CteWSbV5IkSVM2X5j7OPALY6zjF4B/nEw5kiRJWoj5wtzvAs9I\n8p4kj5nZmeTAJH8CPAN47TgbS3JOkruSXDfSdkaSDUmubq9njvSd3m6BcmOSp4+0H5Xk2tb3Fm+P\nIkmSdlRzjmatqn9IchLwTuCnklzD19+a5LuB/wROrKqPj7m9c4G3AufPaD+rqt4w2pDkMGAVcDiw\nL/DhJIe2W6C8HXgR8Angg8BxwCVj1iBJkrTdmPemwVX1XuBxwJnAvcBh7XVva3tcVf3puBurqr8D\n7h5z9uOBC6pqc1XdDKwHjk6yD7B7VV1RVcUQDJ89bg2SJEnbk60+zquq/gV49SLX8bIkJwJrgVdU\n1T0Mjw67YmSe21vbV9r0zHZJkqQdzrxH5qbk7cBjgSOBjcAbJ7nyJCcnWZtk7aZNmya5akmSpCW3\n5GGuqu6sqger6qvAu4CjW9cG4ICRWfdvbRva9Mz2udZ/dlWtrKqVK1asmGzxkiRJS2zJw1y7Bm6L\n5wBbRrpeBKxKsmuSgxluTHxlVW0E7ktyTBvFeiJw4VSLliRJWia2es3cJCX5U+ApwF5Jbgd+G3hK\nkiOBAm4BXgxQVeuSrAauBx4ATm0jWQFOYRgZuxvDKFZHskqSpB3SVMNcVZ0wS/O755n/TIZRszPb\n1wJHTLA0SZKkLo19mjXJiUn2WMxiJEmStDALuWbuj4EDATL430m+fXHKkiRJ0jjmPM2a5BLgauAz\n7RWG69pgCIG/DVwM3LHINUqSJGkO810zdynwBOCZwOMZgtxbk1wOfJKvD3eSJElaAvM9m/XNW6aT\n7Ap8CfgUw+O9ns8Q5P4kyaXAh6vq0kWuVZIkSTPMec1ckl9K8kNJHlFVm1vzH7cRqY9jODL3p8DD\ngbcufqmSJEmaab7TrM8CXsVwT7hbGY7ErUqyG3Btm+eSqvrUItcoSZKkOcx5ZK6qnlZVezM8xP4U\nhiNxP8ZwLd3dDOHuF5Mc207DSpIkacq2emuSqrpj5Hq4X6iqPYGVDOHuAIYnMdyzaBVKkiRpTtv6\nbNYb2vtvVtUBwFETqkeSJEkLMPbjvKpqNPgVcCuwufXdMOtCkiRJWlTb9GzWqvoqcPCEa5EkSdIC\nbetpVkmSJC0DhjlJkqSOGeYkSZI6ZpiTJEnqmGFOkiSpY4Y5SZKkjhnmJEmSOrZN95mTtOM467Kb\nlroEde7lTz10qUuQtmsemZMkSeqYYU6SJKljhjlJkqSOGeYkSZI6ZpiTJEnqmGFOkiSpY4Y5SZKk\njhnmJEmSOmaYkyRJ6phhTpIkqWOGOUmSpI4Z5iRJkjpmmJMkSeqYYU6SJKljhjlJkqSOGeYkSZI6\nZpiTJEnqmGFOkiSpY4Y5SZKkjhnmJEmSOmaYkyRJ6phhTpIkqWOGOUmSpI4Z5iRJkjpmmJMkSeqY\nYU6SJKljhjlJkqSOGeYkSZI6ZpiTJEnqmGFOkiSpY4Y5SZKkjk01zCU5J8ldSa4baXtUksuSfK69\n7znSd3qS9UluTPL0kfajklzb+t6SJNP8HpIkScvFtI/MnQscN6PtNGBNVR0CrGmfSXIYsAo4vC3z\ntiQ7tWXeDrwIOKS9Zq5TkiRphzDVMFdVfwfcPaP5eOC8Nn0e8OyR9guqanNV3QysB45Osg+we1Vd\nUVUFnD+yjCRJ0g5lOVwzt3dVbWzTdwB7t+n9gNtG5ru9te3Xpme2S5Ik7XCWQ5j7L+1IW01ynUlO\nTrI2ydpNmzZNctWSJElLbjmEuTvbqVPa+12tfQNwwMh8+7e2DW16ZvusqursqlpZVStXrFgx0cIl\nSZKW2nIIcxcBJ7Xpk4ALR9pXJdk1ycEMAx2ubKdk70tyTBvFeuLIMpIkSTuUnae5sSR/CjwF2CvJ\n7cBvA68DVid5IXAr8DyAqlqXZDVwPfAAcGpVPdhWdQrDyNjdgEvaS5IkaYcz1TBXVSfM0XXsHPOf\nCZw5S/ta4IgJliZJktSl5XCaVZIkSdvIMCdJktQxw5wkSVLHDHOSJEkdM8xJkiR1zDAnSZLUMcOc\nJElSxwxzkiRJHTPMSZIkdcwwJ0mS1DHDnCRJUscMc5IkSR0zzEmSJHXMMCdJktQxw5wkSVLHDHOS\nJEkdM8xJkiR1zDAnSZLUMcOcJElSxwxzkiRJHTPMSZIkdcwwJ0mS1DHDnCRJUscMc5IkSR0zzEmS\nJHXMMCdJktQxw5wkSVLHDHOSJEkdM8xJkiR1zDAnSZLUMcOcJElSxwxzkiRJHTPMSZIkdcwwJ0mS\n1DHDnCRJUscMc5IkSR0zzEmSJHXMMCdJktQxw5wkSVLHDHOSJEkdM8xJkiR1zDAnSZLUMcOcJElS\nxwxzkiRJHTPMSZIkdcwwJ0mS1DHDnCRJUscMc5IkSR0zzEmSJHXMMCdJktQxw5wkSVLHDHOSJEkd\nWzZhLsktSa5NcnWSta3tUUkuS/K59r7nyPynJ1mf5MYkT1+6yiVJkpbOsglzzY9U1ZFVtbJ9Pg1Y\nU1WHAGvaZ5IcBqwCDgeOA96WZKelKFiSJGkpLbcwN9PxwHlt+jzg2SPtF1TV5qq6GVgPHL0E9UmS\nJC2p5RTmCvhwkquSnNza9q6qjW36DmDvNr0fcNvIsre3tm+Q5OQka5Os3bRp02LULUmStGR2XuoC\nRvxgVW1I8mjgsiSfHe2sqkpSC11pVZ0NnA2wcuXKBS8vSZK0nC2bI3NVtaG93wW8n+G06Z1J9gFo\n73e12TcAB4wsvn9rkyRJ2qEsizCX5FuTPGLLNPA04DrgIuCkNttJwIVt+iJgVZJdkxwMHAJcOd2q\nJUmSlt5yOc26N/D+JDDU9N6qujTJJ4HVSV4I3Ao8D6Cq1iVZDVwPPACcWlUPLk3pkiRJS2dZhLmq\n+jzwvbO0fwE4do5lzgTOXOTSJEmSlrVlcZpVkiRJ28YwJ0mS1DHDnCRJUscMc5IkSR0zzEmSJHXM\nMCdJktQxw5wkSVLHDHOSJEkdM8xJkiR1zDAnSZLUMcOcJElSxwxzkiRJHTPMSZIkdcwwJ0mS1DHD\nnCRJUscMc5IkSR0zzEmSJHXMMCdJktQxw5wkSVLHDHOSJEkdM8xJkiR1zDAnSZLUMcOcJElSxwxz\nkiRJHTPMSZIkdcwwJ0mS1DHDnCRJUscMc5IkSR0zzEmSJHXMMCdJktQxw5wkSVLHDHOSJEkdM8xJ\nkiR1zDAnSZLUMcOcJElSxwxzkiRJHTPMSZIkdcwwJ0mS1DHDnCRJUscMc5IkSR0zzEmSJHXMMCdJ\nktQxw5wkSVLHDHOSJEkdM8xJkiR1zDAnSZLUMcOcJElSxwxzkiRJHTPMSZIkdcwwJ0mS1DHDnCRJ\nUse6DnNJjktyY5L1SU5b6nokSZKmrdswl2Qn4A+BZwCHASckOWxpq5IkSZqubsMccDSwvqo+X1X/\nCVwAHL/ENUmSJE3VzktdwDdhP+C2kc+3Az8wc6YkJwMnt4/3J7lxCrVpfnsB/7rURSxXv7rUBWhb\nuE/Pw326S+7T85jiPv2YcWbqOcyNparOBs5e6jr0NUnWVtXKpa5DmhT3aW1v3Kf70vNp1g3AASOf\n929tkiRJO4yew9wngUOSHJzkocAq4KIlrkmSJGmquj3NWlUPJHkp8DfATsA5VbVuicvSeDztre2N\n+7S2N+7THUlVLXUNkiRJ2kY9n2aVJEna4RnmJEmSOmaY09QkeUmSE9v0C5LsO9L3Rz7BQ9uDJHsk\nOWXk875J/nwpa5K2RZKDkvzMNi57/6Tr0dy8Zk5LIslHgV+rqrVLXYs0SUkOAi6uqiOWuBTpm5Lk\nKQz/Tz9rlr6dq+qBeZa9v6oevpj16Ws8MqextL/QPpvkPUluSPLnSb4lybFJPp3k2iTnJNm1zf+6\nJNcnuSbJG1rbGUl+LclzgZXAe5JcnWS3JB9NsrIdvfv9ke2+IMlb2/TPJbmyLfPO9nxeaUHavnxD\nknclWZfkQ20f/I4klya5KsnfJ/muNv93JLmi7eP/Z8sRhyQPT7Imyada35bHCb4O+I62n/5+2951\nbZkrkhw+UsuW/f5b28/Ple3nyUcTapttwz5+bvt/ecvyW46qvQ74obYvv7z9f3xRko8Aa+b5GdC0\nVZUvX1t9AQcBBTy5fT4H+F8Mj1Q7tLWdD/wK8G3AjXztyO8e7f0Mhr/yAD4KrBxZ/0cZAt4Khmfu\nbmm/BPhB4PHAB4BdWvvbgBOX+t/FV3+vti8/ABzZPq8Gfg5YAxzS2n4A+Eibvhg4oU2/BLi/Te8M\n7N6m9wLWA2nrv27G9q5r0y8HXt2m9wFubNOvBX6uTe8B3AR861L/W/nq87UN+/i5wHNHlt+yjz+F\n4SjzlvYXMDw681Ht86w/A6Pr8DWdl0fmtBC3VdU/tOn/BxwL3FxVN7W284D/Bvwb8GXg3Ul+AviP\ncTdQVZuAzyc5Jsm3Ad8F/EPb1lHAJ5Nc3T4/dgLfSTumm6vq6jZ9FcMvvycBf9b2r3cyhC2AJwJ/\n1qbfO7KOAK9Ncg3wYYbnRe+9le2uBrYcAXkesOVauqcBp7VtfxR4GHDggr+V9DUL2ccX4rKqurtN\nb8vPgBZBtzcN1pKYeYHlvQxH4b5+puGGzkczBK7nAi8FfnQB27mA4RfdZ4H3V1UlCXBeVZ2+TZVL\nX2/zyPSDDL+A7q2qIxewjp9lOJJ8VFV9JcktDCFsTlW1IckXknwP8NMMR/pg+KX4k1V14wK2L81n\nIfv4A7RozZyYAAAFQUlEQVTLrpI8BHjoPOv995HpBf8MaHF4ZE4LcWCSJ7bpnwHWAgcl+c7W9nzg\nb5M8HHhkVX2Q4bTS986yri8Cj5hjO+8HjgdOYAh2MJweeG6SRwMkeVSSx3yzX0hq7gNuTvJTABls\n2W+vAH6yTa8aWeaRwF3tl9iPAFv2x/n2bYD3Ab/B8DNyTWv7G+Bl7Y8Wkjzhm/1C0gzz7eO3MJz5\nAPgfwC5temv78lw/A5oyw5wW4kbg1CQ3AHsCZwH/k+Gw/bXAV4F3MPzwX9wOvX8M+NVZ1nUu8I4t\nAyBGO6rqHuAG4DFVdWVru57hGr0PtfVexradIpDm8rPAC5N8BljH8AcFDNeB/mrb776T4TICgPcA\nK9u+fyLDkWSq6gvAPyS5bnQwz4g/ZwiFq0fafofhF+g1Sda1z9KkzbWPvwv44db+RL529O0a4MEk\nn0ny8lnWN+vPgKbPW5NoLPF2C9pBJfkW4EvtdP8qhsEQjtqTtGx4zZwkze8o4K3tFOi9wM8vcT2S\n9HU8MidJktQxr5mTJEnqmGFOkiSpY4Y5SZKkjhnmJG3Xkvxkko8kuTfJ5iQ3JXlTkn3bMywryTc8\nSFySemGYk7TdSvJGhvu5fZ7hptZPY7g/4rHAHy5haZI0Md6aRNJ2KcmPM9yw+oVVdc5I198mOZsh\n2ElS9zwyJ2l79XLgUzOCHABV9WBVXTLbQklOTPKxJHcnuSfJ5UlWzpjn8CSXtnn+PckNSU4d6f/B\nJH+f5L72unrLY5RG5vmFJOvaqd9bk/zGQrYhSVt4ZE7SdifJLsCTgDduw+IHMzym6HMMj9g6Afj7\nJIdX1efbPB9geOTczzE80PxxwO5t27sDFwMXAq8BAnw3sMdIfb8OvBZ4PfBRhhsT/06S/6iqt25t\nG5I0ypsGS9ruJPl2YCPwkqp65zzzHQTcDPx4VV08S/9DGM5gXAe8t6pek2QvYBPwPVV17SzLrAQ+\nCexeVV+cpX934F+A36+qV4+0vwY4GdiP4dnHc25DkkZ5mlXS9mzBf60meXyS9ye5E3gQ+ArDUbFD\n2yx3A7cB70jy00kePWMV/wTcD7w3yfFJ9pjR/0TgW4E/S7LzlhfwEWBvYP8xtiFJ/8UwJ2l79AWG\nU5MHLmShJI8APgQcwDB44oeA7wc+AzwMoKq+yjB44g7gHOCOdn3cE1r/PcBTGU7RrgY2JfnrJI9t\nm9mrva9jCIpbXpe39gO2tg1JGuVpVknbpSRrGE51fv888xzEyGnWJE8D/gZ4fFV9dmS+m4Grquq5\nM5bfhSHw/R7D6dH9WxDb0r8b8GPAm4AvVNUxSZ4BfBB4FnDnLGXdOHp6dmvbkCSPzEnaXv0BsDLJ\nSTM7kjwkyXGzLLNbe988Mu+TgINm20BVfaWqPsIQ1vZhZJBD6/9SVX2A4ejaYa3548CXgH2rau0s\nry8uZBuS5GhWSdulqvpAkjcB707yZIbRpfcD3wW8BLiF4fYlo65o87wryesZrl87A9iwZYYk3wO8\nAXgfw82I9wReCXymqu5O8t+Bnwf+CvhnhqNpL2a4Jo6qujfJGcCbkzwG+DuGP6wPBX6kqp6ztW1M\n6J9I0nbCMCdpu1VVr0jyj8BLgfcyHHm7BbiIISw9bMb8d7b7wb2BIfx9jiH4jd4D7g6G06OvAvYF\n7mW43u2VrX89w8CL1wKPZhiVejHwmyPbeX2Sf2EIk68AvgzcxBDextmGJP0Xr5mTJEnqmNfMSZIk\ndcwwJ0mS1DHDnCRJUscMc5IkSR0zzEmSJHXMMCdJktQxw5wkSVLHDHOSJEkd+/+m4yDE+We0xAAA\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f644b2bf6a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The bar chart for the test data set\n",
    "\n",
    "y = [len(t_df[t_df[2] == i]) for i in ['positive', 'negative', 'neutral']]\n",
    "x = ['positive', 'negative', 'neutral']\n",
    "x_pos = range(len(x))\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.bar(x_pos, y, alpha=0.5)\n",
    "plt.xticks(x_pos, x)\n",
    "plt.ylabel('# Occurences').set_size(15)\n",
    "plt.xlabel('Classes').set_size(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-process tweets from the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_tweets_test = t_df[3]\n",
    "\n",
    "t_unigram140Score, t_unigram140Reps = [], []\n",
    "t_bigram140Score, t_bigram140Reps = [], []\n",
    "t_SemEvalScore, t_SemEvalReps = [], []\n",
    "for tweet in raw_tweets_test:\n",
    "    tweet = tweet.lower()\n",
    "    #Sentiment140 unigram Score\n",
    "    score, reps = unigram140Polarity(tweet, unigram140_d)\n",
    "    t_unigram140Score.append(score)\n",
    "    t_unigram140Reps.append(reps)\n",
    "    #Sentiment140 bigram Score\n",
    "    score, reps = bigram140Polarity(tweet, bigram140_d)\n",
    "    t_bigram140Score.append(score)\n",
    "    t_bigram140Reps.append(reps)\n",
    "    # SentEval 2015 Score\n",
    "    score, reps = SemEvalLexiconPolarity(tweet, EnglishLexicon)\n",
    "    t_SemEvalScore.append(score)\n",
    "    t_SemEvalReps.append(reps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_tweets_test = [replaceSlangs(tweet, slangs) for tweet in raw_tweets_test]\n",
    "raw_tweets_test = [replace_apostrophe(tweet, apos) for tweet in raw_tweets_test]\n",
    "raw_tweets_test = [subsEmoticon(tweet, dict) for tweet in raw_tweets_test]\n",
    "raw_tweets_test = [handle_negation(tweet) for tweet in raw_tweets_test] #negation\n",
    "lemmatized_tweets_test = [lemma(tweet) for tweet in raw_tweets_test]\n",
    "preprocessed_tweets_test = [preprocess(tweet) for tweet in lemmatized_tweets_test]\n",
    "final_tweets_test = [rem_stop(tweet) for tweet in preprocessed_tweets_test]\n",
    "t_df[3] = final_tweets_test\n",
    "\n",
    "del raw_tweets_test, lemmatized_tweets_test, preprocessed_tweets_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done scoring test set ..\n",
      "Done reshaping test set ..\n"
     ]
    }
   ],
   "source": [
    "t_raw_tweets_MPQA = [subsMPQA(tweet,dictionary) for tweet in final_tweets_test]\n",
    "t_lemmatized_tweets_MPQA = [lemma(tweet) for tweet in t_raw_tweets_MPQA]\n",
    "t_raw_tweets_bing = [subsBINGP(tweet, expanded_pos) for tweet in t_lemmatized_tweets_MPQA]\n",
    "t_raw_tweets_bing = [subsBINGN(tweet, expanded_neg) for tweet in t_lemmatized_tweets_MPQA]\n",
    "\n",
    "t_BingMpqaScore = []\n",
    "t_AfinnScore, t_AfinnReps = [], []\n",
    "t_WordnetScore, t_WordnetReps = [], []\n",
    "t_length = len(t_raw_tweets_bing)\n",
    "\n",
    "for tw in t_raw_tweets_bing:\n",
    "    Bing_MPQA = 0\n",
    "    for i in tw:\n",
    "        if (i == 'positive'):\n",
    "            Bing_MPQA +=  1\n",
    "        if (i == 'negative'):\n",
    "            Bing_MPQA -= 1\n",
    "    t_BingMpqaScore.append(Bing_MPQA)\n",
    "    tmp = afinnPolarity(tw, afinn)\n",
    "    t_AfinnScore.append(tmp[0])\n",
    "    t_AfinnReps.append(tmp[1])\n",
    "    tmp = WordnetPolarity(tw, sentiWordnet)\n",
    "    t_WordnetScore.append(tmp[0])\n",
    "    t_WordnetReps.append(tmp[1])\n",
    "print(\"Done scoring test set ..\")\n",
    "    \n",
    "#reshape\n",
    "t_BingMpqaScore = np.array(t_BingMpqaScore).reshape(t_length, 1)\n",
    "t_AfinnScore = np.array(t_AfinnScore).reshape(t_length, 1)\n",
    "t_AfinnReps = np.array(t_AfinnReps).reshape(t_length, 1)\n",
    "t_WordnetScore = np.array(t_WordnetScore).reshape(t_length, 1)\n",
    "t_WordnetReps = np.array(t_WordnetReps).reshape(t_length, 1)\n",
    "t_SemEvalScore = np.array(t_SemEvalScore).reshape(t_length, 1)\n",
    "t_SemEvalReps = np.array(t_SemEvalReps).reshape(t_length, 1)\n",
    "t_unigram140Score = np.array(t_unigram140Score).reshape(t_length, 1)\n",
    "t_unigram140Reps = np.array(t_unigram140Reps).reshape(t_length, 1)\n",
    "t_bigram140Score = np.array(t_bigram140Score).reshape(t_length, 1)\n",
    "t_bigram140Reps = np.array(t_bigram140Reps).reshape(t_length, 1)\n",
    "print(\"Done reshaping test set ..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done normalizing test set ..\n",
      "(7584, 6)\n"
     ]
    }
   ],
   "source": [
    "#Normalization\n",
    "t_BingMpqaScore = t_BingMpqaScore/np.linalg.norm(t_BingMpqaScore)\n",
    "t_AfinnScore = t_AfinnScore/np.linalg.norm(t_AfinnScore)\n",
    "t_AfinnReps = t_AfinnReps/np.linalg.norm(t_AfinnReps)\n",
    "t_WordnetScore = t_WordnetScore/np.linalg.norm(t_WordnetScore)\n",
    "t_WordnetReps = t_WordnetReps/np.linalg.norm(t_WordnetReps)\n",
    "t_SemEvalScore = t_SemEvalScore/np.linalg.norm(t_SemEvalScore)\n",
    "t_SemEvalReps = t_SemEvalReps/np.linalg.norm(t_SemEvalReps)\n",
    "t_unigram140Score = t_unigram140Score/np.linalg.norm(t_unigram140Score)\n",
    "t_unigram140Reps = t_unigram140Reps/np.linalg.norm(t_unigram140Reps)\n",
    "t_bigram140Score = t_bigram140Score/np.linalg.norm(t_bigram140Score)\n",
    "t_bigram140Reps = t_bigram140Reps/np.linalg.norm(t_bigram140Reps)\n",
    "print(\"Done normalizing test set ..\")\n",
    "\n",
    "t_all_scores = np.hstack( (t_BingMpqaScore, t_AfinnScore, t_WordnetScore, t_SemEvalScore, t_unigram140Score, t_bigram140Score) )\n",
    "t_sum_score = np.sum(t_all_scores, axis=1).reshape(t_length, 1)\n",
    "print (t_all_scores.shape)\n",
    "\n",
    "# Delete\n",
    "del t_raw_tweets_MPQA, t_lemmatized_tweets_MPQA, t_raw_tweets_bing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>282031301962395648</td>\n",
       "      <td>T14111200</td>\n",
       "      <td>neutral</td>\n",
       "      <td>dec as_not end_not world_not baby_not boom_not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11975</td>\n",
       "      <td>SM112166</td>\n",
       "      <td>negative</td>\n",
       "      <td>yar quite clever aft lor ask thk darren so_not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>136592</td>\n",
       "      <td>LJ112295</td>\n",
       "      <td>negative</td>\n",
       "      <td>thin lizzy hate informercial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>253421252956545024</td>\n",
       "      <td>T13114433</td>\n",
       "      <td>neutral</td>\n",
       "      <td>mt #syria deir ezzor ali bashar altheeb martyr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>220880422320603137</td>\n",
       "      <td>T14114138</td>\n",
       "      <td>negative</td>\n",
       "      <td>hate roskilde_not festival_not saturday_not pr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0          1         2  \\\n",
       "2  282031301962395648  T14111200   neutral   \n",
       "3               11975   SM112166  negative   \n",
       "4              136592   LJ112295  negative   \n",
       "5  253421252956545024  T13114433   neutral   \n",
       "6  220880422320603137  T14114138  negative   \n",
       "\n",
       "                                                   3  \n",
       "2  dec as_not end_not world_not baby_not boom_not...  \n",
       "3  yar quite clever aft lor ask thk darren so_not...  \n",
       "4                       thin lizzy hate informercial  \n",
       "5  mt #syria deir ezzor ali bashar altheeb martyr...  \n",
       "6  hate roskilde_not festival_not saturday_not pr...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the features vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7584, 5)\n",
      "(7584, 80050)\n"
     ]
    }
   ],
   "source": [
    "test_features = count_vectorizer.transform(final_tweets_test)\n",
    "test_count_features = svd.transform(test_features)\n",
    "test_count_features = scipy.sparse.csr_matrix(test_count_features)\n",
    "print (test_count_features.shape)\n",
    "\n",
    "\n",
    "test_tfidf_features = tfidf_vectorizer.transform(final_tweets_test)\n",
    "test_tfidf_features = scipy.sparse.csr_matrix(test_tfidf_features)\n",
    "print (test_tfidf_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7584, 12)\n",
      "(7584, 80067)\n"
     ]
    }
   ],
   "source": [
    "t_final_total = scipy.sparse.csr_matrix(np.hstack( (t_all_scores, t_sum_score, t_AfinnReps, t_WordnetReps, t_SemEvalReps, t_unigram140Reps, t_bigram140Reps) ))\n",
    "print (t_final_total.shape)\n",
    "test_features = scipy.sparse.hstack([test_count_features, test_tfidf_features, t_final_total])\n",
    "print (test_features.shape)\n",
    "\n",
    "del t_all_scores, t_sum_score, t_BingMpqaScore, t_AfinnScore, t_WordnetScore, t_SemEvalScore, t_unigram140Score, t_bigram140Score\n",
    "del t_AfinnReps, t_WordnetReps, t_SemEvalReps, t_unigram140Reps, t_bigram140Reps\n",
    "del test_count_features, test_tfidf_features, t_final_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get labels from a set of test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7584,)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_labels = t_df[2]\n",
    "actual_labels = actual_labels.map(mapper)\n",
    "actual_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict labels using the template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = classifier.predict(test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>Evaluate the Model</font>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 58.36%\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {:0.2f}%'.format(metrics.accuracy_score(actual_labels, predicted_labels) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy of cross-validation 10 times on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import model_selection\n",
    "\n",
    "# scores = model_selection.cross_val_score(classifier, test_features, actual_labels, cv=10, scoring='accuracy')\n",
    "# print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "# del test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.65      0.40      0.50      1296\n",
      "          0       0.57      0.71      0.63      3448\n",
      "          1       0.58      0.51      0.54      2840\n",
      "\n",
      "avg / total       0.59      0.58      0.58      7584\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# draw the classification report\n",
    "print('{}'.format(metrics.classification_report(actual_labels, predicted_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See [Confusion Matrix](https://fr.wikipedia.org/wiki/Matrice_de_confusion) for more details\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1449  120 1271]\n",
      " [ 210  523  563]\n",
      " [ 832  162 2454]]\n",
      "\n",
      "\u001b[31m\" macro f1 score \"\u001b[0m\n",
      "0.5586357982113245\n",
      "\n",
      "\u001b[31m\" micro f1 score \"\u001b[0m\n",
      "0.5835970464135021\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print('{}\\n'.format(metrics.confusion_matrix(actual_labels, predicted_labels, labels=[1,-1,0])))\n",
    "print(\"\\x1b[31m\\\" macro f1 score \\\"\\x1b[0m\")\n",
    "print('{}\\n'.format(metrics.f1_score(actual_labels, predicted_labels, average='macro')))\n",
    "print(\"\\x1b[31m\\\" micro f1 score \\\"\\x1b[0m\")\n",
    "print('{}\\n'.format(metrics.f1_score(actual_labels, predicted_labels, average='micro')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison with the 5 best teams of subtask B\n",
    "\n",
    "We compare our average f-score with the other teams in the workshop. The results are taken from the attached document:\n",
    "[Final report SemEval 2014 Subtask 9](http://www.aclweb.org/anthology/S14-2009)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Team|Accuracy (Macro Averaged)| Accuracy (Micro Averaged)|\n",
    "|----|-------------------------|--------------------------|\n",
    "|TeamX|65.63%|69.99%|\n",
    "|coooolll|63.23%|70.51%|\n",
    "|RTRGO|63.08%|70.15%|\n",
    "|NRC-Canada|67.62%|71.37%|\n",
    "|TUGAS|63.89%|68.84%|\n",
    "|**_ME_**|_57.48%_|_64.86%_|\n",
    "| | |***classement : 23 / 50***|\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# <font color='red'>Stopwords Analysis</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Method|Accuracy (Macro Averaged)| Accuracy (Micro Averaged)|\n",
    "|----|-------------------------|--------------------------|\n",
    "|Baseline (with stopwords)|63.56%|65.75%|\n",
    "|classical|65.14%|68.01%|\n",
    "|TF-High|58.78|61.23|\n",
    "|TF1|63.69|66.20|\n",
    "|IDF|52.39|56.77|\n",
    "|TRBS|55.86|58.35|\n",
    "|MI|Nan|Nan|\n",
    "\n",
    "**NOTE**:\n",
    "- The 'TF1' method wasn't great as expected because we are using tfidf vectorizer which mainly depends on the infrequent words which we have removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
